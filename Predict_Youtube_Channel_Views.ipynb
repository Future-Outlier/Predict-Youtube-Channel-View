{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20479f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e107eaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'Totals.csv'\n",
    "f = open(fname, encoding = 'cp950')\n",
    "data = f.read()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e30a3387",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Date,Views\\n2021-04-22,0\\n2021-04-23,0\\n2021-04-24,491\\n2021-04-25,117\\n2021-04-26,54\\n2021-04-27,794\\n2021-04-28,738\\n2021-04-29,1695\\n2021-04-30,925\\n2021-05-01,220\\n2021-05-02,176\\n2021-05-03,85\\n2021-05-04,39\\n2021-05-05,100\\n2021-05-06,45\\n2021-05-07,40\\n2021-05-08,38\\n2021-05-09,35\\n2021-05-10,12\\n2021-05-11,17\\n2021-05-12,18\\n2021-05-13,14\\n2021-05-14,29\\n2021-05-15,17\\n2021-05-16,175\\n2021-05-17,108\\n2021-05-18,56\\n2021-05-19,32\\n2021-05-20,50\\n2021-05-21,36\\n2021-05-22,45\\n2021-05-23,54\\n2021-05-24,35\\n2021-05-25,28\\n2021-05-26,254\\n2021-05-27,68\\n2021-05-28,67\\n2021-05-29,425\\n2021-05-30,158\\n2021-05-31,112\\n2021-06-01,55\\n2021-06-02,61\\n2021-06-03,53\\n2021-06-04,18\\n2021-06-05,37\\n2021-06-06,42\\n2021-06-07,50\\n2021-06-08,39\\n2021-06-09,30\\n2021-06-10,21\\n2021-06-11,13\\n2021-06-12,50\\n2021-06-13,40\\n2021-06-14,27\\n2021-06-15,63\\n2021-06-16,55\\n2021-06-17,35\\n2021-06-18,20\\n2021-06-19,28\\n2021-06-20,55\\n2021-06-21,55\\n2021-06-22,22\\n2021-06-23,21\\n2021-06-24,36\\n2021-06-25,23\\n2021-06-26,34\\n2021-06-27,22\\n2021-06-28,22\\n2021-06-29,31\\n2021-06-30,22\\n2021-07-01,23\\n2021-07-02,40\\n2021-07-03,22\\n2021-07-04,28\\n2021-07-05,15\\n2021-07-06,19\\n2021-07-07,38\\n2021-07-08,11\\n2021-07-09,22\\n2021-07-10,119\\n2021-07-11,69\\n2021-07-12,42\\n2021-07-13,29\\n2021-07-14,21\\n2021-07-15,14\\n2021-07-16,28\\n2021-07-17,26\\n2021-07-18,27\\n2021-07-19,33\\n2021-07-20,36\\n2021-07-21,38\\n2021-07-22,21\\n2021-07-23,25\\n2021-07-24,17\\n2021-07-25,22\\n2021-07-26,23\\n2021-07-27,22\\n2021-07-28,11\\n2021-07-29,16\\n2021-07-30,10\\n2021-07-31,21\\n2021-08-01,21\\n2021-08-02,86\\n2021-08-03,30\\n2021-08-04,236\\n2021-08-05,171\\n2021-08-06,23\\n2021-08-07,22\\n2021-08-08,18\\n2021-08-09,44\\n2021-08-10,28\\n2021-08-11,52\\n2021-08-12,37\\n2021-08-13,25\\n2021-08-14,19\\n2021-08-15,15\\n2021-08-16,39\\n2021-08-17,214\\n2021-08-18,59\\n2021-08-19,66\\n2021-08-20,37\\n2021-08-21,48\\n2021-08-22,60\\n2021-08-23,52\\n2021-08-24,39\\n2021-08-25,18\\n2021-08-26,32\\n2021-08-27,78\\n2021-08-28,49\\n2021-08-29,21\\n2021-08-30,68\\n2021-08-31,75\\n2021-09-01,68\\n2021-09-02,60\\n2021-09-03,130\\n2021-09-04,278\\n2021-09-05,119\\n2021-09-06,68\\n2021-09-07,34\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eba1b721",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines=data.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d7e97cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5e799f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Views'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers=lines[0].split(',')[1]\n",
    "\n",
    "headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3caf2f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "del lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cec605ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46350413",
   "metadata": {},
   "outputs": [],
   "source": [
    "del lines[139]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b4c1860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "views = []\n",
    "# enumerate will give the count number of the loop (i)\n",
    "for i, line in enumerate(lines):\n",
    "#     print(line.split(','))\n",
    "#     print(i, line)\n",
    "\n",
    "    view = int(line.split(',')[1]) # get the information of youtube view\n",
    "    views.append(view) # for RNN format \n",
    "\n",
    "views = np.array(views) # convert it into  numpy array \n",
    "\n",
    "plt.plot(views, label=\"views\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34e23a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139\n"
     ]
    }
   ],
   "source": [
    "print(len(views))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2094b33",
   "metadata": {},
   "source": [
    "## Let's use RNN to predict viewers in next 1 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b9b079a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139\n"
     ]
    }
   ],
   "source": [
    "print(len(views))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e459b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "new_raw_data=[]\n",
    "for i in range(len(views)):\n",
    "    new_raw_data.append([views[i]])\n",
    "print(type(new_raw_data))\n",
    "new_raw_data = np.array(new_raw_data)\n",
    "print(type(new_raw_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035c8b17",
   "metadata": {},
   "source": [
    "## I plan to use last 3 days to predict the next day views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48c8414a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136 136\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "length = 3\n",
    "delay = 3 \n",
    "sampling_rate = 1\n",
    "stride = 1 \n",
    "batch_size = 1 \n",
    "\n",
    "data = new_raw_data[:-(delay)]\n",
    "target = new_raw_data[(delay):] \n",
    "print(len(data), len(target))\n",
    "# Create Training Data \n",
    "train_gen = TimeseriesGenerator(data, target, \n",
    "                               length=length,\n",
    "                               sampling_rate=sampling_rate,\n",
    "                               stride=stride,\n",
    "                               start_index=0,\n",
    "                               end_index=100,\n",
    "                               batch_size=1)\n",
    "# Create Validation Data \n",
    "val_gen = TimeseriesGenerator(data, target, \n",
    "                               length=length,\n",
    "                               sampling_rate=sampling_rate,\n",
    "                               stride=stride,\n",
    "                               start_index=101,\n",
    "                               end_index=135,\n",
    "                               batch_size=1)\n",
    "# # Create Testing Data \n",
    "# test_gen = TimeseriesGenerator(data, target, \n",
    "#                                length=length,\n",
    "#                                sampling_rate=sampling_rate,\n",
    "#                                stride=stride,\n",
    "#                                start_index=21,\n",
    "#                                end_index=24,\n",
    "#                                batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "316a84ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.preprocessing.sequence.TimeseriesGenerator object at 0x0000022BDDA814C0>\n",
      "98\n"
     ]
    }
   ],
   "source": [
    "print(train_gen)\n",
    "print(len(train_gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b021e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn (SimpleRNN)       (None, 10)                120       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 241\n",
      "Trainable params: 241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras import layers\n",
    "rnn_model = Sequential([\n",
    "    layers.SimpleRNN(10, input_shape=(3, 1)),\n",
    "    layers.Dense(10, activation='relu'),\n",
    "    layers.Dense(1)  \n",
    "])\n",
    "rnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86a32263",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model.compile(optimizer='rmsprop', loss='mse',\n",
    "                   metrics=['mae']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a8f98a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "98/98 [==============================] - 1s 3ms/step - loss: 48898.6133 - mae: 80.5104 - val_loss: 6547.4736 - val_mae: 59.3464\n",
      "Epoch 2/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 48671.2617 - mae: 79.2157 - val_loss: 6374.9536 - val_mae: 57.8720\n",
      "Epoch 3/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 48530.9727 - mae: 77.8854 - val_loss: 6219.9087 - val_mae: 56.5194\n",
      "Epoch 4/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 48271.4727 - mae: 76.3508 - val_loss: 6062.1719 - val_mae: 55.1073\n",
      "Epoch 5/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 47974.2539 - mae: 74.6173 - val_loss: 5844.0278 - val_mae: 53.0912\n",
      "Epoch 6/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 47783.8555 - mae: 72.9731 - val_loss: 5692.5894 - val_mae: 51.6453\n",
      "Epoch 7/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 47482.6328 - mae: 71.2304 - val_loss: 5496.0884 - val_mae: 49.7064\n",
      "Epoch 8/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 47226.9336 - mae: 69.5372 - val_loss: 5315.5898 - val_mae: 47.8563\n",
      "Epoch 9/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 47015.4492 - mae: 68.0621 - val_loss: 5170.9028 - val_mae: 46.3391\n",
      "Epoch 10/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 46802.4961 - mae: 66.6289 - val_loss: 4998.9917 - val_mae: 44.5630\n",
      "Epoch 11/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 46542.1953 - mae: 65.1679 - val_loss: 4858.0088 - val_mae: 43.1499\n",
      "Epoch 12/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 46376.4336 - mae: 63.9416 - val_loss: 4701.4902 - val_mae: 41.7367\n",
      "Epoch 13/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 46103.6367 - mae: 62.7193 - val_loss: 4552.9790 - val_mae: 40.4749\n",
      "Epoch 14/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 45858.5859 - mae: 61.9649 - val_loss: 4405.6162 - val_mae: 39.2668\n",
      "Epoch 15/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 45709.9062 - mae: 61.3743 - val_loss: 4277.3271 - val_mae: 38.2390\n",
      "Epoch 16/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 45487.6133 - mae: 60.8662 - val_loss: 4170.0859 - val_mae: 37.3675\n",
      "Epoch 17/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 45277.6719 - mae: 60.4990 - val_loss: 4039.2107 - val_mae: 36.3580\n",
      "Epoch 18/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 45118.8828 - mae: 60.2717 - val_loss: 3957.1809 - val_mae: 35.7004\n",
      "Epoch 19/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44966.9023 - mae: 60.2837 - val_loss: 3862.7844 - val_mae: 34.9496\n",
      "Epoch 20/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44836.7656 - mae: 60.2104 - val_loss: 3782.5408 - val_mae: 34.3345\n",
      "Epoch 21/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44708.9531 - mae: 60.1294 - val_loss: 3705.1853 - val_mae: 33.7932\n",
      "Epoch 22/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44534.3633 - mae: 60.2506 - val_loss: 3628.8049 - val_mae: 33.2350\n",
      "Epoch 23/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44435.2773 - mae: 60.5574 - val_loss: 3574.0103 - val_mae: 32.9496\n",
      "Epoch 24/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44316.1133 - mae: 60.6206 - val_loss: 3516.9033 - val_mae: 32.6932\n",
      "Epoch 25/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44217.6289 - mae: 60.9510 - val_loss: 3466.5212 - val_mae: 32.5474\n",
      "Epoch 26/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44140.0938 - mae: 61.2502 - val_loss: 3422.6733 - val_mae: 32.4135\n",
      "Epoch 27/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44047.3008 - mae: 61.6887 - val_loss: 3382.3472 - val_mae: 32.2836\n",
      "Epoch 28/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 43978.5781 - mae: 61.9430 - val_loss: 3345.5806 - val_mae: 32.1587\n",
      "Epoch 29/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 43870.6055 - mae: 62.4866 - val_loss: 3306.1377 - val_mae: 32.0707\n",
      "Epoch 30/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 43842.1133 - mae: 62.5267 - val_loss: 3287.7131 - val_mae: 32.0358\n",
      "Epoch 31/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 43769.8516 - mae: 62.9135 - val_loss: 3265.0376 - val_mae: 31.9910\n",
      "Epoch 32/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 43718.8281 - mae: 63.2820 - val_loss: 3239.4031 - val_mae: 31.9378\n",
      "Epoch 33/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 43663.6328 - mae: 63.5332 - val_loss: 3215.9941 - val_mae: 31.8864\n",
      "Epoch 34/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 43607.2539 - mae: 63.8503 - val_loss: 3191.5088 - val_mae: 31.8750\n",
      "Epoch 35/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 43594.0469 - mae: 63.9647 - val_loss: 3187.4690 - val_mae: 31.8750\n",
      "Epoch 36/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 43530.5469 - mae: 64.3606 - val_loss: 3176.1921 - val_mae: 31.8965\n",
      "Epoch 37/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 43513.9805 - mae: 64.3915 - val_loss: 3166.0505 - val_mae: 31.9227\n",
      "Epoch 38/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 43467.6172 - mae: 64.7003 - val_loss: 3162.0830 - val_mae: 31.9333\n",
      "Epoch 39/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 43572.5547 - mae: 64.1363 - val_loss: 3180.1748 - val_mae: 31.8864\n",
      "Epoch 40/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 43521.2344 - mae: 64.3151 - val_loss: 3165.2632 - val_mae: 31.9249\n",
      "Epoch 41/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 43480.6797 - mae: 64.6144 - val_loss: 3152.0596 - val_mae: 31.9606\n",
      "Epoch 42/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 43460.3203 - mae: 64.7694 - val_loss: 3147.4062 - val_mae: 31.9737\n",
      "Epoch 43/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 43425.3047 - mae: 64.8743 - val_loss: 3132.9470 - val_mae: 32.0164\n",
      "Epoch 44/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 43385.7891 - mae: 65.2850 - val_loss: 3126.4651 - val_mae: 32.0367\n",
      "Epoch 45/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 43518.0938 - mae: 65.3753 - val_loss: 3124.3984 - val_mae: 32.0433\n",
      "Epoch 46/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 43376.7539 - mae: 65.4892 - val_loss: 3115.5779 - val_mae: 32.0881\n",
      "Epoch 47/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 43341.5195 - mae: 65.6538 - val_loss: 3110.6497 - val_mae: 32.1374\n",
      "Epoch 48/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 43327.7188 - mae: 65.6929 - val_loss: 3102.1479 - val_mae: 32.2249\n",
      "Epoch 49/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 43296.2305 - mae: 65.9624 - val_loss: 3099.0974 - val_mae: 32.2598\n",
      "Epoch 50/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 43276.2188 - mae: 66.0624 - val_loss: 3090.0083 - val_mae: 32.3602\n",
      "Epoch 51/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 43238.0156 - mae: 66.2507 - val_loss: 3089.4519 - val_mae: 32.3579\n",
      "Epoch 52/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 43255.2617 - mae: 65.8913 - val_loss: 3089.5400 - val_mae: 32.2914\n",
      "Epoch 53/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 43439.7695 - mae: 64.2826 - val_loss: 3161.8372 - val_mae: 32.1313\n",
      "Epoch 54/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 43217.9727 - mae: 63.8195 - val_loss: 3255.5586 - val_mae: 32.3761\n",
      "Epoch 55/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 43313.8203 - mae: 61.9664 - val_loss: 3133.8723 - val_mae: 32.2270\n",
      "Epoch 56/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 43148.5664 - mae: 63.3135 - val_loss: 3164.7092 - val_mae: 32.2919\n",
      "Epoch 57/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 43386.7656 - mae: 61.8061 - val_loss: 3161.3201 - val_mae: 32.3475\n",
      "Epoch 58/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 43006.9492 - mae: 63.3383 - val_loss: 3276.8743 - val_mae: 32.5188\n",
      "Epoch 59/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 43144.2500 - mae: 62.6481 - val_loss: 3291.7688 - val_mae: 32.5233\n",
      "Epoch 60/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 43073.2031 - mae: 62.4561 - val_loss: 3135.6143 - val_mae: 32.5945\n",
      "Epoch 61/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 43120.8711 - mae: 62.3976 - val_loss: 3180.4492 - val_mae: 32.6373\n",
      "Epoch 62/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 42894.9883 - mae: 62.5038 - val_loss: 3140.9575 - val_mae: 32.7515\n",
      "Epoch 63/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 42992.5469 - mae: 62.3598 - val_loss: 3223.7935 - val_mae: 32.7710\n",
      "Epoch 64/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 42773.8008 - mae: 63.1010 - val_loss: 3382.2168 - val_mae: 33.2247\n",
      "Epoch 65/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 43134.8164 - mae: 61.5596 - val_loss: 3208.7725 - val_mae: 33.0163\n",
      "Epoch 66/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 42837.5820 - mae: 62.5004 - val_loss: 3185.3064 - val_mae: 33.0033\n",
      "Epoch 67/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 42662.8633 - mae: 62.3094 - val_loss: 3245.9575 - val_mae: 32.9177\n",
      "Epoch 68/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 43132.9844 - mae: 58.8791 - val_loss: 3212.3608 - val_mae: 32.8532\n",
      "Epoch 69/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 42640.4805 - mae: 61.9699 - val_loss: 3174.9304 - val_mae: 32.7627\n",
      "Epoch 70/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 42613.2461 - mae: 62.2907 - val_loss: 3281.0850 - val_mae: 32.8327\n",
      "Epoch 71/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 42535.8555 - mae: 60.9740 - val_loss: 3095.8406 - val_mae: 32.8887\n",
      "Epoch 72/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 42314.0625 - mae: 63.0827 - val_loss: 3138.9890 - val_mae: 32.9198\n",
      "Epoch 73/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 42306.1016 - mae: 62.2683 - val_loss: 3178.3027 - val_mae: 33.1465\n",
      "Epoch 74/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 42338.2734 - mae: 62.2003 - val_loss: 3160.7014 - val_mae: 33.1901\n",
      "Epoch 75/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 42170.2617 - mae: 63.0946 - val_loss: 3250.6030 - val_mae: 33.4308\n",
      "Epoch 76/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 42130.6133 - mae: 62.7060 - val_loss: 3386.6497 - val_mae: 33.2531\n",
      "Epoch 77/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 42490.4219 - mae: 60.4302 - val_loss: 3191.2590 - val_mae: 33.5793\n",
      "Epoch 78/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 42211.5195 - mae: 61.5684 - val_loss: 3072.7939 - val_mae: 33.7911\n",
      "Epoch 79/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 42086.5898 - mae: 62.7724 - val_loss: 3083.1931 - val_mae: 33.8615\n",
      "Epoch 80/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 42023.2188 - mae: 63.1253 - val_loss: 3131.3225 - val_mae: 33.8559\n",
      "Epoch 81/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 41965.1797 - mae: 62.6410 - val_loss: 3134.8633 - val_mae: 34.0026\n",
      "Epoch 82/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 41889.4141 - mae: 63.2844 - val_loss: 3295.7976 - val_mae: 33.6867\n",
      "Epoch 83/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 42095.6680 - mae: 60.5990 - val_loss: 3104.9744 - val_mae: 34.2411\n",
      "Epoch 84/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 42169.7227 - mae: 61.0342 - val_loss: 3179.5828 - val_mae: 34.2526\n",
      "Epoch 85/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 41842.0664 - mae: 62.7834 - val_loss: 3142.1135 - val_mae: 34.4447\n",
      "Epoch 86/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 41794.4102 - mae: 62.6030 - val_loss: 3190.5964 - val_mae: 34.5356\n",
      "Epoch 87/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 41999.5117 - mae: 62.1661 - val_loss: 3269.2600 - val_mae: 34.4262\n",
      "Epoch 88/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 41765.9570 - mae: 62.4891 - val_loss: 3193.9641 - val_mae: 34.6104\n",
      "Epoch 89/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 42432.8711 - mae: 60.6628 - val_loss: 3240.8381 - val_mae: 34.4932\n",
      "Epoch 90/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 42009.8047 - mae: 61.3282 - val_loss: 3279.5029 - val_mae: 34.5711\n",
      "Epoch 91/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 41656.4297 - mae: 63.2618 - val_loss: 3374.0291 - val_mae: 34.4716\n",
      "Epoch 92/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 42235.3203 - mae: 60.4209 - val_loss: 3161.0010 - val_mae: 34.7943\n",
      "Epoch 93/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 41674.2734 - mae: 61.9377 - val_loss: 3162.7798 - val_mae: 35.3037\n",
      "Epoch 94/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 41572.7383 - mae: 63.1641 - val_loss: 3214.3215 - val_mae: 35.2072\n",
      "Epoch 95/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 41941.8398 - mae: 61.2218 - val_loss: 3290.9099 - val_mae: 34.9722\n",
      "Epoch 96/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 41606.9375 - mae: 61.7973 - val_loss: 3252.3342 - val_mae: 35.4414\n",
      "Epoch 97/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 41568.6172 - mae: 62.6990 - val_loss: 3256.9453 - val_mae: 35.5768\n",
      "Epoch 98/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 41505.7148 - mae: 61.9170 - val_loss: 3227.9048 - val_mae: 35.8823\n",
      "Epoch 99/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 41364.7695 - mae: 63.0654 - val_loss: 3235.2078 - val_mae: 35.9476\n",
      "Epoch 100/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 41495.1602 - mae: 63.1202 - val_loss: 3332.7432 - val_mae: 35.4783\n",
      "Epoch 101/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 42399.4844 - mae: 60.8237 - val_loss: 3368.0940 - val_mae: 34.9479\n",
      "Epoch 102/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 41550.7891 - mae: 61.6831 - val_loss: 3440.7791 - val_mae: 34.5473\n",
      "Epoch 103/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 42904.4648 - mae: 60.7076 - val_loss: 3393.4055 - val_mae: 34.2759\n",
      "Epoch 104/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 41665.0352 - mae: 61.9454 - val_loss: 3288.6885 - val_mae: 36.1056\n",
      "Epoch 105/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 41041.1484 - mae: 64.1555 - val_loss: 3407.6272 - val_mae: 35.4604\n",
      "Epoch 106/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 41462.8789 - mae: 61.6259 - val_loss: 3442.7317 - val_mae: 36.0772\n",
      "Epoch 107/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 41138.7578 - mae: 62.1743 - val_loss: 3570.6868 - val_mae: 34.9180\n",
      "Epoch 108/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 42015.8320 - mae: 59.5440 - val_loss: 3435.3416 - val_mae: 36.0257\n",
      "Epoch 109/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 41131.2305 - mae: 63.2623 - val_loss: 3475.2800 - val_mae: 35.7474\n",
      "Epoch 110/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 42359.4492 - mae: 59.4212 - val_loss: 3475.5120 - val_mae: 35.4795\n",
      "Epoch 111/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 41196.6406 - mae: 62.3915 - val_loss: 3401.5291 - val_mae: 36.5080\n",
      "Epoch 112/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 41250.8203 - mae: 61.5568 - val_loss: 3344.3752 - val_mae: 37.3231\n",
      "Epoch 113/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 40821.3125 - mae: 65.6057 - val_loss: 3448.4150 - val_mae: 35.2774\n",
      "Epoch 114/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 41525.0469 - mae: 61.1000 - val_loss: 3452.8560 - val_mae: 36.6606\n",
      "Epoch 115/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 40840.5547 - mae: 62.2203 - val_loss: 3448.2334 - val_mae: 35.7925\n",
      "Epoch 116/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 41996.8320 - mae: 60.1365 - val_loss: 3469.3411 - val_mae: 35.8008\n",
      "Epoch 117/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 42255.9766 - mae: 59.2211 - val_loss: 3411.1082 - val_mae: 36.0325\n",
      "Epoch 118/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 40769.9453 - mae: 64.6425 - val_loss: 3448.8281 - val_mae: 34.9591\n",
      "Epoch 119/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 41655.5703 - mae: 59.0364 - val_loss: 3343.9111 - val_mae: 36.5979\n",
      "Epoch 120/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 40687.8359 - mae: 65.3958 - val_loss: 3462.0671 - val_mae: 35.3029\n",
      "Epoch 121/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 42421.9844 - mae: 60.2785 - val_loss: 3468.0171 - val_mae: 34.7531\n",
      "Epoch 122/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 41021.9883 - mae: 62.2807 - val_loss: 3419.0398 - val_mae: 37.1093\n",
      "Epoch 123/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 41702.0586 - mae: 61.5034 - val_loss: 3502.1079 - val_mae: 36.5219\n",
      "Epoch 124/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 40736.6953 - mae: 63.0514 - val_loss: 3617.7505 - val_mae: 33.6089\n",
      "Epoch 125/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 41461.1523 - mae: 61.4955 - val_loss: 3490.7781 - val_mae: 37.7901\n",
      "Epoch 126/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 40930.1133 - mae: 62.5921 - val_loss: 3528.5073 - val_mae: 38.6191\n",
      "Epoch 127/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 40508.6406 - mae: 63.9031 - val_loss: 3535.2468 - val_mae: 35.2914\n",
      "Epoch 128/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 41207.9297 - mae: 62.4390 - val_loss: 3560.6047 - val_mae: 37.3970\n",
      "Epoch 129/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 42393.6562 - mae: 60.9441 - val_loss: 3261.2434 - val_mae: 35.0353\n",
      "Epoch 130/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 42061.3320 - mae: 62.9945 - val_loss: 3348.4038 - val_mae: 34.3742\n",
      "Epoch 131/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 40945.0117 - mae: 63.0546 - val_loss: 3525.0288 - val_mae: 33.3400\n",
      "Epoch 132/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 41069.8672 - mae: 61.1077 - val_loss: 3492.0581 - val_mae: 37.8470\n",
      "Epoch 133/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 41106.5391 - mae: 62.6636 - val_loss: 3509.9541 - val_mae: 38.5987\n",
      "Epoch 134/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 40266.7344 - mae: 65.6377 - val_loss: 3533.0715 - val_mae: 34.3793\n",
      "Epoch 135/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 41172.9375 - mae: 62.6913 - val_loss: 3437.5999 - val_mae: 34.6553\n",
      "Epoch 136/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 41248.6953 - mae: 61.6195 - val_loss: 3572.9097 - val_mae: 35.4718\n",
      "Epoch 137/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 41278.1680 - mae: 61.4190 - val_loss: 3587.6848 - val_mae: 36.0434\n",
      "Epoch 138/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 40822.3047 - mae: 62.1756 - val_loss: 3569.2656 - val_mae: 38.0375\n",
      "Epoch 139/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 40829.3906 - mae: 62.7966 - val_loss: 3498.5020 - val_mae: 37.1783\n",
      "Epoch 140/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 40876.5547 - mae: 60.5680 - val_loss: 3607.6624 - val_mae: 39.7993\n",
      "Epoch 141/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 40309.2070 - mae: 65.9563 - val_loss: 3643.0530 - val_mae: 40.1147\n",
      "Epoch 142/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 40224.1797 - mae: 66.0326 - val_loss: 3504.9949 - val_mae: 36.2577\n",
      "Epoch 143/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 41551.4805 - mae: 60.2043 - val_loss: 3582.3318 - val_mae: 37.9894\n",
      "Epoch 144/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 40098.2773 - mae: 64.6788 - val_loss: 3644.2175 - val_mae: 34.5702\n",
      "Epoch 145/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 43174.7305 - mae: 58.9494 - val_loss: 3488.2288 - val_mae: 33.6344\n",
      "Epoch 146/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 41622.3828 - mae: 60.5818 - val_loss: 3496.6602 - val_mae: 36.1255\n",
      "Epoch 147/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 40718.1758 - mae: 63.2763 - val_loss: 3559.1287 - val_mae: 38.9977\n",
      "Epoch 148/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 40669.9062 - mae: 63.5835 - val_loss: 3578.5378 - val_mae: 37.7491\n",
      "Epoch 149/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 40524.0273 - mae: 63.5946 - val_loss: 3600.9133 - val_mae: 34.7399\n",
      "Epoch 150/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 40937.3203 - mae: 61.6755 - val_loss: 3600.8391 - val_mae: 34.6663\n",
      "Epoch 151/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 42254.7852 - mae: 60.0865 - val_loss: 3416.2354 - val_mae: 36.6543\n",
      "Epoch 152/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 40988.6562 - mae: 62.2547 - val_loss: 3447.7102 - val_mae: 37.4731\n",
      "Epoch 153/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 41189.9883 - mae: 63.2947 - val_loss: 3438.4380 - val_mae: 36.3627\n",
      "Epoch 154/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 41736.5273 - mae: 60.6941 - val_loss: 3524.6401 - val_mae: 36.9383\n",
      "Epoch 155/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 40984.5898 - mae: 62.7266 - val_loss: 3568.9136 - val_mae: 37.1745\n",
      "Epoch 156/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 40799.9531 - mae: 62.7472 - val_loss: 3534.4749 - val_mae: 36.8122\n",
      "Epoch 157/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 41192.2812 - mae: 60.9373 - val_loss: 3571.2351 - val_mae: 38.2911\n",
      "Epoch 158/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 40586.3750 - mae: 64.0148 - val_loss: 3594.0139 - val_mae: 37.7939\n",
      "Epoch 159/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 40854.4805 - mae: 63.1218 - val_loss: 3615.2141 - val_mae: 37.6546\n",
      "Epoch 160/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 40650.7773 - mae: 62.6848 - val_loss: 3659.2827 - val_mae: 38.4246\n",
      "Epoch 161/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 40782.2578 - mae: 61.2772 - val_loss: 3675.1155 - val_mae: 39.8380\n",
      "Epoch 162/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 40701.8945 - mae: 62.5776 - val_loss: 3701.0005 - val_mae: 39.4451\n",
      "Epoch 163/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 40921.6719 - mae: 61.4604 - val_loss: 3651.1606 - val_mae: 37.5135\n",
      "Epoch 164/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 40922.4336 - mae: 61.5128 - val_loss: 3622.5969 - val_mae: 37.1214\n",
      "Epoch 165/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 41442.3281 - mae: 61.3593 - val_loss: 3577.6780 - val_mae: 34.1909\n",
      "Epoch 166/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 41002.6602 - mae: 60.7398 - val_loss: 3617.5137 - val_mae: 37.3925\n",
      "Epoch 167/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 40680.6641 - mae: 61.8653 - val_loss: 3689.6594 - val_mae: 39.8599\n",
      "Epoch 168/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 41044.8711 - mae: 61.4007 - val_loss: 3604.0447 - val_mae: 37.2995\n",
      "Epoch 169/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 40557.8867 - mae: 59.8782 - val_loss: 3707.9980 - val_mae: 40.7177\n",
      "Epoch 170/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 40420.2188 - mae: 63.4659 - val_loss: 3588.6558 - val_mae: 35.2178\n",
      "Epoch 171/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 40888.6562 - mae: 59.5523 - val_loss: 3664.0085 - val_mae: 39.1209\n",
      "Epoch 172/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 40672.5781 - mae: 61.3709 - val_loss: 3567.2798 - val_mae: 34.7807\n",
      "Epoch 173/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 40922.7188 - mae: 59.1826 - val_loss: 3677.1726 - val_mae: 38.2091\n",
      "Epoch 174/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 40722.5195 - mae: 61.9768 - val_loss: 3672.8826 - val_mae: 37.8914\n",
      "Epoch 175/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 40800.0078 - mae: 60.1340 - val_loss: 3669.1484 - val_mae: 39.4040\n",
      "Epoch 176/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 40363.9297 - mae: 63.7114 - val_loss: 3629.2451 - val_mae: 39.6568\n",
      "Epoch 177/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 40567.6602 - mae: 61.8610 - val_loss: 3696.4177 - val_mae: 40.0560\n",
      "Epoch 178/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 40309.0469 - mae: 63.6391 - val_loss: 3527.6050 - val_mae: 34.8747\n",
      "Epoch 179/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 40632.8438 - mae: 61.1098 - val_loss: 3593.3713 - val_mae: 38.5475\n",
      "Epoch 180/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 40190.4062 - mae: 63.3463 - val_loss: 3630.6255 - val_mae: 39.3868\n",
      "Epoch 181/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 41267.4375 - mae: 61.9656 - val_loss: 3583.4553 - val_mae: 37.6014\n",
      "Epoch 182/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 40449.4805 - mae: 62.4842 - val_loss: 3723.5112 - val_mae: 39.4353\n",
      "Epoch 183/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 40641.7109 - mae: 62.2280 - val_loss: 3562.5295 - val_mae: 36.5605\n",
      "Epoch 184/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 40355.6953 - mae: 63.5006 - val_loss: 3565.2891 - val_mae: 36.6013\n",
      "Epoch 185/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 40440.2031 - mae: 62.7922 - val_loss: 3738.6252 - val_mae: 39.5703\n",
      "Epoch 186/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 40527.9844 - mae: 60.6578 - val_loss: 3821.2422 - val_mae: 40.4352\n",
      "Epoch 187/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 42069.9570 - mae: 62.2306 - val_loss: 3459.4575 - val_mae: 34.8486\n",
      "Epoch 188/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 40539.5703 - mae: 61.9523 - val_loss: 3620.2751 - val_mae: 37.9924\n",
      "Epoch 189/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 40324.8789 - mae: 62.3837 - val_loss: 3635.7263 - val_mae: 37.6739\n",
      "Epoch 190/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 39741.4062 - mae: 62.1751 - val_loss: 3907.5422 - val_mae: 41.3261\n",
      "Epoch 191/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 39797.2031 - mae: 66.2664 - val_loss: 3845.1042 - val_mae: 39.8507\n",
      "Epoch 192/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 39688.7891 - mae: 63.3764 - val_loss: 3604.4404 - val_mae: 36.6821\n",
      "Epoch 193/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 40998.8164 - mae: 59.7235 - val_loss: 3688.1106 - val_mae: 38.3058\n",
      "Epoch 194/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 39968.3906 - mae: 62.8490 - val_loss: 3587.4609 - val_mae: 35.8346\n",
      "Epoch 195/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 40238.9492 - mae: 62.3742 - val_loss: 3736.9006 - val_mae: 39.3243\n",
      "Epoch 196/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 40054.3906 - mae: 62.4001 - val_loss: 3543.0156 - val_mae: 34.9117\n",
      "Epoch 197/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 41343.8281 - mae: 59.8492 - val_loss: 3521.5652 - val_mae: 35.5888\n",
      "Epoch 198/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 41307.5273 - mae: 59.8666 - val_loss: 3444.5479 - val_mae: 36.7176\n",
      "Epoch 199/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 39784.5117 - mae: 64.9331 - val_loss: 3537.9890 - val_mae: 36.8991\n",
      "Epoch 200/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 40268.9023 - mae: 62.8086 - val_loss: 3824.9155 - val_mae: 40.1036\n",
      "Epoch 201/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 39997.8555 - mae: 64.5512 - val_loss: 3647.3696 - val_mae: 37.6636\n",
      "Epoch 202/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 40030.1328 - mae: 62.4382 - val_loss: 3976.7148 - val_mae: 41.9957\n",
      "Epoch 203/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 39534.4258 - mae: 65.9259 - val_loss: 3617.0256 - val_mae: 37.2615\n",
      "Epoch 204/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 41391.6562 - mae: 59.6595 - val_loss: 3507.2095 - val_mae: 37.1318\n",
      "Epoch 205/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 40359.2539 - mae: 62.0144 - val_loss: 3610.8989 - val_mae: 38.2393\n",
      "Epoch 206/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 39782.1953 - mae: 64.7157 - val_loss: 3489.2498 - val_mae: 37.1438\n",
      "Epoch 207/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 40565.5000 - mae: 62.8974 - val_loss: 3571.2546 - val_mae: 37.6314\n",
      "Epoch 208/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 41413.1250 - mae: 61.7973 - val_loss: 3529.8652 - val_mae: 37.4965\n",
      "Epoch 209/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 40942.1914 - mae: 61.6491 - val_loss: 3663.9397 - val_mae: 39.1096\n",
      "Epoch 210/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 39602.0547 - mae: 64.8498 - val_loss: 3454.9929 - val_mae: 34.2684\n",
      "Epoch 211/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 40688.2188 - mae: 60.1641 - val_loss: 3757.7415 - val_mae: 38.9263\n",
      "Epoch 212/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 40111.4570 - mae: 62.5200 - val_loss: 3756.8357 - val_mae: 39.6662\n",
      "Epoch 213/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 39356.8438 - mae: 64.7073 - val_loss: 3515.4788 - val_mae: 36.1811\n",
      "Epoch 214/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 40333.5039 - mae: 62.4627 - val_loss: 3616.9133 - val_mae: 37.4656\n",
      "Epoch 215/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 39735.1680 - mae: 63.8821 - val_loss: 3662.5618 - val_mae: 37.8493\n",
      "Epoch 216/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 40399.2305 - mae: 61.5942 - val_loss: 3551.3516 - val_mae: 36.1812\n",
      "Epoch 217/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 39826.0625 - mae: 62.3376 - val_loss: 3661.2593 - val_mae: 38.0122\n",
      "Epoch 218/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 40190.7734 - mae: 62.2997 - val_loss: 3769.4011 - val_mae: 39.5567\n",
      "Epoch 219/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 40364.0430 - mae: 62.6670 - val_loss: 3681.4561 - val_mae: 38.4223\n",
      "Epoch 220/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 39661.4531 - mae: 63.0595 - val_loss: 3478.8445 - val_mae: 34.1893\n",
      "Epoch 221/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 40314.8750 - mae: 62.4247 - val_loss: 3703.7263 - val_mae: 38.6560\n",
      "Epoch 222/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 39777.4062 - mae: 62.2369 - val_loss: 3573.4763 - val_mae: 37.0609\n",
      "Epoch 223/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 40094.1523 - mae: 62.0995 - val_loss: 3797.3538 - val_mae: 40.3370\n",
      "Epoch 224/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 39749.0078 - mae: 63.5145 - val_loss: 3729.2302 - val_mae: 39.3304\n",
      "Epoch 225/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 39526.5820 - mae: 62.1934 - val_loss: 4026.4026 - val_mae: 42.5388\n",
      "Epoch 226/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 39348.0430 - mae: 66.9619 - val_loss: 3847.7532 - val_mae: 40.0063\n",
      "Epoch 227/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 39915.2461 - mae: 62.9920 - val_loss: 3638.9487 - val_mae: 37.7362\n",
      "Epoch 228/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 39788.2500 - mae: 62.4485 - val_loss: 4023.7776 - val_mae: 42.1144\n",
      "Epoch 229/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 39187.6523 - mae: 65.1834 - val_loss: 3516.8298 - val_mae: 35.1323\n",
      "Epoch 230/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 39886.5547 - mae: 61.8373 - val_loss: 4122.2891 - val_mae: 42.4506\n",
      "Epoch 231/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 38984.1484 - mae: 65.5601 - val_loss: 3523.8433 - val_mae: 35.4490\n",
      "Epoch 232/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 40569.5977 - mae: 60.1168 - val_loss: 3810.5620 - val_mae: 39.2899\n",
      "Epoch 233/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 39822.1133 - mae: 62.0818 - val_loss: 3761.7764 - val_mae: 38.8757\n",
      "Epoch 234/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 40736.0352 - mae: 62.1132 - val_loss: 3703.9424 - val_mae: 38.1665\n",
      "Epoch 235/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 40187.9805 - mae: 60.6724 - val_loss: 4067.0515 - val_mae: 41.6554\n",
      "Epoch 236/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 39848.1641 - mae: 63.2852 - val_loss: 3766.4058 - val_mae: 38.8198\n",
      "Epoch 237/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 40198.1367 - mae: 60.9809 - val_loss: 3792.9958 - val_mae: 39.2818\n",
      "Epoch 238/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 39607.2695 - mae: 61.9663 - val_loss: 3822.1040 - val_mae: 39.7096\n",
      "Epoch 239/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 39729.4648 - mae: 62.3815 - val_loss: 3734.8335 - val_mae: 38.2744\n",
      "Epoch 240/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 39843.9805 - mae: 61.5183 - val_loss: 3726.4409 - val_mae: 38.0020\n",
      "Epoch 241/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 39547.3789 - mae: 61.6003 - val_loss: 3685.4788 - val_mae: 37.7193\n",
      "Epoch 242/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 39066.6445 - mae: 63.8776 - val_loss: 3572.1367 - val_mae: 35.5786\n",
      "Epoch 243/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 40711.0586 - mae: 60.5813 - val_loss: 3682.8691 - val_mae: 37.6921\n",
      "Epoch 244/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 39722.6211 - mae: 61.3116 - val_loss: 3580.7808 - val_mae: 36.5065\n",
      "Epoch 245/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 39643.8359 - mae: 60.7497 - val_loss: 3800.6453 - val_mae: 39.1274\n",
      "Epoch 246/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 39359.9453 - mae: 62.5348 - val_loss: 3603.5325 - val_mae: 36.7084\n",
      "Epoch 247/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 39541.8555 - mae: 61.7585 - val_loss: 3900.6514 - val_mae: 40.0513\n",
      "Epoch 248/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 39126.0859 - mae: 64.3207 - val_loss: 3808.3193 - val_mae: 39.2923\n",
      "Epoch 249/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 39332.5508 - mae: 63.2415 - val_loss: 3791.9741 - val_mae: 39.6341\n",
      "Epoch 250/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 41039.8125 - mae: 60.5452 - val_loss: 3601.7466 - val_mae: 36.8709\n",
      "Epoch 251/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 39324.3047 - mae: 61.5250 - val_loss: 3728.7424 - val_mae: 39.2126\n",
      "Epoch 252/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 38977.8867 - mae: 64.4038 - val_loss: 3510.9341 - val_mae: 34.6521\n",
      "Epoch 253/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 39858.5586 - mae: 61.6704 - val_loss: 3624.6819 - val_mae: 36.8653\n",
      "Epoch 254/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 39009.8359 - mae: 61.6626 - val_loss: 3477.2844 - val_mae: 34.0370\n",
      "Epoch 255/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 39391.0938 - mae: 60.9941 - val_loss: 3787.0232 - val_mae: 38.8505\n",
      "Epoch 256/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 39291.8945 - mae: 61.5040 - val_loss: 3792.8269 - val_mae: 39.1242\n",
      "Epoch 257/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 39172.8086 - mae: 62.8826 - val_loss: 3693.7505 - val_mae: 38.2096\n",
      "Epoch 258/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 38849.1523 - mae: 62.6041 - val_loss: 3628.4509 - val_mae: 37.1007\n",
      "Epoch 259/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 38367.1797 - mae: 61.2692 - val_loss: 3538.2261 - val_mae: 33.9820\n",
      "Epoch 260/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 39545.6484 - mae: 60.6783 - val_loss: 3503.7141 - val_mae: 33.8030\n",
      "Epoch 261/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 39168.8750 - mae: 59.0909 - val_loss: 3565.2275 - val_mae: 35.9812\n",
      "Epoch 262/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 39975.3242 - mae: 62.2407 - val_loss: 3762.2222 - val_mae: 38.5633\n",
      "Epoch 263/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 39657.8750 - mae: 61.8971 - val_loss: 3757.2107 - val_mae: 38.6537\n",
      "Epoch 264/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 38367.9102 - mae: 62.1847 - val_loss: 3455.4724 - val_mae: 33.1189\n",
      "Epoch 265/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 39353.9922 - mae: 61.3121 - val_loss: 3447.8789 - val_mae: 33.8797\n",
      "Epoch 266/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 39493.1250 - mae: 61.1878 - val_loss: 3707.9050 - val_mae: 38.2315\n",
      "Epoch 267/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 40050.5273 - mae: 59.7091 - val_loss: 3685.5962 - val_mae: 38.2698\n",
      "Epoch 268/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 38124.0117 - mae: 63.2392 - val_loss: 3469.0457 - val_mae: 33.2896\n",
      "Epoch 269/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 39418.2695 - mae: 60.8778 - val_loss: 3547.5410 - val_mae: 35.8180\n",
      "Epoch 270/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 38875.5820 - mae: 60.6800 - val_loss: 3672.3357 - val_mae: 37.7375\n",
      "Epoch 271/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 38565.4414 - mae: 62.3613 - val_loss: 3952.0527 - val_mae: 41.0659\n",
      "Epoch 272/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 39587.4922 - mae: 60.2667 - val_loss: 3605.9749 - val_mae: 36.3072\n",
      "Epoch 273/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 38335.0039 - mae: 60.3617 - val_loss: 3590.1169 - val_mae: 35.1030\n",
      "Epoch 274/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 38812.6055 - mae: 58.7176 - val_loss: 3881.7246 - val_mae: 39.0984\n",
      "Epoch 275/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 38285.6719 - mae: 62.9798 - val_loss: 3579.3447 - val_mae: 35.6245\n",
      "Epoch 276/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 38725.7188 - mae: 60.5257 - val_loss: 3541.6748 - val_mae: 34.7388\n",
      "Epoch 277/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 39762.0547 - mae: 60.3208 - val_loss: 3771.2500 - val_mae: 38.3796\n",
      "Epoch 278/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 38796.1523 - mae: 59.9411 - val_loss: 3831.6204 - val_mae: 39.1894\n",
      "Epoch 279/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 38355.2578 - mae: 61.0139 - val_loss: 3544.9702 - val_mae: 33.4193\n",
      "Epoch 280/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 38695.1289 - mae: 59.3357 - val_loss: 3524.9380 - val_mae: 33.7162\n",
      "Epoch 281/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 39274.5703 - mae: 60.3675 - val_loss: 3666.7146 - val_mae: 36.8059\n",
      "Epoch 282/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 38410.5859 - mae: 59.4869 - val_loss: 3573.8796 - val_mae: 33.7521\n",
      "Epoch 283/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 39406.7344 - mae: 58.1811 - val_loss: 3625.9890 - val_mae: 35.7654\n",
      "Epoch 284/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 38485.5938 - mae: 61.2789 - val_loss: 3654.4155 - val_mae: 36.3956\n",
      "Epoch 285/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 38907.0898 - mae: 59.6714 - val_loss: 4026.2087 - val_mae: 40.6254\n",
      "Epoch 286/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 38460.1133 - mae: 62.8682 - val_loss: 3591.8169 - val_mae: 35.1065\n",
      "Epoch 287/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 38874.2812 - mae: 59.5827 - val_loss: 3684.3276 - val_mae: 37.5426\n",
      "Epoch 288/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 38076.5859 - mae: 60.8578 - val_loss: 3577.5051 - val_mae: 35.6400\n",
      "Epoch 289/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 37778.2070 - mae: 60.9531 - val_loss: 3540.5027 - val_mae: 34.7749\n",
      "Epoch 290/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 38611.6094 - mae: 60.7469 - val_loss: 3695.8264 - val_mae: 37.8205\n",
      "Epoch 291/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 38125.2188 - mae: 61.8458 - val_loss: 3682.4531 - val_mae: 37.5960\n",
      "Epoch 292/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 38059.5195 - mae: 61.1529 - val_loss: 3850.8879 - val_mae: 39.6473\n",
      "Epoch 293/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 37531.3945 - mae: 63.8490 - val_loss: 3649.4270 - val_mae: 36.7805\n",
      "Epoch 294/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 38379.5195 - mae: 60.9727 - val_loss: 3625.5793 - val_mae: 36.7719\n",
      "Epoch 295/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 37838.1797 - mae: 61.1715 - val_loss: 3664.6953 - val_mae: 37.1990\n",
      "Epoch 296/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 38099.1875 - mae: 60.1692 - val_loss: 3534.4348 - val_mae: 34.7556\n",
      "Epoch 297/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 38070.2617 - mae: 60.0640 - val_loss: 3673.8318 - val_mae: 36.9212\n",
      "Epoch 298/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 38145.9375 - mae: 59.6166 - val_loss: 3941.9121 - val_mae: 39.8976\n",
      "Epoch 299/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 38290.1367 - mae: 60.4529 - val_loss: 3818.2292 - val_mae: 38.7817\n",
      "Epoch 300/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 38060.5195 - mae: 60.7790 - val_loss: 3783.5952 - val_mae: 38.3611\n",
      "Epoch 301/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 38598.5938 - mae: 59.9671 - val_loss: 3602.4927 - val_mae: 36.1812\n",
      "Epoch 302/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 37899.4805 - mae: 61.7119 - val_loss: 3663.3428 - val_mae: 37.0286\n",
      "Epoch 303/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 37929.2656 - mae: 60.5787 - val_loss: 3745.0879 - val_mae: 38.3061\n",
      "Epoch 304/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 37374.7461 - mae: 60.4818 - val_loss: 3679.3533 - val_mae: 37.4650\n",
      "Epoch 305/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 38917.6289 - mae: 59.6373 - val_loss: 3570.0117 - val_mae: 36.4881\n",
      "Epoch 306/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 37882.6523 - mae: 60.5612 - val_loss: 3644.3081 - val_mae: 37.5624\n",
      "Epoch 307/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 37435.5117 - mae: 58.3748 - val_loss: 3782.1052 - val_mae: 39.9491\n",
      "Epoch 308/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 37280.0391 - mae: 62.0484 - val_loss: 3738.5454 - val_mae: 37.6806\n",
      "Epoch 309/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 37451.4570 - mae: 60.1469 - val_loss: 3794.4844 - val_mae: 38.7167\n",
      "Epoch 310/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 37277.1172 - mae: 61.1078 - val_loss: 3681.0081 - val_mae: 37.3375\n",
      "Epoch 311/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 37193.2695 - mae: 60.4162 - val_loss: 3611.0718 - val_mae: 35.2921\n",
      "Epoch 312/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 38397.7695 - mae: 58.1866 - val_loss: 3661.6484 - val_mae: 37.0624\n",
      "Epoch 313/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 37293.7422 - mae: 61.8026 - val_loss: 3646.7141 - val_mae: 37.3465\n",
      "Epoch 314/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 36960.4062 - mae: 62.0132 - val_loss: 3646.8262 - val_mae: 37.3320\n",
      "Epoch 315/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 37043.1211 - mae: 60.6694 - val_loss: 3609.2500 - val_mae: 36.6721\n",
      "Epoch 316/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 37090.6172 - mae: 58.5764 - val_loss: 3650.7085 - val_mae: 37.0633\n",
      "Epoch 317/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 37011.3945 - mae: 60.1428 - val_loss: 3571.1821 - val_mae: 33.7914\n",
      "Epoch 318/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 38621.6680 - mae: 58.4424 - val_loss: 3704.2725 - val_mae: 37.9433\n",
      "Epoch 319/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 37852.8203 - mae: 61.9023 - val_loss: 3578.0542 - val_mae: 35.1015\n",
      "Epoch 320/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 36689.3125 - mae: 58.5750 - val_loss: 3851.0483 - val_mae: 39.1761\n",
      "Epoch 321/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 36216.1406 - mae: 61.4575 - val_loss: 3561.1733 - val_mae: 33.5891\n",
      "Epoch 322/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 37419.4844 - mae: 58.5564 - val_loss: 3823.7114 - val_mae: 38.8969\n",
      "Epoch 323/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 36536.4023 - mae: 60.3295 - val_loss: 3955.8030 - val_mae: 40.2001\n",
      "Epoch 324/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 36695.8867 - mae: 62.0463 - val_loss: 3711.0735 - val_mae: 37.5366\n",
      "Epoch 325/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 37401.9805 - mae: 58.5673 - val_loss: 3850.0955 - val_mae: 38.5760\n",
      "Epoch 326/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 36938.0195 - mae: 60.1944 - val_loss: 3595.4146 - val_mae: 34.3947\n",
      "Epoch 327/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 36807.9609 - mae: 58.5336 - val_loss: 3916.0698 - val_mae: 40.5214\n",
      "Epoch 328/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 36827.2227 - mae: 60.3782 - val_loss: 3622.4170 - val_mae: 35.5285\n",
      "Epoch 329/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 37216.8477 - mae: 60.5138 - val_loss: 3659.5615 - val_mae: 36.0822\n",
      "Epoch 330/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 36827.7656 - mae: 60.6806 - val_loss: 3613.4939 - val_mae: 36.1532\n",
      "Epoch 331/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 37413.6602 - mae: 59.8602 - val_loss: 3616.0120 - val_mae: 36.0174\n",
      "Epoch 332/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 36875.6406 - mae: 58.8054 - val_loss: 3673.7024 - val_mae: 37.1631\n",
      "Epoch 333/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 36227.2266 - mae: 59.8526 - val_loss: 3666.2085 - val_mae: 36.6331\n",
      "Epoch 334/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 36464.1289 - mae: 60.9972 - val_loss: 4012.4404 - val_mae: 40.7015\n",
      "Epoch 335/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 36814.1172 - mae: 60.7965 - val_loss: 3685.8850 - val_mae: 37.1310\n",
      "Epoch 336/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 36622.7266 - mae: 58.2710 - val_loss: 3692.2830 - val_mae: 37.0590\n",
      "Epoch 337/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 36715.2734 - mae: 58.9395 - val_loss: 3833.4155 - val_mae: 39.0139\n",
      "Epoch 338/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 36585.6016 - mae: 59.6331 - val_loss: 3710.6611 - val_mae: 37.4653\n",
      "Epoch 339/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 36529.2109 - mae: 58.8016 - val_loss: 3579.0559 - val_mae: 34.6046\n",
      "Epoch 340/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 36802.4961 - mae: 58.6804 - val_loss: 3842.0254 - val_mae: 39.1564\n",
      "Epoch 341/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 36419.7227 - mae: 59.6196 - val_loss: 3992.8701 - val_mae: 41.6156\n",
      "Epoch 342/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 35608.8750 - mae: 60.9313 - val_loss: 3533.2151 - val_mae: 34.7647\n",
      "Epoch 343/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 36438.9219 - mae: 57.6846 - val_loss: 3599.8389 - val_mae: 36.4535\n",
      "Epoch 344/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 36693.3242 - mae: 59.5319 - val_loss: 3599.1401 - val_mae: 36.9092\n",
      "Epoch 345/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 35812.2812 - mae: 59.2937 - val_loss: 3687.6450 - val_mae: 39.9931\n",
      "Epoch 346/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 36896.7461 - mae: 62.3978 - val_loss: 3677.7307 - val_mae: 37.2228\n",
      "Epoch 347/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 36323.9688 - mae: 58.4196 - val_loss: 3636.2114 - val_mae: 35.8138\n",
      "Epoch 348/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 35926.2656 - mae: 61.0999 - val_loss: 3660.1892 - val_mae: 36.7580\n",
      "Epoch 349/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 35457.6211 - mae: 60.8372 - val_loss: 3618.7974 - val_mae: 34.3974\n",
      "Epoch 350/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 36665.8125 - mae: 57.7545 - val_loss: 3644.3438 - val_mae: 35.9774\n",
      "Epoch 351/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 36162.3438 - mae: 58.2656 - val_loss: 3682.1597 - val_mae: 36.3420\n",
      "Epoch 352/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 35731.8203 - mae: 57.6525 - val_loss: 3658.0864 - val_mae: 35.4061\n",
      "Epoch 353/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 35912.0977 - mae: 58.8121 - val_loss: 3684.7295 - val_mae: 34.4781\n",
      "Epoch 354/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 35912.7539 - mae: 59.8781 - val_loss: 3945.3518 - val_mae: 39.8196\n",
      "Epoch 355/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 35710.6055 - mae: 59.9307 - val_loss: 3822.0496 - val_mae: 38.1829\n",
      "Epoch 356/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 35451.3125 - mae: 58.6699 - val_loss: 3625.0679 - val_mae: 34.1996\n",
      "Epoch 357/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 36163.3477 - mae: 56.9324 - val_loss: 3855.0134 - val_mae: 38.8125\n",
      "Epoch 358/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 35329.7383 - mae: 56.6933 - val_loss: 3919.7231 - val_mae: 41.0339\n",
      "Epoch 359/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 36150.2539 - mae: 59.6456 - val_loss: 3630.3335 - val_mae: 36.4198\n",
      "Epoch 360/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 38518.0312 - mae: 58.2946 - val_loss: 3755.4041 - val_mae: 38.5520\n",
      "Epoch 361/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 35723.1797 - mae: 58.5283 - val_loss: 3752.6426 - val_mae: 39.2287\n",
      "Epoch 362/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 35730.9023 - mae: 60.6171 - val_loss: 3829.8879 - val_mae: 40.1694\n",
      "Epoch 363/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 35643.2109 - mae: 60.4319 - val_loss: 3704.1677 - val_mae: 36.8224\n",
      "Epoch 364/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 36048.5547 - mae: 57.6478 - val_loss: 4043.3933 - val_mae: 40.8228\n",
      "Epoch 365/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 35786.1172 - mae: 58.9935 - val_loss: 4120.5337 - val_mae: 41.7186\n",
      "Epoch 366/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 35403.8047 - mae: 60.8032 - val_loss: 3770.8914 - val_mae: 37.1497\n",
      "Epoch 367/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 36354.7031 - mae: 57.6922 - val_loss: 3743.6306 - val_mae: 37.2074\n",
      "Epoch 368/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 35790.9336 - mae: 59.6254 - val_loss: 3795.7197 - val_mae: 38.7070\n",
      "Epoch 369/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 35496.7578 - mae: 58.7900 - val_loss: 3884.5166 - val_mae: 40.3595\n",
      "Epoch 370/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 35586.2930 - mae: 58.8446 - val_loss: 3704.0017 - val_mae: 37.4764\n",
      "Epoch 371/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 35656.4492 - mae: 59.8575 - val_loss: 3782.8655 - val_mae: 38.3590\n",
      "Epoch 372/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 35681.8203 - mae: 58.0543 - val_loss: 3725.5388 - val_mae: 37.7141\n",
      "Epoch 373/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 36021.7695 - mae: 57.5709 - val_loss: 3683.2422 - val_mae: 37.0217\n",
      "Epoch 374/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 34934.1172 - mae: 59.4030 - val_loss: 3627.4109 - val_mae: 35.5038\n",
      "Epoch 375/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 35153.4492 - mae: 58.9471 - val_loss: 3628.1624 - val_mae: 35.8289\n",
      "Epoch 376/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 35359.3125 - mae: 58.0647 - val_loss: 3801.4861 - val_mae: 39.1654\n",
      "Epoch 377/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 35525.2148 - mae: 57.8511 - val_loss: 3636.3889 - val_mae: 37.0358\n",
      "Epoch 378/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 35278.5938 - mae: 57.4858 - val_loss: 3940.7947 - val_mae: 40.2985\n",
      "Epoch 379/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 34963.5391 - mae: 58.7795 - val_loss: 3909.4475 - val_mae: 40.3377\n",
      "Epoch 380/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 34927.6523 - mae: 61.0941 - val_loss: 3650.7593 - val_mae: 34.6777\n",
      "Epoch 381/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 35452.3359 - mae: 56.9650 - val_loss: 3799.2097 - val_mae: 38.8763\n",
      "Epoch 382/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 34877.7539 - mae: 59.8228 - val_loss: 3652.0767 - val_mae: 35.3381\n",
      "Epoch 383/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 35615.5352 - mae: 57.7847 - val_loss: 3609.6445 - val_mae: 36.2911\n",
      "Epoch 384/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 35385.0312 - mae: 57.4083 - val_loss: 3829.3608 - val_mae: 38.9698\n",
      "Epoch 385/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 34947.1016 - mae: 57.7268 - val_loss: 3758.9888 - val_mae: 37.5256\n",
      "Epoch 386/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 34877.9883 - mae: 58.3259 - val_loss: 3716.6667 - val_mae: 36.4616\n",
      "Epoch 387/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 35226.8281 - mae: 56.7700 - val_loss: 3831.2288 - val_mae: 38.8626\n",
      "Epoch 388/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 35061.1445 - mae: 58.2860 - val_loss: 3775.1501 - val_mae: 38.6413\n",
      "Epoch 389/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 34904.4414 - mae: 60.4509 - val_loss: 3778.5688 - val_mae: 39.0863\n",
      "Epoch 390/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 35600.8203 - mae: 58.4428 - val_loss: 4303.0977 - val_mae: 43.3981\n",
      "Epoch 391/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 34584.6875 - mae: 59.4804 - val_loss: 3683.1443 - val_mae: 37.2208\n",
      "Epoch 392/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 34538.0469 - mae: 58.1659 - val_loss: 3485.7832 - val_mae: 34.4578\n",
      "Epoch 393/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 34738.6875 - mae: 57.8750 - val_loss: 3772.1025 - val_mae: 38.1618\n",
      "Epoch 394/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 34998.2773 - mae: 57.7852 - val_loss: 3665.6208 - val_mae: 37.3171\n",
      "Epoch 395/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 34504.8594 - mae: 58.1836 - val_loss: 3622.5352 - val_mae: 36.9946\n",
      "Epoch 396/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 34391.6367 - mae: 58.0249 - val_loss: 4009.2629 - val_mae: 42.0348\n",
      "Epoch 397/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 34278.9180 - mae: 58.9933 - val_loss: 3638.1375 - val_mae: 37.7649\n",
      "Epoch 398/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 35856.4883 - mae: 57.6345 - val_loss: 3459.3918 - val_mae: 35.0759\n",
      "Epoch 399/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 34210.5469 - mae: 57.1017 - val_loss: 3369.2476 - val_mae: 33.6461\n",
      "Epoch 400/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 34915.7891 - mae: 62.8046 - val_loss: 3464.0569 - val_mae: 34.0177\n",
      "Epoch 401/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 36340.0117 - mae: 57.3040 - val_loss: 3417.0127 - val_mae: 33.2955\n",
      "Epoch 402/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 34238.0273 - mae: 57.9034 - val_loss: 3602.9773 - val_mae: 36.2770\n",
      "Epoch 403/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 39508.2617 - mae: 57.9026 - val_loss: 3906.3049 - val_mae: 40.8706\n",
      "Epoch 404/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 34273.3281 - mae: 60.0640 - val_loss: 3493.1814 - val_mae: 35.5730\n",
      "Epoch 405/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 34299.8633 - mae: 58.3919 - val_loss: 3734.0200 - val_mae: 39.3338\n",
      "Epoch 406/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 34060.4883 - mae: 57.5446 - val_loss: 3649.5750 - val_mae: 38.3922\n",
      "Epoch 407/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 33711.7109 - mae: 60.5962 - val_loss: 3491.4983 - val_mae: 34.9108\n",
      "Epoch 408/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 33982.0781 - mae: 57.8394 - val_loss: 3499.6646 - val_mae: 36.0773\n",
      "Epoch 409/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 33985.0977 - mae: 58.0917 - val_loss: 3598.0002 - val_mae: 37.4023\n",
      "Epoch 410/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 33217.7227 - mae: 57.5791 - val_loss: 3570.8799 - val_mae: 39.5194\n",
      "Epoch 411/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 33648.8633 - mae: 60.9768 - val_loss: 3638.4724 - val_mae: 38.2789\n",
      "Epoch 412/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 33620.3203 - mae: 60.9489 - val_loss: 3508.3083 - val_mae: 37.5758\n",
      "Epoch 413/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 33852.3359 - mae: 59.6454 - val_loss: 3509.1145 - val_mae: 35.4245\n",
      "Epoch 414/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 33868.4844 - mae: 59.4886 - val_loss: 3472.5251 - val_mae: 35.9676\n",
      "Epoch 415/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 33564.4922 - mae: 57.4480 - val_loss: 3641.0361 - val_mae: 37.8449\n",
      "Epoch 416/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 34160.5547 - mae: 57.1770 - val_loss: 3663.3123 - val_mae: 38.4580\n",
      "Epoch 417/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 33419.7344 - mae: 60.8340 - val_loss: 3482.8623 - val_mae: 34.5841\n",
      "Epoch 418/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 34270.4375 - mae: 57.4774 - val_loss: 3647.1660 - val_mae: 38.8577\n",
      "Epoch 419/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 33591.1875 - mae: 58.7041 - val_loss: 3424.6997 - val_mae: 33.7246\n",
      "Epoch 420/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 36829.0781 - mae: 57.5530 - val_loss: 3390.3640 - val_mae: 35.1221\n",
      "Epoch 421/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 35147.8516 - mae: 56.9170 - val_loss: 3595.4312 - val_mae: 38.0212\n",
      "Epoch 422/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 33838.8633 - mae: 58.4144 - val_loss: 3493.8018 - val_mae: 37.0212\n",
      "Epoch 423/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 33847.7305 - mae: 58.1988 - val_loss: 3503.5315 - val_mae: 36.8278\n",
      "Epoch 424/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 33496.1602 - mae: 57.0788 - val_loss: 3499.0291 - val_mae: 37.3874\n",
      "Epoch 425/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 33413.6523 - mae: 61.4488 - val_loss: 3419.7051 - val_mae: 36.0886\n",
      "Epoch 426/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 32835.6562 - mae: 60.6653 - val_loss: 3776.4946 - val_mae: 39.4954\n",
      "Epoch 427/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 33065.7188 - mae: 55.5993 - val_loss: 3807.2375 - val_mae: 41.4036\n",
      "Epoch 428/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 32506.4141 - mae: 59.9014 - val_loss: 3535.3506 - val_mae: 36.7982\n",
      "Epoch 429/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 33240.1992 - mae: 57.8832 - val_loss: 3529.0693 - val_mae: 36.2673\n",
      "Epoch 430/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 33304.4531 - mae: 57.3498 - val_loss: 3486.6106 - val_mae: 36.8016\n",
      "Epoch 431/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 32711.9238 - mae: 60.1096 - val_loss: 3464.8892 - val_mae: 36.4899\n",
      "Epoch 432/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 32898.6523 - mae: 61.4097 - val_loss: 3491.9119 - val_mae: 36.2506\n",
      "Epoch 433/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 32788.7578 - mae: 58.3558 - val_loss: 3681.0623 - val_mae: 40.4766\n",
      "Epoch 434/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 32394.8848 - mae: 58.9834 - val_loss: 3523.8794 - val_mae: 36.2453\n",
      "Epoch 435/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 33321.4492 - mae: 56.6747 - val_loss: 3455.8132 - val_mae: 35.9075\n",
      "Epoch 436/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 33160.1094 - mae: 58.2447 - val_loss: 3493.5349 - val_mae: 36.6054\n",
      "Epoch 437/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 32931.3789 - mae: 57.9007 - val_loss: 3481.3032 - val_mae: 36.1971\n",
      "Epoch 438/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 33168.7148 - mae: 56.0136 - val_loss: 3585.7888 - val_mae: 37.7059\n",
      "Epoch 439/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 32613.3848 - mae: 56.2985 - val_loss: 3598.4924 - val_mae: 35.5562\n",
      "Epoch 440/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 33002.0742 - mae: 55.5543 - val_loss: 3379.0693 - val_mae: 35.4871\n",
      "Epoch 441/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 31937.6562 - mae: 58.4213 - val_loss: 3472.4336 - val_mae: 35.2539\n",
      "Epoch 442/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 33502.3945 - mae: 58.3357 - val_loss: 3890.6133 - val_mae: 40.8739\n",
      "Epoch 443/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 33020.9023 - mae: 61.3925 - val_loss: 3716.4863 - val_mae: 38.1011\n",
      "Epoch 444/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 32395.4219 - mae: 57.3559 - val_loss: 3754.0974 - val_mae: 41.1114\n",
      "Epoch 445/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 32215.5137 - mae: 60.8327 - val_loss: 3546.0562 - val_mae: 36.7636\n",
      "Epoch 446/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 32744.7930 - mae: 57.0432 - val_loss: 3669.7947 - val_mae: 38.3781\n",
      "Epoch 447/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 32684.4727 - mae: 52.7945 - val_loss: 3527.2766 - val_mae: 37.0345\n",
      "Epoch 448/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 32159.3613 - mae: 56.7570 - val_loss: 3615.9456 - val_mae: 37.4510\n",
      "Epoch 449/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 39431.8477 - mae: 58.5957 - val_loss: 3489.7041 - val_mae: 37.6828\n",
      "Epoch 450/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 32430.4023 - mae: 57.5702 - val_loss: 3604.5417 - val_mae: 38.4904\n",
      "Epoch 451/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 32976.6484 - mae: 56.9095 - val_loss: 3580.4204 - val_mae: 38.2108\n",
      "Epoch 452/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 35112.6680 - mae: 57.4709 - val_loss: 3261.4180 - val_mae: 34.6926\n",
      "Epoch 453/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 32286.6406 - mae: 59.0262 - val_loss: 3327.2915 - val_mae: 36.1958\n",
      "Epoch 454/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 33148.8672 - mae: 60.2367 - val_loss: 3357.9009 - val_mae: 35.3861\n",
      "Epoch 455/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 33136.5625 - mae: 58.1859 - val_loss: 3403.1890 - val_mae: 35.6152\n",
      "Epoch 456/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 33158.1406 - mae: 56.5256 - val_loss: 3512.6392 - val_mae: 37.2023\n",
      "Epoch 457/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 33309.2031 - mae: 57.2631 - val_loss: 3445.5930 - val_mae: 36.8730\n",
      "Epoch 458/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 32979.6133 - mae: 57.0546 - val_loss: 3484.9973 - val_mae: 37.2889\n",
      "Epoch 459/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 31965.1484 - mae: 59.4653 - val_loss: 3534.2104 - val_mae: 36.3586\n",
      "Epoch 460/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 32032.6582 - mae: 56.6430 - val_loss: 3574.6743 - val_mae: 37.8287\n",
      "Epoch 461/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 32176.3008 - mae: 56.6681 - val_loss: 3674.6931 - val_mae: 39.2633\n",
      "Epoch 462/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 32012.4473 - mae: 58.0877 - val_loss: 3528.6230 - val_mae: 36.8310\n",
      "Epoch 463/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 31978.7266 - mae: 57.2529 - val_loss: 3620.0457 - val_mae: 39.0691\n",
      "Epoch 464/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 31685.3828 - mae: 58.4353 - val_loss: 3516.2119 - val_mae: 37.6270\n",
      "Epoch 465/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 31449.4590 - mae: 60.2983 - val_loss: 3707.2930 - val_mae: 38.3103\n",
      "Epoch 466/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 31923.3984 - mae: 57.1927 - val_loss: 3524.5200 - val_mae: 37.2981\n",
      "Epoch 467/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 31876.7324 - mae: 57.8506 - val_loss: 3504.4329 - val_mae: 36.8882\n",
      "Epoch 468/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 31810.6270 - mae: 56.7359 - val_loss: 3527.8049 - val_mae: 36.9799\n",
      "Epoch 469/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 32056.3184 - mae: 55.6202 - val_loss: 3594.0566 - val_mae: 38.6698\n",
      "Epoch 470/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 31980.2441 - mae: 57.3516 - val_loss: 3439.0935 - val_mae: 36.5793\n",
      "Epoch 471/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 32971.3359 - mae: 55.8191 - val_loss: 3770.0857 - val_mae: 40.3493\n",
      "Epoch 472/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 31422.5898 - mae: 55.0735 - val_loss: 3471.4885 - val_mae: 37.2205\n",
      "Epoch 473/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 31485.1094 - mae: 59.2067 - val_loss: 3740.9360 - val_mae: 40.6252\n",
      "Epoch 474/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 31973.0059 - mae: 57.7589 - val_loss: 3612.9514 - val_mae: 38.9053\n",
      "Epoch 475/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 31008.9863 - mae: 59.6597 - val_loss: 3732.0176 - val_mae: 40.9704\n",
      "Epoch 476/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 31488.9238 - mae: 58.1906 - val_loss: 3542.3230 - val_mae: 38.2269\n",
      "Epoch 477/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 39551.5273 - mae: 60.0834 - val_loss: 3567.0579 - val_mae: 38.7441\n",
      "Epoch 478/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 37605.5430 - mae: 60.4057 - val_loss: 3638.5044 - val_mae: 39.3883\n",
      "Epoch 479/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 31641.9277 - mae: 57.5710 - val_loss: 3496.3831 - val_mae: 37.2168\n",
      "Epoch 480/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 31122.1016 - mae: 59.3067 - val_loss: 3720.6350 - val_mae: 39.5410\n",
      "Epoch 481/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 31403.5000 - mae: 56.7898 - val_loss: 3438.0435 - val_mae: 36.8028\n",
      "Epoch 482/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 31445.7031 - mae: 56.6706 - val_loss: 3548.8191 - val_mae: 37.9427\n",
      "Epoch 483/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 31316.7910 - mae: 55.2043 - val_loss: 3953.5278 - val_mae: 42.2335\n",
      "Epoch 484/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 31007.0176 - mae: 59.6905 - val_loss: 3762.7842 - val_mae: 40.3036\n",
      "Epoch 485/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 31099.0898 - mae: 59.3961 - val_loss: 3594.8613 - val_mae: 38.1785\n",
      "Epoch 486/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 31090.0918 - mae: 58.6906 - val_loss: 3535.2769 - val_mae: 37.2281\n",
      "Epoch 487/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 31332.1602 - mae: 53.8165 - val_loss: 3488.9609 - val_mae: 37.2794\n",
      "Epoch 488/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 30884.9688 - mae: 60.1843 - val_loss: 3579.5229 - val_mae: 37.1524\n",
      "Epoch 489/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 31317.8496 - mae: 56.0955 - val_loss: 3870.4866 - val_mae: 40.8949\n",
      "Epoch 490/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 30402.1113 - mae: 56.8901 - val_loss: 3700.9092 - val_mae: 39.7675\n",
      "Epoch 491/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 30803.1738 - mae: 56.7359 - val_loss: 3546.0725 - val_mae: 35.9709\n",
      "Epoch 492/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 32182.5195 - mae: 60.1402 - val_loss: 3457.4414 - val_mae: 36.2914\n",
      "Epoch 493/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 31184.6484 - mae: 58.8671 - val_loss: 3717.3533 - val_mae: 40.0186\n",
      "Epoch 494/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 30814.0664 - mae: 57.9887 - val_loss: 3556.8982 - val_mae: 37.3536\n",
      "Epoch 495/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 30914.8906 - mae: 57.0884 - val_loss: 3558.7539 - val_mae: 37.7516\n",
      "Epoch 496/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 30461.2344 - mae: 59.6434 - val_loss: 3557.6311 - val_mae: 37.7708\n",
      "Epoch 497/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 30511.3555 - mae: 57.7516 - val_loss: 3772.6677 - val_mae: 40.3628\n",
      "Epoch 498/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 30760.8008 - mae: 57.3417 - val_loss: 3735.6003 - val_mae: 40.2364\n",
      "Epoch 499/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 30454.7109 - mae: 56.6728 - val_loss: 3815.1748 - val_mae: 41.1204\n",
      "Epoch 500/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 30475.3242 - mae: 55.0804 - val_loss: 3571.4138 - val_mae: 38.9531\n",
      "Epoch 501/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 30367.4141 - mae: 57.6413 - val_loss: 3536.3379 - val_mae: 38.0809\n",
      "Epoch 502/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 30924.0195 - mae: 56.9413 - val_loss: 3812.7524 - val_mae: 42.1143\n",
      "Epoch 503/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 30129.0918 - mae: 56.1763 - val_loss: 3564.4487 - val_mae: 39.3723\n",
      "Epoch 504/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 30258.7812 - mae: 60.1354 - val_loss: 3465.1580 - val_mae: 36.7102\n",
      "Epoch 505/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 30211.6855 - mae: 58.1880 - val_loss: 3699.0483 - val_mae: 39.8339\n",
      "Epoch 506/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 31014.3516 - mae: 54.8560 - val_loss: 3455.9202 - val_mae: 36.5361\n",
      "Epoch 507/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 30283.6348 - mae: 54.1890 - val_loss: 3472.3604 - val_mae: 37.4979\n",
      "Epoch 508/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 30327.8613 - mae: 54.6532 - val_loss: 3404.3950 - val_mae: 36.0605\n",
      "Epoch 509/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 29977.7363 - mae: 59.1648 - val_loss: 3454.5051 - val_mae: 36.8906\n",
      "Epoch 510/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 31078.3848 - mae: 57.2220 - val_loss: 3310.7083 - val_mae: 36.6629\n",
      "Epoch 511/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 29531.8496 - mae: 59.1970 - val_loss: 3534.4414 - val_mae: 36.4631\n",
      "Epoch 512/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 31691.0645 - mae: 55.1361 - val_loss: 3430.1311 - val_mae: 36.9747\n",
      "Epoch 513/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 31020.1270 - mae: 57.8497 - val_loss: 3719.9041 - val_mae: 39.8982\n",
      "Epoch 514/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 30440.5352 - mae: 55.4563 - val_loss: 3509.7383 - val_mae: 38.2045\n",
      "Epoch 515/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 29602.2441 - mae: 58.4638 - val_loss: 3448.0317 - val_mae: 37.1868\n",
      "Epoch 516/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 30336.6855 - mae: 56.1724 - val_loss: 3572.1238 - val_mae: 38.9079\n",
      "Epoch 517/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 30191.3418 - mae: 58.1188 - val_loss: 3510.6191 - val_mae: 37.7672\n",
      "Epoch 518/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 30321.5820 - mae: 57.2678 - val_loss: 3938.6558 - val_mae: 42.0228\n",
      "Epoch 519/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 30201.9668 - mae: 57.6565 - val_loss: 3673.5151 - val_mae: 39.9343\n",
      "Epoch 520/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 30163.7832 - mae: 58.3176 - val_loss: 3448.8616 - val_mae: 37.1862\n",
      "Epoch 521/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 32815.2188 - mae: 58.2721 - val_loss: 3275.8816 - val_mae: 35.7290\n",
      "Epoch 522/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 30201.1113 - mae: 55.5805 - val_loss: 3730.7131 - val_mae: 40.1296\n",
      "Epoch 523/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 29803.0684 - mae: 53.9994 - val_loss: 3612.3984 - val_mae: 39.6529\n",
      "Epoch 524/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 29704.0469 - mae: 56.0186 - val_loss: 3506.6213 - val_mae: 36.7525\n",
      "Epoch 525/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 29836.4277 - mae: 54.6858 - val_loss: 3414.6733 - val_mae: 36.8854\n",
      "Epoch 526/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 29497.1582 - mae: 56.6314 - val_loss: 3483.3293 - val_mae: 38.0223\n",
      "Epoch 527/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 29744.3184 - mae: 56.0223 - val_loss: 3409.0769 - val_mae: 37.3296\n",
      "Epoch 528/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 29444.5723 - mae: 55.2391 - val_loss: 3461.8701 - val_mae: 37.7012\n",
      "Epoch 529/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 29561.8691 - mae: 55.7473 - val_loss: 3526.6130 - val_mae: 38.6483\n",
      "Epoch 530/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 29782.9492 - mae: 55.0956 - val_loss: 3789.4514 - val_mae: 41.2890\n",
      "Epoch 531/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 29733.4160 - mae: 56.4019 - val_loss: 3453.6831 - val_mae: 36.2875\n",
      "Epoch 532/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 29698.7695 - mae: 56.4171 - val_loss: 3539.3350 - val_mae: 37.6862\n",
      "Epoch 533/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 29238.7148 - mae: 55.7169 - val_loss: 3587.8071 - val_mae: 37.3461\n",
      "Epoch 534/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 29298.9668 - mae: 59.2972 - val_loss: 3644.9810 - val_mae: 38.5588\n",
      "Epoch 535/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 29373.4004 - mae: 55.2887 - val_loss: 3358.6670 - val_mae: 35.5636\n",
      "Epoch 536/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 31110.4355 - mae: 60.8454 - val_loss: 3750.3103 - val_mae: 40.9724\n",
      "Epoch 537/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 29564.2148 - mae: 57.6608 - val_loss: 3460.3398 - val_mae: 36.5806\n",
      "Epoch 538/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 29561.2012 - mae: 54.5313 - val_loss: 3458.4338 - val_mae: 36.6836\n",
      "Epoch 539/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 29497.1582 - mae: 54.1350 - val_loss: 3415.8311 - val_mae: 37.3290\n",
      "Epoch 540/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 29741.9609 - mae: 54.6431 - val_loss: 3368.3616 - val_mae: 37.0352\n",
      "Epoch 541/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 29131.4258 - mae: 55.8736 - val_loss: 3487.0063 - val_mae: 37.9000\n",
      "Epoch 542/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 29095.8828 - mae: 54.4051 - val_loss: 3474.3667 - val_mae: 36.4732\n",
      "Epoch 543/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 28180.6484 - mae: 58.8363 - val_loss: 3523.0835 - val_mae: 36.4854\n",
      "Epoch 544/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 29584.5176 - mae: 57.0634 - val_loss: 4034.1770 - val_mae: 43.7487\n",
      "Epoch 545/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 27539.0684 - mae: 54.9602 - val_loss: 3791.8596 - val_mae: 39.3763\n",
      "Epoch 546/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 29308.1074 - mae: 51.4587 - val_loss: 3509.0520 - val_mae: 37.5476\n",
      "Epoch 547/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 29070.4004 - mae: 53.9391 - val_loss: 3442.1099 - val_mae: 36.9576\n",
      "Epoch 548/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 28731.3691 - mae: 54.1588 - val_loss: 3726.2671 - val_mae: 40.5808\n",
      "Epoch 549/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 29218.8574 - mae: 55.1760 - val_loss: 3435.6575 - val_mae: 36.2782\n",
      "Epoch 550/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 29010.8809 - mae: 55.3545 - val_loss: 3386.7942 - val_mae: 37.2572\n",
      "Epoch 551/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 29185.9688 - mae: 56.9537 - val_loss: 3636.1294 - val_mae: 39.5115\n",
      "Epoch 552/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 29193.3984 - mae: 55.5401 - val_loss: 3789.3750 - val_mae: 41.0008\n",
      "Epoch 553/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 28812.8613 - mae: 56.9455 - val_loss: 3416.1042 - val_mae: 37.6187\n",
      "Epoch 554/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 29592.5820 - mae: 54.6486 - val_loss: 3329.5439 - val_mae: 36.8794\n",
      "Epoch 555/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 28590.0332 - mae: 55.9800 - val_loss: 3352.3408 - val_mae: 36.3034\n",
      "Epoch 556/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 28847.2754 - mae: 56.1864 - val_loss: 3434.0151 - val_mae: 37.5360\n",
      "Epoch 557/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 28343.9102 - mae: 53.9664 - val_loss: 3527.8440 - val_mae: 38.9934\n",
      "Epoch 558/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 28187.9355 - mae: 53.5687 - val_loss: 3368.7068 - val_mae: 36.4352\n",
      "Epoch 559/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 27975.0918 - mae: 54.1839 - val_loss: 3420.3340 - val_mae: 37.5571\n",
      "Epoch 560/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 29344.1562 - mae: 56.2879 - val_loss: 3341.9790 - val_mae: 37.2471\n",
      "Epoch 561/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 28301.7852 - mae: 56.8216 - val_loss: 3535.5188 - val_mae: 39.3678\n",
      "Epoch 562/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 28314.1484 - mae: 54.0663 - val_loss: 3379.7439 - val_mae: 36.9243\n",
      "Epoch 563/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 28408.9355 - mae: 54.5023 - val_loss: 3687.1436 - val_mae: 40.6957\n",
      "Epoch 564/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 28201.7520 - mae: 56.5133 - val_loss: 3274.2354 - val_mae: 36.5360\n",
      "Epoch 565/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 28279.9023 - mae: 56.8084 - val_loss: 3384.2556 - val_mae: 37.1825\n",
      "Epoch 566/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 28433.5742 - mae: 55.2565 - val_loss: 3758.1807 - val_mae: 40.3879\n",
      "Epoch 567/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 27884.7910 - mae: 54.0822 - val_loss: 3844.0000 - val_mae: 41.8399\n",
      "Epoch 568/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 27701.7031 - mae: 54.7878 - val_loss: 3484.4172 - val_mae: 37.8796\n",
      "Epoch 569/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 28358.8848 - mae: 57.4011 - val_loss: 3536.5759 - val_mae: 38.9811\n",
      "Epoch 570/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 27969.3672 - mae: 54.6215 - val_loss: 3997.0454 - val_mae: 42.9071\n",
      "Epoch 571/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 27619.0488 - mae: 53.6873 - val_loss: 3531.8438 - val_mae: 39.0590\n",
      "Epoch 572/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 27636.4277 - mae: 54.8084 - val_loss: 3411.7554 - val_mae: 36.6096\n",
      "Epoch 573/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 27623.8691 - mae: 53.3221 - val_loss: 3446.5715 - val_mae: 36.4960\n",
      "Epoch 574/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 28513.6074 - mae: 55.5400 - val_loss: 3843.2205 - val_mae: 41.1853\n",
      "Epoch 575/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 28588.8906 - mae: 56.4909 - val_loss: 3428.6421 - val_mae: 36.5737\n",
      "Epoch 576/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 28892.4844 - mae: 55.3780 - val_loss: 3409.5342 - val_mae: 37.3593\n",
      "Epoch 577/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 29297.4258 - mae: 56.2796 - val_loss: 3481.4690 - val_mae: 38.2767\n",
      "Epoch 578/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 30074.0996 - mae: 54.7671 - val_loss: 3436.4795 - val_mae: 37.1254\n",
      "Epoch 579/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 27857.7324 - mae: 56.4524 - val_loss: 3633.5383 - val_mae: 41.1606\n",
      "Epoch 580/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 28398.2734 - mae: 58.4807 - val_loss: 3762.3787 - val_mae: 40.6874\n",
      "Epoch 581/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 27880.7109 - mae: 54.8357 - val_loss: 3385.4678 - val_mae: 36.6804\n",
      "Epoch 582/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 29534.8066 - mae: 55.9022 - val_loss: 3480.5413 - val_mae: 38.2042\n",
      "Epoch 583/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 27921.7090 - mae: 54.3406 - val_loss: 3414.3499 - val_mae: 37.2967\n",
      "Epoch 584/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 27734.2363 - mae: 54.7864 - val_loss: 3432.6575 - val_mae: 37.2260\n",
      "Epoch 585/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 29818.5176 - mae: 55.2613 - val_loss: 3734.8896 - val_mae: 40.0831\n",
      "Epoch 586/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 27882.7773 - mae: 53.9913 - val_loss: 3511.3887 - val_mae: 37.4081\n",
      "Epoch 587/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 28733.1992 - mae: 54.2004 - val_loss: 3332.4116 - val_mae: 36.9829\n",
      "Epoch 588/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 28207.0391 - mae: 54.3403 - val_loss: 3424.9216 - val_mae: 37.2619\n",
      "Epoch 589/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 28182.3984 - mae: 56.4719 - val_loss: 3535.8918 - val_mae: 38.9511\n",
      "Epoch 590/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 27701.7305 - mae: 55.6152 - val_loss: 3477.6196 - val_mae: 36.8689\n",
      "Epoch 591/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 27189.7656 - mae: 54.5520 - val_loss: 3448.3506 - val_mae: 37.7043\n",
      "Epoch 592/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 27110.8262 - mae: 53.5605 - val_loss: 3430.1047 - val_mae: 37.3219\n",
      "Epoch 593/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 27848.9668 - mae: 57.9177 - val_loss: 3557.3625 - val_mae: 39.5076\n",
      "Epoch 594/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 27108.4980 - mae: 53.6326 - val_loss: 3401.2673 - val_mae: 38.2632\n",
      "Epoch 595/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 27158.4336 - mae: 54.8436 - val_loss: 3446.2190 - val_mae: 37.9201\n",
      "Epoch 596/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 26157.7988 - mae: 54.3167 - val_loss: 3626.2700 - val_mae: 41.2209\n",
      "Epoch 597/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 27027.6836 - mae: 57.4653 - val_loss: 3306.1934 - val_mae: 36.3407\n",
      "Epoch 598/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 27592.6973 - mae: 54.7552 - val_loss: 3373.5198 - val_mae: 36.6919\n",
      "Epoch 599/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 27400.0840 - mae: 54.5478 - val_loss: 3480.2266 - val_mae: 36.9092\n",
      "Epoch 600/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 28335.9824 - mae: 53.4932 - val_loss: 3383.7705 - val_mae: 37.2117\n",
      "Epoch 601/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 27014.9395 - mae: 52.9572 - val_loss: 3362.1150 - val_mae: 37.6579\n",
      "Epoch 602/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 27132.3984 - mae: 54.3871 - val_loss: 3377.3276 - val_mae: 37.3202\n",
      "Epoch 603/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 27615.5156 - mae: 57.3340 - val_loss: 3396.7502 - val_mae: 37.3001\n",
      "Epoch 604/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 27157.6484 - mae: 56.0644 - val_loss: 4175.6250 - val_mae: 43.7682\n",
      "Epoch 605/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 26581.8145 - mae: 59.2841 - val_loss: 3690.4065 - val_mae: 37.6301\n",
      "Epoch 606/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 27241.5234 - mae: 52.2218 - val_loss: 3855.4487 - val_mae: 42.4264\n",
      "Epoch 607/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 25511.3750 - mae: 55.7710 - val_loss: 3474.5107 - val_mae: 37.4533\n",
      "Epoch 608/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 29759.4434 - mae: 56.1863 - val_loss: 3814.3445 - val_mae: 41.2727\n",
      "Epoch 609/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 25764.0684 - mae: 57.2537 - val_loss: 3561.0168 - val_mae: 39.0295\n",
      "Epoch 610/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 26561.9355 - mae: 53.6980 - val_loss: 3392.5046 - val_mae: 36.7707\n",
      "Epoch 611/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 26645.4316 - mae: 53.6850 - val_loss: 3536.6235 - val_mae: 38.4051\n",
      "Epoch 612/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 26234.9590 - mae: 54.0467 - val_loss: 3394.8647 - val_mae: 36.5760\n",
      "Epoch 613/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 29258.6445 - mae: 55.6708 - val_loss: 3602.2185 - val_mae: 39.2717\n",
      "Epoch 614/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 27369.9863 - mae: 53.2751 - val_loss: 3470.0190 - val_mae: 37.8510\n",
      "Epoch 615/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 26871.5684 - mae: 54.6041 - val_loss: 3476.9778 - val_mae: 38.4633\n",
      "Epoch 616/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 27162.2832 - mae: 54.1447 - val_loss: 3441.5393 - val_mae: 37.6747\n",
      "Epoch 617/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 27628.9805 - mae: 55.2026 - val_loss: 3479.7097 - val_mae: 36.8422\n",
      "Epoch 618/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 27731.0527 - mae: 52.0936 - val_loss: 3441.6394 - val_mae: 37.0637\n",
      "Epoch 619/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 26953.2148 - mae: 52.9649 - val_loss: 3511.0349 - val_mae: 38.4302\n",
      "Epoch 620/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 26392.5820 - mae: 53.7370 - val_loss: 3525.3997 - val_mae: 38.9819\n",
      "Epoch 621/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 26109.5137 - mae: 54.5031 - val_loss: 3338.4465 - val_mae: 36.6852\n",
      "Epoch 622/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 25894.7305 - mae: 53.9825 - val_loss: 3400.6462 - val_mae: 36.8590\n",
      "Epoch 623/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 27062.5684 - mae: 52.8081 - val_loss: 3289.6194 - val_mae: 36.7937\n",
      "Epoch 624/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 26436.5410 - mae: 53.8421 - val_loss: 3341.2009 - val_mae: 36.8605\n",
      "Epoch 625/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 26580.3594 - mae: 57.8682 - val_loss: 3804.7043 - val_mae: 41.4436\n",
      "Epoch 626/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 25782.8066 - mae: 53.2506 - val_loss: 3572.2349 - val_mae: 37.2565\n",
      "Epoch 627/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 26669.7305 - mae: 53.8413 - val_loss: 3911.6367 - val_mae: 41.8803\n",
      "Epoch 628/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 26738.0996 - mae: 55.9043 - val_loss: 3446.0535 - val_mae: 37.3706\n",
      "Epoch 629/1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 25870.3848 - mae: 53.4931 - val_loss: 3457.8965 - val_mae: 38.3782\n",
      "Epoch 630/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 26320.1152 - mae: 54.5015 - val_loss: 3447.4470 - val_mae: 37.5003\n",
      "Epoch 631/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 26399.7637 - mae: 53.2188 - val_loss: 3611.3684 - val_mae: 39.0924\n",
      "Epoch 632/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 27723.9023 - mae: 54.4912 - val_loss: 3363.8281 - val_mae: 37.2844\n",
      "Epoch 633/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 26361.0137 - mae: 53.7412 - val_loss: 3510.6042 - val_mae: 37.5149\n",
      "Epoch 634/1000\n",
      "98/98 [==============================] - ETA: 0s - loss: 26438.7070 - mae: 53.49 - 0s 2ms/step - loss: 26176.5059 - mae: 53.2320 - val_loss: 3473.0049 - val_mae: 38.5586\n",
      "Epoch 635/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 26187.2344 - mae: 52.8169 - val_loss: 3489.3826 - val_mae: 37.8966\n",
      "Epoch 636/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 25917.0684 - mae: 53.2620 - val_loss: 3304.7649 - val_mae: 36.4322\n",
      "Epoch 637/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 25218.7246 - mae: 52.8281 - val_loss: 3484.1025 - val_mae: 38.5653\n",
      "Epoch 638/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 35983.5273 - mae: 56.7823 - val_loss: 3446.2815 - val_mae: 38.1783\n",
      "Epoch 639/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 25162.4844 - mae: 52.9837 - val_loss: 3628.6970 - val_mae: 37.9688\n",
      "Epoch 640/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 26648.2891 - mae: 53.7023 - val_loss: 3593.2961 - val_mae: 38.0404\n",
      "Epoch 641/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 25336.5234 - mae: 51.8710 - val_loss: 3529.5828 - val_mae: 38.1368\n",
      "Epoch 642/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 26067.4648 - mae: 54.5345 - val_loss: 4030.1179 - val_mae: 39.9982\n",
      "Epoch 643/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 26384.9473 - mae: 51.4083 - val_loss: 3934.3308 - val_mae: 39.9603\n",
      "Epoch 644/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 26680.9219 - mae: 52.4837 - val_loss: 4014.7981 - val_mae: 40.4150\n",
      "Epoch 645/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 25367.9141 - mae: 52.0813 - val_loss: 3837.7388 - val_mae: 40.2115\n",
      "Epoch 646/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 25524.7852 - mae: 54.9234 - val_loss: 3538.9285 - val_mae: 37.6933\n",
      "Epoch 647/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 25393.5977 - mae: 53.3399 - val_loss: 3429.3164 - val_mae: 38.2058\n",
      "Epoch 648/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 26697.4277 - mae: 55.2602 - val_loss: 3489.7180 - val_mae: 37.7307\n",
      "Epoch 649/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 25633.5781 - mae: 53.8877 - val_loss: 3403.2522 - val_mae: 37.1885\n",
      "Epoch 650/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 25382.8145 - mae: 54.5368 - val_loss: 3703.9136 - val_mae: 39.1014\n",
      "Epoch 651/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 24919.7637 - mae: 51.8504 - val_loss: 3566.1689 - val_mae: 38.0247\n",
      "Epoch 652/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 25328.6680 - mae: 51.2509 - val_loss: 3943.3562 - val_mae: 41.7180\n",
      "Epoch 653/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 25338.0859 - mae: 55.0441 - val_loss: 3754.3176 - val_mae: 40.0701\n",
      "Epoch 654/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 25015.8008 - mae: 52.0619 - val_loss: 3605.9082 - val_mae: 39.3761\n",
      "Epoch 655/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 25298.7305 - mae: 54.0162 - val_loss: 3852.0476 - val_mae: 39.9453\n",
      "Epoch 656/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 25592.8906 - mae: 51.9435 - val_loss: 3901.1531 - val_mae: 39.9857\n",
      "Epoch 657/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 25726.7109 - mae: 53.0521 - val_loss: 3884.8035 - val_mae: 39.6719\n",
      "Epoch 658/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 24567.8242 - mae: 52.2525 - val_loss: 3730.6665 - val_mae: 38.6733\n",
      "Epoch 659/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 24289.6914 - mae: 51.6895 - val_loss: 3565.1445 - val_mae: 38.4732\n",
      "Epoch 660/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 35402.4062 - mae: 60.4849 - val_loss: 3659.4856 - val_mae: 38.7148\n",
      "Epoch 661/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 26447.1094 - mae: 53.4975 - val_loss: 3730.8965 - val_mae: 39.0789\n",
      "Epoch 662/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 26044.9922 - mae: 55.0796 - val_loss: 3754.6169 - val_mae: 39.2850\n",
      "Epoch 663/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 26484.5938 - mae: 54.9355 - val_loss: 3705.4473 - val_mae: 38.9227\n",
      "Epoch 664/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 25376.2480 - mae: 54.1005 - val_loss: 3823.1284 - val_mae: 40.6795\n",
      "Epoch 665/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 25723.0020 - mae: 54.6690 - val_loss: 3485.3169 - val_mae: 37.6891\n",
      "Epoch 666/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 24512.4434 - mae: 51.4060 - val_loss: 3799.6936 - val_mae: 39.1514\n",
      "Epoch 667/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 24182.6387 - mae: 50.7063 - val_loss: 3552.4785 - val_mae: 37.7544\n",
      "Epoch 668/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 24753.9160 - mae: 51.2990 - val_loss: 3699.8254 - val_mae: 38.6707\n",
      "Epoch 669/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 24907.4648 - mae: 51.9747 - val_loss: 3893.4099 - val_mae: 39.3675\n",
      "Epoch 670/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 26208.0469 - mae: 53.7220 - val_loss: 3728.6208 - val_mae: 39.0052\n",
      "Epoch 671/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 24889.4727 - mae: 53.4380 - val_loss: 3851.0103 - val_mae: 39.9249\n",
      "Epoch 672/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 24678.5508 - mae: 50.3941 - val_loss: 3805.1196 - val_mae: 40.2524\n",
      "Epoch 673/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 24360.8555 - mae: 51.8066 - val_loss: 3580.1094 - val_mae: 38.0421\n",
      "Epoch 674/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 24521.9023 - mae: 51.5256 - val_loss: 3948.6257 - val_mae: 39.1511\n",
      "Epoch 675/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 23951.6680 - mae: 49.2671 - val_loss: 3871.8721 - val_mae: 38.5882\n",
      "Epoch 676/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 24653.2422 - mae: 50.7988 - val_loss: 3669.4082 - val_mae: 38.2264\n",
      "Epoch 677/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 23768.1094 - mae: 51.1231 - val_loss: 3686.5295 - val_mae: 38.6084\n",
      "Epoch 678/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 24091.6777 - mae: 50.6671 - val_loss: 3713.0166 - val_mae: 39.1246\n",
      "Epoch 679/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 25224.6816 - mae: 54.0931 - val_loss: 3653.6387 - val_mae: 39.0343\n",
      "Epoch 680/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 23521.4414 - mae: 52.2383 - val_loss: 3784.9524 - val_mae: 39.2366\n",
      "Epoch 681/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 24275.1348 - mae: 51.5221 - val_loss: 3804.8723 - val_mae: 39.1799\n",
      "Epoch 682/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 24470.7441 - mae: 51.7098 - val_loss: 3679.5601 - val_mae: 38.7237\n",
      "Epoch 683/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 23534.8359 - mae: 51.4166 - val_loss: 3623.1150 - val_mae: 38.8097\n",
      "Epoch 684/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 24639.9277 - mae: 55.2736 - val_loss: 3808.0630 - val_mae: 39.3533\n",
      "Epoch 685/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 24431.8008 - mae: 51.1085 - val_loss: 3961.9534 - val_mae: 39.7957\n",
      "Epoch 686/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 24227.6758 - mae: 50.6802 - val_loss: 3857.5708 - val_mae: 39.3278\n",
      "Epoch 687/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 23548.9141 - mae: 51.0129 - val_loss: 4019.8479 - val_mae: 40.0623\n",
      "Epoch 688/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 24264.8516 - mae: 51.4170 - val_loss: 3977.2188 - val_mae: 39.9032\n",
      "Epoch 689/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 24471.0273 - mae: 52.7191 - val_loss: 3872.7915 - val_mae: 39.5317\n",
      "Epoch 690/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 22947.8027 - mae: 50.4830 - val_loss: 3685.7634 - val_mae: 38.2566\n",
      "Epoch 691/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 25042.8145 - mae: 55.5285 - val_loss: 3807.8687 - val_mae: 37.9859\n",
      "Epoch 692/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 23932.1660 - mae: 53.0163 - val_loss: 3727.7744 - val_mae: 37.7476\n",
      "Epoch 693/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 23843.5098 - mae: 50.8102 - val_loss: 3699.2615 - val_mae: 38.4247\n",
      "Epoch 694/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 24805.7637 - mae: 54.7660 - val_loss: 3825.3542 - val_mae: 37.8120\n",
      "Epoch 695/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 25423.6836 - mae: 53.0596 - val_loss: 3786.6794 - val_mae: 37.5029\n",
      "Epoch 696/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 23731.2676 - mae: 52.7960 - val_loss: 3881.3057 - val_mae: 37.8609\n",
      "Epoch 697/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 24915.7070 - mae: 52.7412 - val_loss: 3732.7249 - val_mae: 36.2730\n",
      "Epoch 698/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 24312.2969 - mae: 51.9747 - val_loss: 3756.9636 - val_mae: 38.3045\n",
      "Epoch 699/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 25269.5723 - mae: 55.0204 - val_loss: 3824.6018 - val_mae: 37.0414\n",
      "Epoch 700/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 34792.6875 - mae: 54.0035 - val_loss: 3702.2573 - val_mae: 36.2759\n",
      "Epoch 701/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 23795.7891 - mae: 49.4151 - val_loss: 3670.3066 - val_mae: 34.8569\n",
      "Epoch 702/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 24086.3496 - mae: 51.4708 - val_loss: 3791.9236 - val_mae: 37.6279\n",
      "Epoch 703/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 24144.6270 - mae: 53.0126 - val_loss: 3819.4277 - val_mae: 38.3557\n",
      "Epoch 704/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 24178.8008 - mae: 52.3209 - val_loss: 3735.9578 - val_mae: 37.1543\n",
      "Epoch 705/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 24543.3262 - mae: 52.0160 - val_loss: 3697.4749 - val_mae: 37.2879\n",
      "Epoch 706/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 24112.9160 - mae: 53.2995 - val_loss: 3747.8601 - val_mae: 37.3388\n",
      "Epoch 707/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 24078.4004 - mae: 52.8383 - val_loss: 3767.8850 - val_mae: 37.1925\n",
      "Epoch 708/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 34591.2695 - mae: 56.4177 - val_loss: 3733.1704 - val_mae: 37.0168\n",
      "Epoch 709/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 23701.4590 - mae: 51.3437 - val_loss: 3705.0918 - val_mae: 35.7665\n",
      "Epoch 710/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 23868.0918 - mae: 51.2843 - val_loss: 3698.8901 - val_mae: 36.6250\n",
      "Epoch 711/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 23245.8984 - mae: 51.2668 - val_loss: 3774.4021 - val_mae: 36.3727\n",
      "Epoch 712/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 24235.6602 - mae: 51.0966 - val_loss: 3732.1721 - val_mae: 36.9009\n",
      "Epoch 713/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 23327.7266 - mae: 50.1506 - val_loss: 3536.0483 - val_mae: 35.4530\n",
      "Epoch 714/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 24290.7168 - mae: 56.2525 - val_loss: 3481.7305 - val_mae: 32.8974\n",
      "Epoch 715/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 23451.8770 - mae: 50.4407 - val_loss: 3747.4761 - val_mae: 35.9098\n",
      "Epoch 716/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 22509.6680 - mae: 49.4733 - val_loss: 3723.1633 - val_mae: 36.8580\n",
      "Epoch 717/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 27599.3164 - mae: 55.9246 - val_loss: 3780.4812 - val_mae: 36.7787\n",
      "Epoch 718/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 24059.8613 - mae: 51.4186 - val_loss: 3682.1602 - val_mae: 36.5767\n",
      "Epoch 719/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 24427.9160 - mae: 53.5445 - val_loss: 3520.5264 - val_mae: 34.6810\n",
      "Epoch 720/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 23880.4023 - mae: 50.7360 - val_loss: 3649.6465 - val_mae: 36.1793\n",
      "Epoch 721/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 22430.4609 - mae: 46.9247 - val_loss: 3730.6172 - val_mae: 36.6476\n",
      "Epoch 722/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 23353.1992 - mae: 49.6409 - val_loss: 3662.9080 - val_mae: 36.0660\n",
      "Epoch 723/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 23329.0000 - mae: 51.3258 - val_loss: 3547.9575 - val_mae: 34.7027\n",
      "Epoch 724/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 33584.0664 - mae: 51.9683 - val_loss: 3610.0415 - val_mae: 35.8026\n",
      "Epoch 725/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 24381.6992 - mae: 53.3790 - val_loss: 3676.0410 - val_mae: 36.7411\n",
      "Epoch 726/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 23552.0820 - mae: 53.4907 - val_loss: 3594.7542 - val_mae: 34.8702\n",
      "Epoch 727/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 23702.5469 - mae: 51.1472 - val_loss: 3671.0950 - val_mae: 34.8737\n",
      "Epoch 728/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 24089.4609 - mae: 51.8090 - val_loss: 3689.0166 - val_mae: 36.0283\n",
      "Epoch 729/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 24463.7520 - mae: 54.0336 - val_loss: 3744.6770 - val_mae: 37.0609\n",
      "Epoch 730/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 23540.1777 - mae: 51.9039 - val_loss: 3673.8398 - val_mae: 35.3561\n",
      "Epoch 731/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 23108.3438 - mae: 49.6945 - val_loss: 3651.3247 - val_mae: 35.6610\n",
      "Epoch 732/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 23012.7012 - mae: 50.7530 - val_loss: 3706.0962 - val_mae: 35.0090\n",
      "Epoch 733/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 23092.4473 - mae: 50.6544 - val_loss: 3494.6208 - val_mae: 32.7894\n",
      "Epoch 734/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 24100.1426 - mae: 52.0572 - val_loss: 3470.5422 - val_mae: 33.3886\n",
      "Epoch 735/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 22505.7305 - mae: 49.8284 - val_loss: 3436.2825 - val_mae: 33.5957\n",
      "Epoch 736/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 23146.7832 - mae: 51.8064 - val_loss: 3682.9648 - val_mae: 36.1727\n",
      "Epoch 737/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 23145.6445 - mae: 52.9201 - val_loss: 3636.9768 - val_mae: 35.7928\n",
      "Epoch 738/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 24049.3359 - mae: 52.1846 - val_loss: 3634.8601 - val_mae: 34.7761\n",
      "Epoch 739/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 22897.9531 - mae: 50.0060 - val_loss: 3639.7954 - val_mae: 35.6451\n",
      "Epoch 740/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 22304.5098 - mae: 48.7829 - val_loss: 3595.3755 - val_mae: 35.4941\n",
      "Epoch 741/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 22802.6250 - mae: 49.8685 - val_loss: 3677.4351 - val_mae: 36.5287\n",
      "Epoch 742/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 22850.7148 - mae: 52.0723 - val_loss: 3606.1282 - val_mae: 36.7804\n",
      "Epoch 743/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 22992.1309 - mae: 50.9756 - val_loss: 3495.2983 - val_mae: 34.6205\n",
      "Epoch 744/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 22535.5000 - mae: 49.1182 - val_loss: 3384.5525 - val_mae: 34.8804\n",
      "Epoch 745/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 22881.9531 - mae: 51.0889 - val_loss: 3475.7012 - val_mae: 34.4298\n",
      "Epoch 746/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 23468.6348 - mae: 51.0237 - val_loss: 3679.3103 - val_mae: 36.6908\n",
      "Epoch 747/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 22327.3730 - mae: 48.9492 - val_loss: 3624.6023 - val_mae: 35.8986\n",
      "Epoch 748/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 22819.1387 - mae: 50.7542 - val_loss: 3493.2314 - val_mae: 35.1618\n",
      "Epoch 749/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 23558.0234 - mae: 51.8637 - val_loss: 3448.6787 - val_mae: 34.4271\n",
      "Epoch 750/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 21909.3242 - mae: 48.9017 - val_loss: 3790.1458 - val_mae: 37.4055\n",
      "Epoch 751/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 21222.2695 - mae: 48.7830 - val_loss: 3567.4885 - val_mae: 35.7514\n",
      "Epoch 752/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 24940.0820 - mae: 55.7701 - val_loss: 3611.3428 - val_mae: 35.8874\n",
      "Epoch 753/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 22056.1191 - mae: 48.6994 - val_loss: 3710.1956 - val_mae: 37.1253\n",
      "Epoch 754/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 37547.7031 - mae: 55.7349 - val_loss: 3543.4355 - val_mae: 34.7505\n",
      "Epoch 755/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 22396.9512 - mae: 50.7456 - val_loss: 3700.7483 - val_mae: 36.9359\n",
      "Epoch 756/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 22423.5742 - mae: 49.1701 - val_loss: 3627.9514 - val_mae: 36.7352\n",
      "Epoch 757/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 33609.2109 - mae: 54.0626 - val_loss: 3487.9526 - val_mae: 35.3685\n",
      "Epoch 758/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 24563.6719 - mae: 54.9799 - val_loss: 3566.9641 - val_mae: 35.2791\n",
      "Epoch 759/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 22393.3164 - mae: 50.0483 - val_loss: 3429.2712 - val_mae: 34.2456\n",
      "Epoch 760/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 22276.6406 - mae: 50.3425 - val_loss: 3647.0437 - val_mae: 36.2946\n",
      "Epoch 761/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 22124.3926 - mae: 49.3041 - val_loss: 3530.4180 - val_mae: 33.0588\n",
      "Epoch 762/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 21948.8496 - mae: 48.5890 - val_loss: 3860.8320 - val_mae: 38.3316\n",
      "Epoch 763/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 21887.4688 - mae: 47.9041 - val_loss: 4241.2456 - val_mae: 42.5956\n",
      "Epoch 764/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 22667.4023 - mae: 51.3355 - val_loss: 3544.7810 - val_mae: 35.8169\n",
      "Epoch 765/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 22935.1855 - mae: 52.0414 - val_loss: 3598.6340 - val_mae: 32.9892\n",
      "Epoch 766/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 24140.2305 - mae: 50.4892 - val_loss: 3682.2275 - val_mae: 35.4444\n",
      "Epoch 767/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 20467.6953 - mae: 49.7082 - val_loss: 3658.1069 - val_mae: 35.6574\n",
      "Epoch 768/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 22106.0918 - mae: 48.8578 - val_loss: 3643.4001 - val_mae: 36.4614\n",
      "Epoch 769/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 21572.8730 - mae: 52.4942 - val_loss: 3702.0063 - val_mae: 36.5682\n",
      "Epoch 770/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 21785.6445 - mae: 54.4824 - val_loss: 4147.9653 - val_mae: 40.8776\n",
      "Epoch 771/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 20100.9922 - mae: 49.4131 - val_loss: 3757.2361 - val_mae: 35.1813\n",
      "Epoch 772/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 22087.7832 - mae: 48.5153 - val_loss: 3802.6211 - val_mae: 36.1625\n",
      "Epoch 773/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 22041.7910 - mae: 49.1594 - val_loss: 3751.5493 - val_mae: 35.8126\n",
      "Epoch 774/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 22561.0234 - mae: 50.6622 - val_loss: 3612.3501 - val_mae: 35.5646\n",
      "Epoch 775/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 23971.6172 - mae: 54.4521 - val_loss: 4034.5745 - val_mae: 41.1527\n",
      "Epoch 776/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 22942.9258 - mae: 53.0472 - val_loss: 3658.3555 - val_mae: 35.6101\n",
      "Epoch 777/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 24202.0195 - mae: 54.5628 - val_loss: 3655.1111 - val_mae: 35.1841\n",
      "Epoch 778/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 21940.9414 - mae: 48.7626 - val_loss: 3571.9978 - val_mae: 34.5952\n",
      "Epoch 779/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 24249.2441 - mae: 56.5209 - val_loss: 3457.2146 - val_mae: 32.7157\n",
      "Epoch 780/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 22543.5352 - mae: 50.7271 - val_loss: 3548.1570 - val_mae: 33.1094\n",
      "Epoch 781/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 24703.6758 - mae: 59.5673 - val_loss: 3576.0176 - val_mae: 33.4505\n",
      "Epoch 782/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 23349.7148 - mae: 52.4164 - val_loss: 3573.8896 - val_mae: 35.1993\n",
      "Epoch 783/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 21987.2773 - mae: 50.3148 - val_loss: 3470.9031 - val_mae: 34.6707\n",
      "Epoch 784/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 21692.4414 - mae: 48.3846 - val_loss: 3562.2932 - val_mae: 32.8331\n",
      "Epoch 785/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 21986.8223 - mae: 47.5309 - val_loss: 3887.8735 - val_mae: 36.1277\n",
      "Epoch 786/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 21797.5938 - mae: 48.8483 - val_loss: 3461.8337 - val_mae: 33.6096\n",
      "Epoch 787/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 21758.8281 - mae: 49.4812 - val_loss: 3373.9917 - val_mae: 32.2691\n",
      "Epoch 788/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 21814.6836 - mae: 50.6675 - val_loss: 3466.3008 - val_mae: 33.5700\n",
      "Epoch 789/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 21966.4219 - mae: 49.8204 - val_loss: 3495.5303 - val_mae: 34.8499\n",
      "Epoch 790/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 20974.4434 - mae: 49.2532 - val_loss: 3714.9734 - val_mae: 38.5851\n",
      "Epoch 791/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 21483.4922 - mae: 49.0895 - val_loss: 3979.9319 - val_mae: 40.2029\n",
      "Epoch 792/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 21239.9180 - mae: 48.2838 - val_loss: 3659.6938 - val_mae: 36.6768\n",
      "Epoch 793/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 34443.3086 - mae: 57.1227 - val_loss: 3585.7927 - val_mae: 35.5575\n",
      "Epoch 794/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 23446.4473 - mae: 53.1458 - val_loss: 3487.1919 - val_mae: 34.9844\n",
      "Epoch 795/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 20974.2402 - mae: 48.1168 - val_loss: 3561.3438 - val_mae: 34.7602\n",
      "Epoch 796/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 21066.1250 - mae: 48.3818 - val_loss: 3621.7407 - val_mae: 35.8654\n",
      "Epoch 797/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 21632.1660 - mae: 50.2039 - val_loss: 3470.3220 - val_mae: 33.1946\n",
      "Epoch 798/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 21354.7363 - mae: 47.3060 - val_loss: 3686.8328 - val_mae: 36.4583\n",
      "Epoch 799/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 21165.9668 - mae: 48.7162 - val_loss: 3545.4932 - val_mae: 34.6773\n",
      "Epoch 800/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 21438.2578 - mae: 49.1897 - val_loss: 3654.8555 - val_mae: 35.7811\n",
      "Epoch 801/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 22477.8926 - mae: 51.7961 - val_loss: 4054.2588 - val_mae: 37.8907\n",
      "Epoch 802/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 21367.7070 - mae: 49.1761 - val_loss: 3714.4438 - val_mae: 37.2303\n",
      "Epoch 803/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 21347.4746 - mae: 48.2229 - val_loss: 3589.6448 - val_mae: 34.8872\n",
      "Epoch 804/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 21701.4648 - mae: 48.8568 - val_loss: 3433.3784 - val_mae: 33.1467\n",
      "Epoch 805/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 20910.5098 - mae: 46.3938 - val_loss: 3462.0579 - val_mae: 35.3058\n",
      "Epoch 806/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 20917.4785 - mae: 47.5556 - val_loss: 4062.5244 - val_mae: 39.9067\n",
      "Epoch 807/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 21880.9023 - mae: 51.4431 - val_loss: 3368.0549 - val_mae: 32.3908\n",
      "Epoch 808/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 21648.4648 - mae: 50.6955 - val_loss: 3627.7410 - val_mae: 37.0567\n",
      "Epoch 809/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 21646.2656 - mae: 50.8254 - val_loss: 3527.8892 - val_mae: 35.2272\n",
      "Epoch 810/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 20150.3223 - mae: 45.9023 - val_loss: 3975.5898 - val_mae: 39.3185\n",
      "Epoch 811/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 21584.7598 - mae: 50.5400 - val_loss: 3651.5781 - val_mae: 35.8792\n",
      "Epoch 812/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 20907.5488 - mae: 48.4599 - val_loss: 3499.1047 - val_mae: 33.5155\n",
      "Epoch 813/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 22619.6094 - mae: 50.7438 - val_loss: 4307.7949 - val_mae: 40.4930\n",
      "Epoch 814/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 20921.9277 - mae: 47.6803 - val_loss: 3866.6003 - val_mae: 38.8519\n",
      "Epoch 815/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 23814.5840 - mae: 54.2159 - val_loss: 4188.5659 - val_mae: 41.7087\n",
      "Epoch 816/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 19360.7148 - mae: 48.7085 - val_loss: 3923.0820 - val_mae: 39.5421\n",
      "Epoch 817/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 20755.9277 - mae: 48.3220 - val_loss: 3612.2551 - val_mae: 35.5017\n",
      "Epoch 818/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 20649.4824 - mae: 47.8917 - val_loss: 3514.3401 - val_mae: 36.0288\n",
      "Epoch 819/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 21647.6152 - mae: 53.5924 - val_loss: 4081.9360 - val_mae: 39.5531\n",
      "Epoch 820/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 23121.5254 - mae: 54.4998 - val_loss: 4226.0420 - val_mae: 40.2916\n",
      "Epoch 821/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 20059.9688 - mae: 49.7206 - val_loss: 3768.9912 - val_mae: 37.0185\n",
      "Epoch 822/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 21189.0820 - mae: 47.3629 - val_loss: 3989.8911 - val_mae: 38.9632\n",
      "Epoch 823/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 20150.8066 - mae: 48.7594 - val_loss: 3664.1565 - val_mae: 36.8723\n",
      "Epoch 824/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 20641.1621 - mae: 48.3053 - val_loss: 3955.7893 - val_mae: 39.6825\n",
      "Epoch 825/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 19897.1035 - mae: 48.9495 - val_loss: 3568.2646 - val_mae: 36.3290\n",
      "Epoch 826/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 21753.8105 - mae: 52.7648 - val_loss: 3361.2297 - val_mae: 32.4564\n",
      "Epoch 827/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 20750.1270 - mae: 49.1728 - val_loss: 4050.8345 - val_mae: 39.6838\n",
      "Epoch 828/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 20375.2793 - mae: 50.6584 - val_loss: 3341.6196 - val_mae: 32.9927\n",
      "Epoch 829/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 21082.6094 - mae: 50.3225 - val_loss: 3463.7510 - val_mae: 34.1856\n",
      "Epoch 830/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 19179.4219 - mae: 51.2876 - val_loss: 3504.0901 - val_mae: 34.2281\n",
      "Epoch 831/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 19059.3984 - mae: 50.0716 - val_loss: 3929.2854 - val_mae: 38.5790\n",
      "Epoch 832/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 28501.9336 - mae: 66.0415 - val_loss: 3469.8179 - val_mae: 32.5195\n",
      "Epoch 833/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 22366.0742 - mae: 54.3817 - val_loss: 3484.9058 - val_mae: 32.6648\n",
      "Epoch 834/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 21131.2949 - mae: 48.7148 - val_loss: 3407.7332 - val_mae: 32.4403\n",
      "Epoch 835/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 22197.3008 - mae: 53.4095 - val_loss: 3355.7461 - val_mae: 32.2593\n",
      "Epoch 836/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 21112.0371 - mae: 50.3326 - val_loss: 3343.8687 - val_mae: 32.7510\n",
      "Epoch 837/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 25846.3984 - mae: 56.7381 - val_loss: 3392.6741 - val_mae: 34.1618\n",
      "Epoch 838/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 20423.8262 - mae: 48.0979 - val_loss: 3655.0276 - val_mae: 36.4531\n",
      "Epoch 839/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 21760.1719 - mae: 52.4743 - val_loss: 3448.9646 - val_mae: 32.5705\n",
      "Epoch 840/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 21070.8652 - mae: 49.6460 - val_loss: 3746.1211 - val_mae: 36.6156\n",
      "Epoch 841/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 20840.5918 - mae: 50.7659 - val_loss: 3747.9973 - val_mae: 36.4205\n",
      "Epoch 842/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 20144.8770 - mae: 47.4043 - val_loss: 3775.6887 - val_mae: 35.9621\n",
      "Epoch 843/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 21039.0488 - mae: 49.1973 - val_loss: 4243.6055 - val_mae: 40.5952\n",
      "Epoch 844/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 21057.7441 - mae: 51.6245 - val_loss: 3919.8914 - val_mae: 37.6083\n",
      "Epoch 845/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 20689.6699 - mae: 52.9675 - val_loss: 4533.8550 - val_mae: 42.6071\n",
      "Epoch 846/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 19305.3516 - mae: 48.3647 - val_loss: 4228.1895 - val_mae: 40.3373\n",
      "Epoch 847/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 20538.3809 - mae: 47.7329 - val_loss: 3526.4272 - val_mae: 35.1157\n",
      "Epoch 848/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 19696.5859 - mae: 49.5557 - val_loss: 3986.8274 - val_mae: 40.0370\n",
      "Epoch 849/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 18992.7207 - mae: 49.3504 - val_loss: 3698.7334 - val_mae: 36.4201\n",
      "Epoch 850/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 20600.5527 - mae: 48.2095 - val_loss: 4092.9539 - val_mae: 39.0794\n",
      "Epoch 851/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 20028.7266 - mae: 46.8607 - val_loss: 4133.6475 - val_mae: 41.1325\n",
      "Epoch 852/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 20344.4590 - mae: 52.9947 - val_loss: 4057.6448 - val_mae: 40.1643\n",
      "Epoch 853/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 20214.5664 - mae: 48.4536 - val_loss: 3831.9910 - val_mae: 37.8301\n",
      "Epoch 854/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 19973.0039 - mae: 50.4258 - val_loss: 4090.9619 - val_mae: 41.1209\n",
      "Epoch 855/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 20788.1523 - mae: 50.9353 - val_loss: 3468.0664 - val_mae: 35.1399\n",
      "Epoch 856/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 20996.0547 - mae: 51.5863 - val_loss: 3920.4053 - val_mae: 36.4786\n",
      "Epoch 857/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 21024.5469 - mae: 50.6048 - val_loss: 3401.1921 - val_mae: 32.4393\n",
      "Epoch 858/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 20394.7441 - mae: 47.9649 - val_loss: 3386.1255 - val_mae: 32.4615\n",
      "Epoch 859/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 20037.0117 - mae: 47.5098 - val_loss: 3392.8462 - val_mae: 33.3794\n",
      "Epoch 860/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 19946.0488 - mae: 48.1319 - val_loss: 3918.3989 - val_mae: 36.6257\n",
      "Epoch 861/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 19621.2988 - mae: 46.8435 - val_loss: 3442.9595 - val_mae: 33.6664\n",
      "Epoch 862/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 20025.1895 - mae: 47.3883 - val_loss: 3622.3354 - val_mae: 36.6062\n",
      "Epoch 863/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 19722.6367 - mae: 46.3945 - val_loss: 3339.8201 - val_mae: 32.0315\n",
      "Epoch 864/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 21412.1445 - mae: 52.7927 - val_loss: 3362.4583 - val_mae: 32.2819\n",
      "Epoch 865/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 20158.7109 - mae: 48.8809 - val_loss: 3339.6736 - val_mae: 32.1808\n",
      "Epoch 866/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 19781.6406 - mae: 46.8958 - val_loss: 3600.7017 - val_mae: 37.3895\n",
      "Epoch 867/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 20134.4414 - mae: 49.7383 - val_loss: 3584.0913 - val_mae: 36.1534\n",
      "Epoch 868/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 22022.8320 - mae: 54.6118 - val_loss: 3369.2744 - val_mae: 32.1670\n",
      "Epoch 869/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 21736.5020 - mae: 52.4056 - val_loss: 3402.5320 - val_mae: 32.3240\n",
      "Epoch 870/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 20723.0605 - mae: 49.5807 - val_loss: 3690.5347 - val_mae: 36.3029\n",
      "Epoch 871/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 20832.3887 - mae: 50.8313 - val_loss: 3370.4136 - val_mae: 34.7508\n",
      "Epoch 872/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 20071.8691 - mae: 49.3668 - val_loss: 3876.5601 - val_mae: 38.0283\n",
      "Epoch 873/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 20528.2441 - mae: 48.7775 - val_loss: 3547.4272 - val_mae: 33.0478\n",
      "Epoch 874/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 20003.8691 - mae: 48.2710 - val_loss: 4117.8506 - val_mae: 39.3163\n",
      "Epoch 875/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 21129.8320 - mae: 50.5006 - val_loss: 3498.8823 - val_mae: 33.2567\n",
      "Epoch 876/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 19838.7715 - mae: 46.8532 - val_loss: 3382.7166 - val_mae: 33.4196\n",
      "Epoch 877/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 19662.5938 - mae: 47.0502 - val_loss: 3442.7805 - val_mae: 34.0284\n",
      "Epoch 878/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 19990.1113 - mae: 49.0538 - val_loss: 3476.9849 - val_mae: 34.3788\n",
      "Epoch 879/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 20595.7559 - mae: 49.6130 - val_loss: 4077.0559 - val_mae: 39.3934\n",
      "Epoch 880/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 18471.1270 - mae: 50.8994 - val_loss: 4103.6387 - val_mae: 38.5776\n",
      "Epoch 881/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 19324.9922 - mae: 47.0807 - val_loss: 3395.5286 - val_mae: 33.1945\n",
      "Epoch 882/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 19613.3359 - mae: 49.2168 - val_loss: 4166.1724 - val_mae: 39.3397\n",
      "Epoch 883/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 19694.6074 - mae: 47.3951 - val_loss: 3315.6885 - val_mae: 32.1107\n",
      "Epoch 884/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 21235.4531 - mae: 47.7786 - val_loss: 3508.5066 - val_mae: 34.2269\n",
      "Epoch 885/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 20738.0762 - mae: 49.8951 - val_loss: 3333.1211 - val_mae: 32.4271\n",
      "Epoch 886/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 20757.5918 - mae: 50.1766 - val_loss: 3448.8445 - val_mae: 34.6686\n",
      "Epoch 887/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 21428.0527 - mae: 53.1566 - val_loss: 3550.8379 - val_mae: 36.2265\n",
      "Epoch 888/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 22680.8613 - mae: 58.5427 - val_loss: 3434.2004 - val_mae: 32.1247\n",
      "Epoch 889/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 20780.2988 - mae: 52.3563 - val_loss: 3462.7192 - val_mae: 32.5848\n",
      "Epoch 890/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 20103.2891 - mae: 49.2871 - val_loss: 3594.0347 - val_mae: 35.2851\n",
      "Epoch 891/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 19983.3340 - mae: 47.9525 - val_loss: 3417.3335 - val_mae: 33.5652\n",
      "Epoch 892/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 21502.7441 - mae: 53.5277 - val_loss: 3892.8525 - val_mae: 38.1720\n",
      "Epoch 893/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 19372.3340 - mae: 47.9626 - val_loss: 4077.5276 - val_mae: 39.2543\n",
      "Epoch 894/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 19618.7637 - mae: 47.3669 - val_loss: 4019.8809 - val_mae: 39.2353\n",
      "Epoch 895/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 19657.3066 - mae: 47.4038 - val_loss: 4176.4233 - val_mae: 39.8861\n",
      "Epoch 896/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 19656.5449 - mae: 48.4047 - val_loss: 4011.6147 - val_mae: 38.6803\n",
      "Epoch 897/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 19399.7852 - mae: 47.8264 - val_loss: 3871.9155 - val_mae: 37.2989\n",
      "Epoch 898/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 19731.3008 - mae: 49.4378 - val_loss: 3805.4097 - val_mae: 36.5812\n",
      "Epoch 899/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 19546.4141 - mae: 47.2797 - val_loss: 3548.9011 - val_mae: 36.2599\n",
      "Epoch 900/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 20360.9199 - mae: 51.7258 - val_loss: 3981.4302 - val_mae: 38.8787\n",
      "Epoch 901/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 20278.3301 - mae: 49.2294 - val_loss: 3978.5664 - val_mae: 39.9582\n",
      "Epoch 902/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 19518.8203 - mae: 51.5935 - val_loss: 3968.5417 - val_mae: 39.4138\n",
      "Epoch 903/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 18920.4492 - mae: 51.3295 - val_loss: 3975.4175 - val_mae: 39.4505\n",
      "Epoch 904/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 19446.7422 - mae: 49.1206 - val_loss: 4154.4126 - val_mae: 39.9790\n",
      "Epoch 905/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 18969.4336 - mae: 47.3634 - val_loss: 3551.0596 - val_mae: 34.8309\n",
      "Epoch 906/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 19389.5938 - mae: 49.3562 - val_loss: 3880.7368 - val_mae: 38.1306\n",
      "Epoch 907/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 19085.7070 - mae: 46.4111 - val_loss: 3809.1941 - val_mae: 36.8791\n",
      "Epoch 908/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 18573.5020 - mae: 46.5325 - val_loss: 3475.6301 - val_mae: 33.6359\n",
      "Epoch 909/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 17797.2441 - mae: 43.7607 - val_loss: 4115.9424 - val_mae: 39.9833\n",
      "Epoch 910/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 19056.0391 - mae: 48.4393 - val_loss: 3968.3838 - val_mae: 36.6973\n",
      "Epoch 911/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 18872.7559 - mae: 46.2193 - val_loss: 3905.8767 - val_mae: 36.5569\n",
      "Epoch 912/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 18831.0039 - mae: 47.0808 - val_loss: 4183.6255 - val_mae: 38.5764\n",
      "Epoch 913/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 22135.9648 - mae: 51.1450 - val_loss: 3555.8972 - val_mae: 34.7888\n",
      "Epoch 914/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 18486.4512 - mae: 47.2563 - val_loss: 3437.2168 - val_mae: 32.5179\n",
      "Epoch 915/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 20074.9102 - mae: 51.0450 - val_loss: 3492.0769 - val_mae: 34.8796\n",
      "Epoch 916/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 22190.7578 - mae: 53.2472 - val_loss: 3369.4365 - val_mae: 32.1853\n",
      "Epoch 917/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 22946.5762 - mae: 56.8436 - val_loss: 3423.5178 - val_mae: 34.0655\n",
      "Epoch 918/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 20219.0137 - mae: 52.6551 - val_loss: 3452.6018 - val_mae: 34.3975\n",
      "Epoch 919/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 19498.8906 - mae: 49.5510 - val_loss: 3380.3262 - val_mae: 32.5036\n",
      "Epoch 920/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 20601.7461 - mae: 50.9553 - val_loss: 3400.0159 - val_mae: 32.3362\n",
      "Epoch 921/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 19282.0117 - mae: 46.7932 - val_loss: 3455.5337 - val_mae: 32.8878\n",
      "Epoch 922/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 21471.3516 - mae: 51.0156 - val_loss: 3474.0085 - val_mae: 33.5928\n",
      "Epoch 923/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 19550.7227 - mae: 48.4389 - val_loss: 3821.1699 - val_mae: 37.5713\n",
      "Epoch 924/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 32985.9805 - mae: 55.1886 - val_loss: 3409.4097 - val_mae: 33.7909\n",
      "Epoch 925/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 32911.3047 - mae: 54.4700 - val_loss: 3296.8447 - val_mae: 32.7689\n",
      "Epoch 926/1000\n",
      "98/98 [==============================] - ETA: 0s - loss: 23331.7129 - mae: 50.95 - 0s 2ms/step - loss: 19166.1660 - mae: 48.7598 - val_loss: 3428.7583 - val_mae: 34.0749\n",
      "Epoch 927/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 19313.0430 - mae: 49.6251 - val_loss: 3366.2205 - val_mae: 34.4150\n",
      "Epoch 928/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 19604.0605 - mae: 49.4431 - val_loss: 3283.3630 - val_mae: 32.0896\n",
      "Epoch 929/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 25433.4395 - mae: 56.3907 - val_loss: 3303.9023 - val_mae: 33.4296\n",
      "Epoch 930/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 20393.2227 - mae: 51.2583 - val_loss: 3431.6387 - val_mae: 33.7335\n",
      "Epoch 931/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 35660.8516 - mae: 55.7373 - val_loss: 4265.2251 - val_mae: 40.6676\n",
      "Epoch 932/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 19733.4785 - mae: 49.5782 - val_loss: 3491.9810 - val_mae: 33.7749\n",
      "Epoch 933/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 19568.6934 - mae: 48.9757 - val_loss: 3519.9968 - val_mae: 34.0678\n",
      "Epoch 934/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 19315.2422 - mae: 46.4183 - val_loss: 3380.3037 - val_mae: 32.6418\n",
      "Epoch 935/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 19830.4336 - mae: 48.6807 - val_loss: 3333.1558 - val_mae: 33.4908\n",
      "Epoch 936/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 33379.9961 - mae: 58.1823 - val_loss: 3323.9028 - val_mae: 32.9594\n",
      "Epoch 937/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 19291.0156 - mae: 48.7095 - val_loss: 3407.0762 - val_mae: 34.4520\n",
      "Epoch 938/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 19293.2109 - mae: 49.8990 - val_loss: 3269.7471 - val_mae: 33.2625\n",
      "Epoch 939/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 19145.6309 - mae: 49.6261 - val_loss: 4184.4609 - val_mae: 40.3502\n",
      "Epoch 940/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 19171.3438 - mae: 49.4872 - val_loss: 3464.3445 - val_mae: 36.1417\n",
      "Epoch 941/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 21546.2168 - mae: 55.2377 - val_loss: 3246.4255 - val_mae: 32.9089\n",
      "Epoch 942/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 20700.1523 - mae: 51.9291 - val_loss: 4070.3853 - val_mae: 40.5232\n",
      "Epoch 943/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 20557.1270 - mae: 53.2902 - val_loss: 3627.2500 - val_mae: 37.0110\n",
      "Epoch 944/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 19558.4473 - mae: 49.4927 - val_loss: 3361.0686 - val_mae: 32.1585\n",
      "Epoch 945/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 21385.4141 - mae: 52.0626 - val_loss: 3362.3293 - val_mae: 32.1510\n",
      "Epoch 946/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 20864.3672 - mae: 50.3483 - val_loss: 3362.8909 - val_mae: 32.4615\n",
      "Epoch 947/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 22285.7188 - mae: 52.1015 - val_loss: 3327.8625 - val_mae: 32.3771\n",
      "Epoch 948/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 20569.0801 - mae: 52.4708 - val_loss: 3282.2715 - val_mae: 32.1038\n",
      "Epoch 949/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 19196.1230 - mae: 47.7726 - val_loss: 4073.7761 - val_mae: 38.2792\n",
      "Epoch 950/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 21130.5547 - mae: 54.9724 - val_loss: 3874.8540 - val_mae: 36.7999\n",
      "Epoch 951/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 19614.7383 - mae: 51.6535 - val_loss: 3310.3057 - val_mae: 32.3193\n",
      "Epoch 952/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 19112.6426 - mae: 47.6303 - val_loss: 3231.4197 - val_mae: 32.1867\n",
      "Epoch 953/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 20026.5293 - mae: 51.2624 - val_loss: 3298.5891 - val_mae: 33.1199\n",
      "Epoch 954/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 19592.7402 - mae: 51.0090 - val_loss: 3307.5864 - val_mae: 32.8547\n",
      "Epoch 955/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 19913.1543 - mae: 47.7199 - val_loss: 3379.9514 - val_mae: 33.4697\n",
      "Epoch 956/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 19149.7305 - mae: 48.4633 - val_loss: 3253.7056 - val_mae: 32.9342\n",
      "Epoch 957/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 21022.0273 - mae: 49.8582 - val_loss: 4010.9934 - val_mae: 39.0028\n",
      "Epoch 958/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 20350.6270 - mae: 52.1037 - val_loss: 3341.6997 - val_mae: 33.9960\n",
      "Epoch 959/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 18715.6621 - mae: 49.4472 - val_loss: 3363.7480 - val_mae: 34.4485\n",
      "Epoch 960/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 36406.9453 - mae: 59.2714 - val_loss: 3195.5269 - val_mae: 32.8498\n",
      "Epoch 961/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 33604.0703 - mae: 56.2745 - val_loss: 3244.5659 - val_mae: 32.7034\n",
      "Epoch 962/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 19797.4727 - mae: 48.6427 - val_loss: 3126.1995 - val_mae: 32.2496\n",
      "Epoch 963/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 20670.4141 - mae: 53.8552 - val_loss: 3307.7283 - val_mae: 32.2495\n",
      "Epoch 964/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 18829.8594 - mae: 47.7771 - val_loss: 3337.3823 - val_mae: 32.1740\n",
      "Epoch 965/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 18871.4570 - mae: 46.8979 - val_loss: 3242.2507 - val_mae: 32.0075\n",
      "Epoch 966/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 18523.0391 - mae: 49.4351 - val_loss: 3993.5737 - val_mae: 38.9594\n",
      "Epoch 967/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 20139.2480 - mae: 50.5057 - val_loss: 3297.4141 - val_mae: 32.1766\n",
      "Epoch 968/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 19648.6250 - mae: 51.6488 - val_loss: 3374.0542 - val_mae: 33.3405\n",
      "Epoch 969/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 19039.9863 - mae: 50.0062 - val_loss: 3461.7539 - val_mae: 34.0678\n",
      "Epoch 970/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 18733.2031 - mae: 47.9337 - val_loss: 3436.8643 - val_mae: 34.3068\n",
      "Epoch 971/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 20511.2969 - mae: 54.0796 - val_loss: 3350.5593 - val_mae: 33.4433\n",
      "Epoch 972/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 19013.5430 - mae: 49.0894 - val_loss: 3314.9629 - val_mae: 33.2790\n",
      "Epoch 973/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 18900.0430 - mae: 48.1046 - val_loss: 3385.1238 - val_mae: 33.1955\n",
      "Epoch 974/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 18785.4180 - mae: 46.6550 - val_loss: 3398.3027 - val_mae: 34.0725\n",
      "Epoch 975/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 18837.9590 - mae: 48.3345 - val_loss: 3469.2114 - val_mae: 34.2520\n",
      "Epoch 976/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 19706.0938 - mae: 48.5925 - val_loss: 3346.9707 - val_mae: 32.8558\n",
      "Epoch 977/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 33221.7227 - mae: 54.6000 - val_loss: 3452.6655 - val_mae: 33.6504\n",
      "Epoch 978/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 33356.7305 - mae: 56.7988 - val_loss: 3526.8792 - val_mae: 35.6131\n",
      "Epoch 979/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 18896.8359 - mae: 48.1157 - val_loss: 3318.5149 - val_mae: 32.5547\n",
      "Epoch 980/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 20469.1719 - mae: 53.4780 - val_loss: 3491.8306 - val_mae: 35.7205\n",
      "Epoch 981/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 19609.9570 - mae: 50.3511 - val_loss: 3690.8931 - val_mae: 37.0927\n",
      "Epoch 982/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 18968.7012 - mae: 49.3410 - val_loss: 3569.3076 - val_mae: 35.9153\n",
      "Epoch 983/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 18597.7070 - mae: 48.0160 - val_loss: 4126.0762 - val_mae: 39.6543\n",
      "Epoch 984/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 18764.4316 - mae: 49.6535 - val_loss: 3426.2588 - val_mae: 33.2528\n",
      "Epoch 985/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 18784.7070 - mae: 48.9266 - val_loss: 3596.6558 - val_mae: 35.4144\n",
      "Epoch 986/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 19157.0000 - mae: 49.9739 - val_loss: 3473.1094 - val_mae: 34.3032\n",
      "Epoch 987/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 20640.0742 - mae: 50.5426 - val_loss: 4002.6577 - val_mae: 39.1418\n",
      "Epoch 988/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 19132.9375 - mae: 49.3848 - val_loss: 3764.0396 - val_mae: 37.4998\n",
      "Epoch 989/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 21686.1309 - mae: 52.0115 - val_loss: 3900.0718 - val_mae: 38.5227\n",
      "Epoch 990/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 18335.0137 - mae: 45.7668 - val_loss: 3452.6357 - val_mae: 33.6518\n",
      "Epoch 991/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 19142.0020 - mae: 47.9810 - val_loss: 3693.9290 - val_mae: 36.6944\n",
      "Epoch 992/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 20613.2637 - mae: 52.5522 - val_loss: 3438.2095 - val_mae: 32.4053\n",
      "Epoch 993/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 19139.7012 - mae: 49.6975 - val_loss: 3432.7739 - val_mae: 33.4670\n",
      "Epoch 994/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 18946.4785 - mae: 50.5580 - val_loss: 3296.6936 - val_mae: 31.7627\n",
      "Epoch 995/1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 19273.1719 - mae: 52.3115 - val_loss: 3347.6611 - val_mae: 32.3117\n",
      "Epoch 996/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 19870.3184 - mae: 49.5414 - val_loss: 3367.0283 - val_mae: 32.5432\n",
      "Epoch 997/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 23271.3242 - mae: 53.3219 - val_loss: 3302.0566 - val_mae: 33.3885\n",
      "Epoch 998/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 19301.4062 - mae: 51.5523 - val_loss: 3355.0688 - val_mae: 32.2633\n",
      "Epoch 999/1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 18972.1289 - mae: 50.4801 - val_loss: 3356.4873 - val_mae: 32.2462\n",
      "Epoch 1000/1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 18676.2930 - mae: 48.6387 - val_loss: 3334.7185 - val_mae: 32.2015\n"
     ]
    }
   ],
   "source": [
    "rnn_history = rnn_model.fit(train_gen,\n",
    "                               epochs=1000,\n",
    "                               validation_data=val_gen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb9eba5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(rnn_history .history['loss'], label='training_loss')\n",
    "plt.plot(rnn_history .history['val_loss'], label='validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d347f649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step - loss: 3334.7185 - mae: 32.2015\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3334.718505859375, 32.20146179199219]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_model.evaluate(val_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ed484c",
   "metadata": {},
   "source": [
    "## We have to try to generate Stateful RNN Module Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e734bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def statefulGenerator(data, target,\n",
    "                      length=1,\n",
    "                      sampling_rate=1,\n",
    "                      stride=1,\n",
    "                      start_index=0,\n",
    "                      end_index=None, \n",
    "                      batch_size=128):\n",
    "        if end_index==None: end_index=len(data)-1\n",
    "            \n",
    "        data_len = ((end_index-start_index+1)-length)//stride \n",
    "        tmp_batch_size = data_len//batch_size  # we can modify it from setting(32) to 1 when prediction\n",
    "\n",
    "        end_index = tmp_batch_size*batch_size*stride + (length-1) + start_index  \n",
    "        data_gen = TimeseriesGenerator(data, target, \n",
    "                               length=length,\n",
    "                               sampling_rate=sampling_rate,\n",
    "                               stride=stride,\n",
    "                               start_index=start_index,\n",
    "                               end_index=end_index,\n",
    "                               batch_size=tmp_batch_size)\n",
    "  \n",
    "        new_data = []\n",
    "        new_target = []\n",
    "\n",
    "        for i in data_gen:\n",
    "            new_data.append(i[0])\n",
    "            new_target.append(i[1])\n",
    "  \n",
    "        new_data = np.array(new_data)\n",
    "        new_target = np.array(new_target)\n",
    "\n",
    "        new_data = new_data.transpose(1, 0, 2, 3)\n",
    "        new_target = new_target.transpose(1, 0, 2)\n",
    "\n",
    "        new_data_gen = []\n",
    "        for i in range(len(new_data)):\n",
    "            new_data_gen.append((new_data[i], new_target[i]))\n",
    "    \n",
    "        return new_data_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d039abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Training Data \n",
    "state_train_gen = statefulGenerator(data, target, \n",
    "                               length=length,\n",
    "                               sampling_rate=sampling_rate,\n",
    "                               stride=stride,\n",
    "                               start_index=0,\n",
    "                               end_index=100,\n",
    "                               batch_size=1)\n",
    "# Create Validation Data \n",
    "state_val_gen = statefulGenerator(data, target, \n",
    "                               length=length,\n",
    "                               sampling_rate=sampling_rate,\n",
    "                               stride=stride,\n",
    "                               start_index=101,\n",
    "                               end_index=135,\n",
    "                               batch_size=1)\n",
    "# # Create Testing Data \n",
    "# state_test_gen = statefulGenerator(data, target, \n",
    "#                                length=length,\n",
    "#                                sampling_rate=sampling_rate,\n",
    "#                                stride=stride,\n",
    "#                                start_index=130001,\n",
    "#                                end_index=None,\n",
    "#                                batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d22a96b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_1 (SimpleRNN)     (1, 10)                   120       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (1, 10)                   110       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (1, 1)                    11        \n",
      "=================================================================\n",
      "Total params: 241\n",
      "Trainable params: 241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "state_model = Sequential([\n",
    "              layers.SimpleRNN(10, stateful=True, batch_input_shape=(1, 3, 1)),\n",
    "              layers.Dense(10, activation='relu'),\n",
    "              layers.Dense(1)\n",
    "])\n",
    "state_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ee33cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 2s 4ms/step - loss: 49090.9023 - mae: 81.2411 - val_loss: 6629.0840 - val_mae: 60.0311\n",
      "Epoch 2 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 48890.3984 - mae: 80.0772 - val_loss: 6498.6050 - val_mae: 58.9343\n",
      "Epoch 3 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 48709.8164 - mae: 78.9069 - val_loss: 6352.9014 - val_mae: 57.6849\n",
      "Epoch 4 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 48508.5391 - mae: 77.5887 - val_loss: 6194.8853 - val_mae: 56.2985\n",
      "Epoch 5 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 48290.2617 - mae: 76.1399 - val_loss: 6027.7119 - val_mae: 54.7937\n",
      "Epoch 6 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 48058.8945 - mae: 74.5795 - val_loss: 5854.6216 - val_mae: 53.1908\n",
      "Epoch 7 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 47818.4336 - mae: 72.9283 - val_loss: 5678.8643 - val_mae: 51.5122\n",
      "Epoch 8 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 47573.0664 - mae: 71.2609 - val_loss: 5503.6084 - val_mae: 49.7820\n",
      "Epoch 9 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 47326.8320 - mae: 69.6099 - val_loss: 5331.8291 - val_mae: 48.0257\n",
      "Epoch 10 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 47083.6289 - mae: 68.0215 - val_loss: 5166.1924 - val_mae: 46.2914\n",
      "Epoch 11 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 46847.0508 - mae: 66.5489 - val_loss: 5008.9458 - val_mae: 44.6679\n",
      "Epoch 12 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 46620.2812 - mae: 65.1786 - val_loss: 4861.8198 - val_mae: 43.1860\n",
      "Epoch 13 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 46405.8125 - mae: 63.9772 - val_loss: 4725.9824 - val_mae: 41.9602\n",
      "Epoch 14 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 46205.5703 - mae: 62.9610 - val_loss: 4602.0254 - val_mae: 40.8691\n",
      "Epoch 15 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 46020.6367 - mae: 62.2975 - val_loss: 4490.0278 - val_mae: 39.9662\n",
      "Epoch 16 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 45851.5352 - mae: 61.8214 - val_loss: 4389.6475 - val_mae: 39.1320\n",
      "Epoch 17 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 45698.0977 - mae: 61.3997 - val_loss: 4300.2432 - val_mae: 38.4203\n",
      "Epoch 18 / 1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 45559.7852 - mae: 61.0416 - val_loss: 4220.9829 - val_mae: 37.7859\n",
      "Epoch 19 / 1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 45435.6523 - mae: 60.7626 - val_loss: 4150.9463 - val_mae: 37.2124\n",
      "Epoch 20 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 45324.6836 - mae: 60.5840 - val_loss: 4089.1907 - val_mae: 36.7457\n",
      "Epoch 21 / 1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 45225.7461 - mae: 60.4529 - val_loss: 4034.8081 - val_mae: 36.3234\n",
      "Epoch 22 / 1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 45137.6875 - mae: 60.3710 - val_loss: 3986.9419 - val_mae: 35.9422\n",
      "Epoch 23 / 1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 45059.3711 - mae: 60.3126 - val_loss: 3944.8162 - val_mae: 35.5988\n",
      "Epoch 24 / 1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 44989.8164 - mae: 60.2622 - val_loss: 3907.7312 - val_mae: 35.2899\n",
      "Epoch 25 / 1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 44928.0000 - mae: 60.2275 - val_loss: 3875.0642 - val_mae: 35.0421\n",
      "Epoch 26 / 1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 44873.1172 - mae: 60.2052 - val_loss: 3846.2710 - val_mae: 34.8241\n",
      "Epoch 27 / 1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 44824.3828 - mae: 60.1882 - val_loss: 3820.8694 - val_mae: 34.6287\n",
      "Epoch 28 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44781.0703 - mae: 60.1815 - val_loss: 3798.4407 - val_mae: 34.4535\n",
      "Epoch 29 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44742.5547 - mae: 60.1758 - val_loss: 3778.6191 - val_mae: 34.3077\n",
      "Epoch 30 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44708.3555 - mae: 60.1746 - val_loss: 3761.0864 - val_mae: 34.1872\n",
      "Epoch 31 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44677.8945 - mae: 60.1809 - val_loss: 3745.5640 - val_mae: 34.0794\n",
      "Epoch 32 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44650.7852 - mae: 60.1944 - val_loss: 3731.8098 - val_mae: 33.9828\n",
      "Epoch 33 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44626.6680 - mae: 60.2073 - val_loss: 3719.6135 - val_mae: 33.8964\n",
      "Epoch 34 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44605.2031 - mae: 60.2227 - val_loss: 3708.7888 - val_mae: 33.8191\n",
      "Epoch 35 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44586.0820 - mae: 60.2423 - val_loss: 3699.1772 - val_mae: 33.7499\n",
      "Epoch 36 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44569.0312 - mae: 60.2619 - val_loss: 3690.6357 - val_mae: 33.6880\n",
      "Epoch 37 / 1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 44553.8438 - mae: 60.2794 - val_loss: 3683.0415 - val_mae: 33.6326\n",
      "Epoch 38 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44540.3164 - mae: 60.2951 - val_loss: 3676.2852 - val_mae: 33.5831\n",
      "Epoch 39 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44528.2227 - mae: 60.3112 - val_loss: 3670.2715 - val_mae: 33.5388\n",
      "Epoch 40 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44517.4531 - mae: 60.3262 - val_loss: 3664.9160 - val_mae: 33.4992\n",
      "Epoch 41 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44507.8477 - mae: 60.3395 - val_loss: 3660.1455 - val_mae: 33.4637\n",
      "Epoch 42 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44499.2500 - mae: 60.3515 - val_loss: 3655.8936 - val_mae: 33.4320\n",
      "Epoch 43 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44491.6016 - mae: 60.3622 - val_loss: 3652.1030 - val_mae: 33.4037\n",
      "Epoch 44 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44484.7344 - mae: 60.3717 - val_loss: 3648.7231 - val_mae: 33.3783\n",
      "Epoch 45 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44478.6289 - mae: 60.3803 - val_loss: 3645.7080 - val_mae: 33.3557\n",
      "Epoch 46 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44473.1953 - mae: 60.3880 - val_loss: 3643.0168 - val_mae: 33.3354\n",
      "Epoch 47 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44468.3281 - mae: 60.3948 - val_loss: 3640.6155 - val_mae: 33.3173\n",
      "Epoch 48 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44463.9805 - mae: 60.4009 - val_loss: 3638.4731 - val_mae: 33.3010\n",
      "Epoch 49 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44460.0938 - mae: 60.4063 - val_loss: 3636.5591 - val_mae: 33.2866\n",
      "Epoch 50 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44456.5977 - mae: 60.4113 - val_loss: 3634.8506 - val_mae: 33.2736\n",
      "Epoch 51 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44453.4961 - mae: 60.4156 - val_loss: 3633.3250 - val_mae: 33.2620\n",
      "Epoch 52 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44450.7188 - mae: 60.4195 - val_loss: 3631.9629 - val_mae: 33.2516\n",
      "Epoch 53 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44448.2617 - mae: 60.4230 - val_loss: 3630.7451 - val_mae: 33.2449\n",
      "Epoch 54 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44446.0039 - mae: 60.4262 - val_loss: 3629.6567 - val_mae: 33.2394\n",
      "Epoch 55 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44444.0547 - mae: 60.4290 - val_loss: 3628.6853 - val_mae: 33.2344\n",
      "Epoch 56 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44442.2812 - mae: 60.4315 - val_loss: 3627.8174 - val_mae: 33.2300\n",
      "Epoch 57 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44440.6953 - mae: 60.4337 - val_loss: 3627.0405 - val_mae: 33.2260\n",
      "Epoch 58 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44439.2891 - mae: 60.4357 - val_loss: 3626.3477 - val_mae: 33.2225\n",
      "Epoch 59 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44438.0000 - mae: 60.4375 - val_loss: 3625.7280 - val_mae: 33.2194\n",
      "Epoch 60 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44436.8711 - mae: 60.4391 - val_loss: 3625.1743 - val_mae: 33.2165\n",
      "Epoch 61 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44435.8711 - mae: 60.4405 - val_loss: 3624.6785 - val_mae: 33.2140\n",
      "Epoch 62 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44434.9883 - mae: 60.4418 - val_loss: 3624.2361 - val_mae: 33.2117\n",
      "Epoch 63 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44434.1445 - mae: 60.4429 - val_loss: 3623.8396 - val_mae: 33.2097\n",
      "Epoch 64 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44433.4336 - mae: 60.4439 - val_loss: 3623.4861 - val_mae: 33.2079\n",
      "Epoch 65 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44432.7969 - mae: 60.4449 - val_loss: 3623.1692 - val_mae: 33.2063\n",
      "Epoch 66 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44432.2148 - mae: 60.4457 - val_loss: 3622.8862 - val_mae: 33.2048\n",
      "Epoch 67 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44431.6992 - mae: 60.4464 - val_loss: 3622.6331 - val_mae: 33.2035\n",
      "Epoch 68 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44431.2344 - mae: 60.4471 - val_loss: 3622.4067 - val_mae: 33.2024\n",
      "Epoch 69 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44430.8008 - mae: 60.4477 - val_loss: 3622.2046 - val_mae: 33.2014\n",
      "Epoch 70 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44430.4336 - mae: 60.4482 - val_loss: 3622.0244 - val_mae: 33.2004\n",
      "Epoch 71 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44430.0977 - mae: 60.4486 - val_loss: 3621.8625 - val_mae: 33.1996\n",
      "Epoch 72 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44429.8125 - mae: 60.4491 - val_loss: 3621.7183 - val_mae: 33.1989\n",
      "Epoch 73 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44429.5625 - mae: 60.4494 - val_loss: 3621.5884 - val_mae: 33.1982\n",
      "Epoch 74 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44429.3438 - mae: 60.4498 - val_loss: 3621.4734 - val_mae: 33.1976\n",
      "Epoch 75 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44429.1133 - mae: 60.4501 - val_loss: 3621.3687 - val_mae: 33.1971\n",
      "Epoch 76 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44428.9219 - mae: 60.4503 - val_loss: 3621.2766 - val_mae: 33.1966\n",
      "Epoch 77 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44428.7539 - mae: 60.4506 - val_loss: 3621.1938 - val_mae: 33.1962\n",
      "Epoch 78 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44428.5977 - mae: 60.4508 - val_loss: 3621.1206 - val_mae: 33.1958\n",
      "Epoch 79 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44428.4844 - mae: 60.4510 - val_loss: 3621.0542 - val_mae: 33.1955\n",
      "Epoch 80 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44428.3789 - mae: 60.4511 - val_loss: 3620.9956 - val_mae: 33.1952\n",
      "Epoch 81 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44428.2461 - mae: 60.4513 - val_loss: 3620.9438 - val_mae: 33.1949\n",
      "Epoch 82 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44428.1523 - mae: 60.4514 - val_loss: 3620.8967 - val_mae: 33.1947\n",
      "Epoch 83 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44428.0703 - mae: 60.4516 - val_loss: 3620.8547 - val_mae: 33.1944\n",
      "Epoch 84 / 1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 44427.9844 - mae: 60.4517 - val_loss: 3620.8176 - val_mae: 33.1942\n",
      "Epoch 85 / 1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 44427.9141 - mae: 60.4518 - val_loss: 3620.7832 - val_mae: 33.1941\n",
      "Epoch 86 / 1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 44427.8516 - mae: 60.4519 - val_loss: 3620.7532 - val_mae: 33.1939\n",
      "Epoch 87 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.7969 - mae: 60.4519 - val_loss: 3620.7263 - val_mae: 33.1938\n",
      "Epoch 88 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.7500 - mae: 60.4520 - val_loss: 3620.7024 - val_mae: 33.1937\n",
      "Epoch 89 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.7109 - mae: 60.4521 - val_loss: 3620.6807 - val_mae: 33.1936\n",
      "Epoch 90 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.6680 - mae: 60.4521 - val_loss: 3620.6619 - val_mae: 33.1935\n",
      "Epoch 91 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.6484 - mae: 60.4522 - val_loss: 3620.6448 - val_mae: 33.1934\n",
      "Epoch 92 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.6055 - mae: 60.4522 - val_loss: 3620.6292 - val_mae: 33.1933\n",
      "Epoch 93 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.5703 - mae: 60.4523 - val_loss: 3620.6150 - val_mae: 33.1932\n",
      "Epoch 94 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.5391 - mae: 60.4523 - val_loss: 3620.6021 - val_mae: 33.1931\n",
      "Epoch 95 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.5039 - mae: 60.4523 - val_loss: 3620.5906 - val_mae: 33.1931\n",
      "Epoch 96 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.4961 - mae: 60.4524 - val_loss: 3620.5798 - val_mae: 33.1930\n",
      "Epoch 97 / 1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 44427.4805 - mae: 60.4524 - val_loss: 3620.5703 - val_mae: 33.1930\n",
      "Epoch 98 / 1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 44427.4492 - mae: 60.4524 - val_loss: 3620.5623 - val_mae: 33.1929\n",
      "Epoch 99 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.4336 - mae: 60.4524 - val_loss: 3620.5544 - val_mae: 33.1929\n",
      "Epoch 100 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.4219 - mae: 60.4525 - val_loss: 3620.5471 - val_mae: 33.1929\n",
      "Epoch 101 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.4219 - mae: 60.4525 - val_loss: 3620.5422 - val_mae: 33.1928\n",
      "Epoch 102 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.4062 - mae: 60.4525 - val_loss: 3620.5371 - val_mae: 33.1928\n",
      "Epoch 103 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.4023 - mae: 60.4525 - val_loss: 3620.5339 - val_mae: 33.1928\n",
      "Epoch 104 / 1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 44427.3945 - mae: 60.4525 - val_loss: 3620.5295 - val_mae: 33.1928\n",
      "Epoch 105 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3789 - mae: 60.4525 - val_loss: 3620.5273 - val_mae: 33.1928\n",
      "Epoch 106 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3711 - mae: 60.4525 - val_loss: 3620.5239 - val_mae: 33.1927\n",
      "Epoch 107 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3672 - mae: 60.4525 - val_loss: 3620.5215 - val_mae: 33.1927\n",
      "Epoch 108 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3633 - mae: 60.4526 - val_loss: 3620.5198 - val_mae: 33.1927\n",
      "Epoch 109 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3555 - mae: 60.4526 - val_loss: 3620.5181 - val_mae: 33.1927\n",
      "Epoch 110 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3477 - mae: 60.4526 - val_loss: 3620.5159 - val_mae: 33.1927\n",
      "Epoch 111 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3477 - mae: 60.4525 - val_loss: 3620.5142 - val_mae: 33.1927\n",
      "Epoch 112 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3438 - mae: 60.4525 - val_loss: 3620.5127 - val_mae: 33.1927\n",
      "Epoch 113 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3359 - mae: 60.4526 - val_loss: 3620.5115 - val_mae: 33.1927\n",
      "Epoch 114 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3320 - mae: 60.4526 - val_loss: 3620.5105 - val_mae: 33.1927\n",
      "Epoch 115 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3281 - mae: 60.4526 - val_loss: 3620.5093 - val_mae: 33.1927\n",
      "Epoch 116 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3281 - mae: 60.4526 - val_loss: 3620.5085 - val_mae: 33.1927\n",
      "Epoch 117 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3281 - mae: 60.4526 - val_loss: 3620.5076 - val_mae: 33.1927\n",
      "Epoch 118 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3281 - mae: 60.4526 - val_loss: 3620.5073 - val_mae: 33.1927\n",
      "Epoch 119 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3203 - mae: 60.4526 - val_loss: 3620.5061 - val_mae: 33.1927\n",
      "Epoch 120 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3203 - mae: 60.4526 - val_loss: 3620.5056 - val_mae: 33.1927\n",
      "Epoch 121 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3203 - mae: 60.4526 - val_loss: 3620.5044 - val_mae: 33.1927\n",
      "Epoch 122 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3203 - mae: 60.4526 - val_loss: 3620.5039 - val_mae: 33.1926\n",
      "Epoch 123 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5039 - val_mae: 33.1926\n",
      "Epoch 124 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5032 - val_mae: 33.1926\n",
      "Epoch 125 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3203 - mae: 60.4526 - val_loss: 3620.5029 - val_mae: 33.1926\n",
      "Epoch 126 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3203 - mae: 60.4526 - val_loss: 3620.5024 - val_mae: 33.1926\n",
      "Epoch 127 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3281 - mae: 60.4526 - val_loss: 3620.5020 - val_mae: 33.1926\n",
      "Epoch 128 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3281 - mae: 60.4526 - val_loss: 3620.5020 - val_mae: 33.1926\n",
      "Epoch 129 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3203 - mae: 60.4526 - val_loss: 3620.5017 - val_mae: 33.1926\n",
      "Epoch 130 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3203 - mae: 60.4526 - val_loss: 3620.5015 - val_mae: 33.1926\n",
      "Epoch 131 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3203 - mae: 60.4526 - val_loss: 3620.5010 - val_mae: 33.1926\n",
      "Epoch 132 / 1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 44427.3203 - mae: 60.4526 - val_loss: 3620.5010 - val_mae: 33.1926\n",
      "Epoch 133 / 1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 44427.3203 - mae: 60.4526 - val_loss: 3620.5002 - val_mae: 33.1926\n",
      "Epoch 134 / 1000\n",
      "98/98 [==============================] - ETA: 0s - loss: 47791.2695 - mae: 63.303 - 0s 2ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5002 - val_mae: 33.1926\n",
      "Epoch 135 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.4998 - val_mae: 33.1926\n",
      "Epoch 136 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.4998 - val_mae: 33.1926\n",
      "Epoch 137 / 1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.4993 - val_mae: 33.1926\n",
      "Epoch 138 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.4993 - val_mae: 33.1926\n",
      "Epoch 139 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.4988 - val_mae: 33.1926\n",
      "Epoch 140 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.4993 - val_mae: 33.1926\n",
      "Epoch 141 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.4988 - val_mae: 33.1926\n",
      "Epoch 142 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.4988 - val_mae: 33.1926\n",
      "Epoch 143 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.4988 - val_mae: 33.1926\n",
      "Epoch 144 / 1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.4988 - val_mae: 33.1926\n",
      "Epoch 145 / 1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.4988 - val_mae: 33.1926\n",
      "Epoch 146 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.4988 - val_mae: 33.1926\n",
      "Epoch 147 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.4985 - val_mae: 33.1926\n",
      "Epoch 148 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.4985 - val_mae: 33.1926\n",
      "Epoch 149 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.4985 - val_mae: 33.1926\n",
      "Epoch 150 / 1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.4985 - val_mae: 33.1926\n",
      "Epoch 151 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.4988 - val_mae: 33.1926\n",
      "Epoch 152 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.4988 - val_mae: 33.1926\n",
      "Epoch 153 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.4988 - val_mae: 33.1926\n",
      "Epoch 154 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.4985 - val_mae: 33.1926\n",
      "Epoch 155 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.4988 - val_mae: 33.1926\n",
      "Epoch 156 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.4988 - val_mae: 33.1926\n",
      "Epoch 157 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.4988 - val_mae: 33.1926\n",
      "Epoch 158 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.4993 - val_mae: 33.1926\n",
      "Epoch 159 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.4988 - val_mae: 33.1926\n",
      "Epoch 160 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.4988 - val_mae: 33.1926\n",
      "Epoch 161 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.4993 - val_mae: 33.1926\n",
      "Epoch 162 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.4993 - val_mae: 33.1926\n",
      "Epoch 163 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.4993 - val_mae: 33.1926\n",
      "Epoch 164 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.4993 - val_mae: 33.1926\n",
      "Epoch 165 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.4993 - val_mae: 33.1926\n",
      "Epoch 166 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.4993 - val_mae: 33.1926\n",
      "Epoch 167 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.4998 - val_mae: 33.1926\n",
      "Epoch 168 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.4993 - val_mae: 33.1926\n",
      "Epoch 169 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.4993 - val_mae: 33.1926\n",
      "Epoch 170 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.4993 - val_mae: 33.1926\n",
      "Epoch 171 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.4998 - val_mae: 33.1926\n",
      "Epoch 172 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.4998 - val_mae: 33.1926\n",
      "Epoch 173 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.4998 - val_mae: 33.1926\n",
      "Epoch 174 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.4998 - val_mae: 33.1926\n",
      "Epoch 175 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.4998 - val_mae: 33.1926\n",
      "Epoch 176 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.4998 - val_mae: 33.1926\n",
      "Epoch 177 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.4998 - val_mae: 33.1926\n",
      "Epoch 178 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.4998 - val_mae: 33.1926\n",
      "Epoch 179 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.4998 - val_mae: 33.1926\n",
      "Epoch 180 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.4998 - val_mae: 33.1926\n",
      "Epoch 181 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.4998 - val_mae: 33.1926\n",
      "Epoch 182 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.4998 - val_mae: 33.1926\n",
      "Epoch 183 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.4998 - val_mae: 33.1926\n",
      "Epoch 184 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.4998 - val_mae: 33.1926\n",
      "Epoch 185 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.4998 - val_mae: 33.1926\n",
      "Epoch 186 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.4998 - val_mae: 33.1926\n",
      "Epoch 187 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5002 - val_mae: 33.1926\n",
      "Epoch 188 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5002 - val_mae: 33.1926\n",
      "Epoch 189 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5002 - val_mae: 33.1926\n",
      "Epoch 190 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5002 - val_mae: 33.1926\n",
      "Epoch 191 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5002 - val_mae: 33.1926\n",
      "Epoch 192 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5002 - val_mae: 33.1926\n",
      "Epoch 193 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5010 - val_mae: 33.1926\n",
      "Epoch 194 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5002 - val_mae: 33.1926\n",
      "Epoch 195 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5010 - val_mae: 33.1926\n",
      "Epoch 196 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5010 - val_mae: 33.1926\n",
      "Epoch 197 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5002 - val_mae: 33.1926\n",
      "Epoch 198 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5010 - val_mae: 33.1926\n",
      "Epoch 199 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5010 - val_mae: 33.1926\n",
      "Epoch 200 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5010 - val_mae: 33.1926\n",
      "Epoch 201 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5010 - val_mae: 33.1926\n",
      "Epoch 202 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5010 - val_mae: 33.1926\n",
      "Epoch 203 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5015 - val_mae: 33.1926\n",
      "Epoch 204 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5010 - val_mae: 33.1926\n",
      "Epoch 205 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5010 - val_mae: 33.1926\n",
      "Epoch 206 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5015 - val_mae: 33.1926\n",
      "Epoch 207 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5010 - val_mae: 33.1926\n",
      "Epoch 208 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5010 - val_mae: 33.1926\n",
      "Epoch 209 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5015 - val_mae: 33.1926\n",
      "Epoch 210 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5015 - val_mae: 33.1926\n",
      "Epoch 211 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5015 - val_mae: 33.1926\n",
      "Epoch 212 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5015 - val_mae: 33.1926\n",
      "Epoch 213 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5015 - val_mae: 33.1926\n",
      "Epoch 214 / 1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5017 - val_mae: 33.1926\n",
      "Epoch 215 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5017 - val_mae: 33.1926\n",
      "Epoch 216 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5017 - val_mae: 33.1926\n",
      "Epoch 217 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5017 - val_mae: 33.1926\n",
      "Epoch 218 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5017 - val_mae: 33.1926\n",
      "Epoch 219 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5020 - val_mae: 33.1926\n",
      "Epoch 220 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5020 - val_mae: 33.1926\n",
      "Epoch 221 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5020 - val_mae: 33.1926\n",
      "Epoch 222 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5020 - val_mae: 33.1926\n",
      "Epoch 223 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5017 - val_mae: 33.1926\n",
      "Epoch 224 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5020 - val_mae: 33.1926\n",
      "Epoch 225 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5024 - val_mae: 33.1926\n",
      "Epoch 226 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5020 - val_mae: 33.1926\n",
      "Epoch 227 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5020 - val_mae: 33.1926\n",
      "Epoch 228 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5020 - val_mae: 33.1926\n",
      "Epoch 229 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5020 - val_mae: 33.1926\n",
      "Epoch 230 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5024 - val_mae: 33.1926\n",
      "Epoch 231 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5020 - val_mae: 33.1926\n",
      "Epoch 232 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5020 - val_mae: 33.1926\n",
      "Epoch 233 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5020 - val_mae: 33.1926\n",
      "Epoch 234 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5020 - val_mae: 33.1926\n",
      "Epoch 235 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5024 - val_mae: 33.1926\n",
      "Epoch 236 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5020 - val_mae: 33.1926\n",
      "Epoch 237 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5024 - val_mae: 33.1926\n",
      "Epoch 238 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5024 - val_mae: 33.1926\n",
      "Epoch 239 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5024 - val_mae: 33.1926\n",
      "Epoch 240 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5020 - val_mae: 33.1926\n",
      "Epoch 241 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5027 - val_mae: 33.1926\n",
      "Epoch 242 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5024 - val_mae: 33.1926\n",
      "Epoch 243 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5024 - val_mae: 33.1926\n",
      "Epoch 244 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5024 - val_mae: 33.1926\n",
      "Epoch 245 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5020 - val_mae: 33.1926\n",
      "Epoch 246 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5020 - val_mae: 33.1926\n",
      "Epoch 247 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5024 - val_mae: 33.1926\n",
      "Epoch 248 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5027 - val_mae: 33.1926\n",
      "Epoch 249 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5024 - val_mae: 33.1926\n",
      "Epoch 250 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5024 - val_mae: 33.1926\n",
      "Epoch 251 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5024 - val_mae: 33.1926\n",
      "Epoch 252 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5027 - val_mae: 33.1926\n",
      "Epoch 253 / 1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5024 - val_mae: 33.1926\n",
      "Epoch 254 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5024 - val_mae: 33.1926\n",
      "Epoch 255 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5020 - val_mae: 33.1926\n",
      "Epoch 256 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5024 - val_mae: 33.1926\n",
      "Epoch 257 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5024 - val_mae: 33.1926\n",
      "Epoch 258 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5024 - val_mae: 33.1926\n",
      "Epoch 259 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5024 - val_mae: 33.1926\n",
      "Epoch 260 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5024 - val_mae: 33.1926\n",
      "Epoch 261 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5024 - val_mae: 33.1926\n",
      "Epoch 262 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5027 - val_mae: 33.1926\n",
      "Epoch 263 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5027 - val_mae: 33.1926\n",
      "Epoch 264 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5024 - val_mae: 33.1926\n",
      "Epoch 265 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5027 - val_mae: 33.1926\n",
      "Epoch 266 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5024 - val_mae: 33.1926\n",
      "Epoch 267 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5027 - val_mae: 33.1926\n",
      "Epoch 268 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5024 - val_mae: 33.1926\n",
      "Epoch 269 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5024 - val_mae: 33.1926\n",
      "Epoch 270 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5029 - val_mae: 33.1926\n",
      "Epoch 271 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5024 - val_mae: 33.1926\n",
      "Epoch 272 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5029 - val_mae: 33.1926\n",
      "Epoch 273 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5024 - val_mae: 33.1926\n",
      "Epoch 274 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5029 - val_mae: 33.1926\n",
      "Epoch 275 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5024 - val_mae: 33.1926\n",
      "Epoch 276 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5029 - val_mae: 33.1926\n",
      "Epoch 277 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5029 - val_mae: 33.1926\n",
      "Epoch 278 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5029 - val_mae: 33.1926\n",
      "Epoch 279 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5029 - val_mae: 33.1926\n",
      "Epoch 280 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5024 - val_mae: 33.1926\n",
      "Epoch 281 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5024 - val_mae: 33.1926\n",
      "Epoch 282 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5027 - val_mae: 33.1926\n",
      "Epoch 283 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5027 - val_mae: 33.1926\n",
      "Epoch 284 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5027 - val_mae: 33.1926\n",
      "Epoch 285 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5027 - val_mae: 33.1926\n",
      "Epoch 286 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5024 - val_mae: 33.1926\n",
      "Epoch 287 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5024 - val_mae: 33.1926\n",
      "Epoch 288 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5020 - val_mae: 33.1926\n",
      "Epoch 289 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5020 - val_mae: 33.1926\n",
      "Epoch 290 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3164 - mae: 60.4526 - val_loss: 3620.5020 - val_mae: 33.1926\n",
      "Epoch 291 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3125 - mae: 60.4526 - val_loss: 3620.5017 - val_mae: 33.1926\n",
      "Epoch 292 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3125 - mae: 60.4526 - val_loss: 3620.5017 - val_mae: 33.1926\n",
      "Epoch 293 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3125 - mae: 60.4526 - val_loss: 3620.5017 - val_mae: 33.1926\n",
      "Epoch 294 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3125 - mae: 60.4526 - val_loss: 3620.5012 - val_mae: 33.1926\n",
      "Epoch 295 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3125 - mae: 60.4526 - val_loss: 3620.5012 - val_mae: 33.1926\n",
      "Epoch 296 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3125 - mae: 60.4526 - val_loss: 3620.5010 - val_mae: 33.1926\n",
      "Epoch 297 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3125 - mae: 60.4526 - val_loss: 3620.5010 - val_mae: 33.1926\n",
      "Epoch 298 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3125 - mae: 60.4526 - val_loss: 3620.5010 - val_mae: 33.1926\n",
      "Epoch 299 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3125 - mae: 60.4526 - val_loss: 3620.5010 - val_mae: 33.1926\n",
      "Epoch 300 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3125 - mae: 60.4526 - val_loss: 3620.5002 - val_mae: 33.1926\n",
      "Epoch 301 / 1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 44427.3125 - mae: 60.4526 - val_loss: 3620.5002 - val_mae: 33.1926\n",
      "Epoch 302 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3125 - mae: 60.4526 - val_loss: 3620.4998 - val_mae: 33.1926\n",
      "Epoch 303 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3125 - mae: 60.4526 - val_loss: 3620.4998 - val_mae: 33.1926\n",
      "Epoch 304 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3125 - mae: 60.4526 - val_loss: 3620.4998 - val_mae: 33.1926\n",
      "Epoch 305 / 1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 44427.3125 - mae: 60.4526 - val_loss: 3620.4998 - val_mae: 33.1926\n",
      "Epoch 306 / 1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 44427.3125 - mae: 60.4526 - val_loss: 3620.4993 - val_mae: 33.1926\n",
      "Epoch 307 / 1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 44427.3125 - mae: 60.4526 - val_loss: 3620.4993 - val_mae: 33.1926\n",
      "Epoch 308 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3125 - mae: 60.4526 - val_loss: 3620.4993 - val_mae: 33.1926\n",
      "Epoch 309 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3125 - mae: 60.4526 - val_loss: 3620.4988 - val_mae: 33.1926\n",
      "Epoch 310 / 1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 44427.3125 - mae: 60.4526 - val_loss: 3620.4985 - val_mae: 33.1926\n",
      "Epoch 311 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3125 - mae: 60.4526 - val_loss: 3620.4985 - val_mae: 33.1926\n",
      "Epoch 312 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3125 - mae: 60.4526 - val_loss: 3620.4978 - val_mae: 33.1926\n",
      "Epoch 313 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3125 - mae: 60.4526 - val_loss: 3620.4976 - val_mae: 33.1926\n",
      "Epoch 314 / 1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 44427.3125 - mae: 60.4526 - val_loss: 3620.4976 - val_mae: 33.1926\n",
      "Epoch 315 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3047 - mae: 60.4526 - val_loss: 3620.4971 - val_mae: 33.1926\n",
      "Epoch 316 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3008 - mae: 60.4526 - val_loss: 3620.4971 - val_mae: 33.1926\n",
      "Epoch 317 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3008 - mae: 60.4526 - val_loss: 3620.4971 - val_mae: 33.1926\n",
      "Epoch 318 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3008 - mae: 60.4526 - val_loss: 3620.4966 - val_mae: 33.1926\n",
      "Epoch 319 / 1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 44427.3008 - mae: 60.4526 - val_loss: 3620.4966 - val_mae: 33.1926\n",
      "Epoch 320 / 1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 44427.3008 - mae: 60.4526 - val_loss: 3620.4961 - val_mae: 33.1926\n",
      "Epoch 321 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3008 - mae: 60.4526 - val_loss: 3620.4961 - val_mae: 33.1926\n",
      "Epoch 322 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3008 - mae: 60.4526 - val_loss: 3620.4958 - val_mae: 33.1926\n",
      "Epoch 323 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3008 - mae: 60.4526 - val_loss: 3620.4954 - val_mae: 33.1926\n",
      "Epoch 324 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.2969 - mae: 60.4526 - val_loss: 3620.4954 - val_mae: 33.1926\n",
      "Epoch 325 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.2969 - mae: 60.4526 - val_loss: 3620.4949 - val_mae: 33.1926\n",
      "Epoch 326 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.2969 - mae: 60.4526 - val_loss: 3620.4949 - val_mae: 33.1926\n",
      "Epoch 327 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.2969 - mae: 60.4526 - val_loss: 3620.4949 - val_mae: 33.1926\n",
      "Epoch 328 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.2969 - mae: 60.4526 - val_loss: 3620.4949 - val_mae: 33.1926\n",
      "Epoch 329 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.2969 - mae: 60.4526 - val_loss: 3620.4949 - val_mae: 33.1926\n",
      "Epoch 330 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.2969 - mae: 60.4526 - val_loss: 3620.4944 - val_mae: 33.1926\n",
      "Epoch 331 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.2969 - mae: 60.4526 - val_loss: 3620.4944 - val_mae: 33.1926\n",
      "Epoch 332 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.2969 - mae: 60.4526 - val_loss: 3620.4944 - val_mae: 33.1926\n",
      "Epoch 333 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3008 - mae: 60.4526 - val_loss: 3620.4939 - val_mae: 33.1926\n",
      "Epoch 334 / 1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 44427.3008 - mae: 60.4526 - val_loss: 3620.4934 - val_mae: 33.1926\n",
      "Epoch 335 / 1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 44427.3008 - mae: 60.4526 - val_loss: 3620.4934 - val_mae: 33.1926\n",
      "Epoch 336 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3008 - mae: 60.4526 - val_loss: 3620.4929 - val_mae: 33.1926\n",
      "Epoch 337 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3047 - mae: 60.4526 - val_loss: 3620.4929 - val_mae: 33.1926\n",
      "Epoch 338 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3008 - mae: 60.4526 - val_loss: 3620.4929 - val_mae: 33.1926\n",
      "Epoch 339 / 1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 44427.3047 - mae: 60.4526 - val_loss: 3620.4929 - val_mae: 33.1926\n",
      "Epoch 340 / 1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 44427.3047 - mae: 60.4526 - val_loss: 3620.4924 - val_mae: 33.1926\n",
      "Epoch 341 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3047 - mae: 60.4526 - val_loss: 3620.4924 - val_mae: 33.1926\n",
      "Epoch 342 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3047 - mae: 60.4526 - val_loss: 3620.4919 - val_mae: 33.1926\n",
      "Epoch 343 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3008 - mae: 60.4526 - val_loss: 3620.4915 - val_mae: 33.1926\n",
      "Epoch 344 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3008 - mae: 60.4526 - val_loss: 3620.4912 - val_mae: 33.1926\n",
      "Epoch 345 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3008 - mae: 60.4526 - val_loss: 3620.4912 - val_mae: 33.1926\n",
      "Epoch 346 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3008 - mae: 60.4526 - val_loss: 3620.4912 - val_mae: 33.1926\n",
      "Epoch 347 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3008 - mae: 60.4526 - val_loss: 3620.4910 - val_mae: 33.1926\n",
      "Epoch 348 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3008 - mae: 60.4526 - val_loss: 3620.4907 - val_mae: 33.1926\n",
      "Epoch 349 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.3008 - mae: 60.4526 - val_loss: 3620.4907 - val_mae: 33.1926\n",
      "Epoch 350 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3008 - mae: 60.4526 - val_loss: 3620.4902 - val_mae: 33.1926\n",
      "Epoch 351 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3008 - mae: 60.4525 - val_loss: 3620.4900 - val_mae: 33.1926\n",
      "Epoch 352 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3008 - mae: 60.4526 - val_loss: 3620.4890 - val_mae: 33.1926\n",
      "Epoch 353 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.3008 - mae: 60.4526 - val_loss: 3620.4885 - val_mae: 33.1926\n",
      "Epoch 354 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.2969 - mae: 60.4526 - val_loss: 3620.4885 - val_mae: 33.1926\n",
      "Epoch 355 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.2969 - mae: 60.4526 - val_loss: 3620.4888 - val_mae: 33.1926\n",
      "Epoch 356 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.2969 - mae: 60.4525 - val_loss: 3620.4885 - val_mae: 33.1926\n",
      "Epoch 357 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.2969 - mae: 60.4526 - val_loss: 3620.4873 - val_mae: 33.1926\n",
      "Epoch 358 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.2969 - mae: 60.4525 - val_loss: 3620.4868 - val_mae: 33.1926\n",
      "Epoch 359 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.2969 - mae: 60.4526 - val_loss: 3620.4868 - val_mae: 33.1926\n",
      "Epoch 360 / 1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 44427.2969 - mae: 60.4526 - val_loss: 3620.4868 - val_mae: 33.1926\n",
      "Epoch 361 / 1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 44427.2891 - mae: 60.4526 - val_loss: 3620.4861 - val_mae: 33.1926\n",
      "Epoch 362 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.2891 - mae: 60.4526 - val_loss: 3620.4856 - val_mae: 33.1926\n",
      "Epoch 363 / 1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 44427.2891 - mae: 60.4525 - val_loss: 3620.4854 - val_mae: 33.1926\n",
      "Epoch 364 / 1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 44427.2891 - mae: 60.4525 - val_loss: 3620.4851 - val_mae: 33.1926\n",
      "Epoch 365 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.2852 - mae: 60.4525 - val_loss: 3620.4846 - val_mae: 33.1926\n",
      "Epoch 366 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.2852 - mae: 60.4525 - val_loss: 3620.4844 - val_mae: 33.1926\n",
      "Epoch 367 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.2852 - mae: 60.4525 - val_loss: 3620.4839 - val_mae: 33.1925\n",
      "Epoch 368 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.2852 - mae: 60.4525 - val_loss: 3620.4839 - val_mae: 33.1925\n",
      "Epoch 369 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.2891 - mae: 60.4525 - val_loss: 3620.4829 - val_mae: 33.1925\n",
      "Epoch 370 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.2852 - mae: 60.4525 - val_loss: 3620.4824 - val_mae: 33.1925\n",
      "Epoch 371 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.2852 - mae: 60.4526 - val_loss: 3620.4819 - val_mae: 33.1925\n",
      "Epoch 372 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.2812 - mae: 60.4526 - val_loss: 3620.4810 - val_mae: 33.1925\n",
      "Epoch 373 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.2812 - mae: 60.4525 - val_loss: 3620.4810 - val_mae: 33.1925\n",
      "Epoch 374 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.2812 - mae: 60.4525 - val_loss: 3620.4810 - val_mae: 33.1925\n",
      "Epoch 375 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.2812 - mae: 60.4525 - val_loss: 3620.4795 - val_mae: 33.1925\n",
      "Epoch 376 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.2812 - mae: 60.4525 - val_loss: 3620.4795 - val_mae: 33.1925\n",
      "Epoch 377 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.2812 - mae: 60.4525 - val_loss: 3620.4788 - val_mae: 33.1925\n",
      "Epoch 378 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.2812 - mae: 60.4525 - val_loss: 3620.4783 - val_mae: 33.1925\n",
      "Epoch 379 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.2812 - mae: 60.4525 - val_loss: 3620.4773 - val_mae: 33.1925\n",
      "Epoch 380 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.2773 - mae: 60.4525 - val_loss: 3620.4766 - val_mae: 33.1925\n",
      "Epoch 381 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.2695 - mae: 60.4525 - val_loss: 3620.4761 - val_mae: 33.1925\n",
      "Epoch 382 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.2695 - mae: 60.4525 - val_loss: 3620.4753 - val_mae: 33.1925\n",
      "Epoch 383 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.2695 - mae: 60.4525 - val_loss: 3620.4746 - val_mae: 33.1925\n",
      "Epoch 384 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.2617 - mae: 60.4525 - val_loss: 3620.4736 - val_mae: 33.1925\n",
      "Epoch 385 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.2617 - mae: 60.4525 - val_loss: 3620.4736 - val_mae: 33.1925\n",
      "Epoch 386 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.2617 - mae: 60.4525 - val_loss: 3620.4727 - val_mae: 33.1925\n",
      "Epoch 387 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.2617 - mae: 60.4525 - val_loss: 3620.4724 - val_mae: 33.1925\n",
      "Epoch 388 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.2617 - mae: 60.4525 - val_loss: 3620.4719 - val_mae: 33.1925\n",
      "Epoch 389 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.2617 - mae: 60.4525 - val_loss: 3620.4709 - val_mae: 33.1925\n",
      "Epoch 390 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.2617 - mae: 60.4525 - val_loss: 3620.4709 - val_mae: 33.1925\n",
      "Epoch 391 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.2617 - mae: 60.4525 - val_loss: 3620.4705 - val_mae: 33.1925\n",
      "Epoch 392 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.2617 - mae: 60.4525 - val_loss: 3620.4692 - val_mae: 33.1925\n",
      "Epoch 393 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.2539 - mae: 60.4525 - val_loss: 3620.4680 - val_mae: 33.1925\n",
      "Epoch 394 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.2539 - mae: 60.4525 - val_loss: 3620.4675 - val_mae: 33.1925\n",
      "Epoch 395 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.2539 - mae: 60.4525 - val_loss: 3620.4670 - val_mae: 33.1925\n",
      "Epoch 396 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.2539 - mae: 60.4525 - val_loss: 3620.4666 - val_mae: 33.1925\n",
      "Epoch 397 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.2500 - mae: 60.4525 - val_loss: 3620.4666 - val_mae: 33.1925\n",
      "Epoch 398 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.2461 - mae: 60.4525 - val_loss: 3620.4658 - val_mae: 33.1924\n",
      "Epoch 399 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.2500 - mae: 60.4525 - val_loss: 3620.4646 - val_mae: 33.1925\n",
      "Epoch 400 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.2500 - mae: 60.4525 - val_loss: 3620.4644 - val_mae: 33.1924\n",
      "Epoch 401 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.2500 - mae: 60.4525 - val_loss: 3620.4634 - val_mae: 33.1924\n",
      "Epoch 402 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.2461 - mae: 60.4525 - val_loss: 3620.4629 - val_mae: 33.1924\n",
      "Epoch 403 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.2383 - mae: 60.4525 - val_loss: 3620.4619 - val_mae: 33.1924\n",
      "Epoch 404 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.2461 - mae: 60.4525 - val_loss: 3620.4604 - val_mae: 33.1924\n",
      "Epoch 405 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.2461 - mae: 60.4525 - val_loss: 3620.4602 - val_mae: 33.1924\n",
      "Epoch 406 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.2461 - mae: 60.4525 - val_loss: 3620.4597 - val_mae: 33.1924\n",
      "Epoch 407 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.2461 - mae: 60.4525 - val_loss: 3620.4585 - val_mae: 33.1924\n",
      "Epoch 408 / 1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 44427.2383 - mae: 60.4525 - val_loss: 3620.4580 - val_mae: 33.1924\n",
      "Epoch 409 / 1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 44427.2344 - mae: 60.4525 - val_loss: 3620.4565 - val_mae: 33.1924\n",
      "Epoch 410 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.2344 - mae: 60.4525 - val_loss: 3620.4561 - val_mae: 33.1924\n",
      "Epoch 411 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.2344 - mae: 60.4525 - val_loss: 3620.4551 - val_mae: 33.1924\n",
      "Epoch 412 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.2344 - mae: 60.4525 - val_loss: 3620.4543 - val_mae: 33.1924\n",
      "Epoch 413 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.2305 - mae: 60.4525 - val_loss: 3620.4539 - val_mae: 33.1924\n",
      "Epoch 414 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.2227 - mae: 60.4525 - val_loss: 3620.4526 - val_mae: 33.1924\n",
      "Epoch 415 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.2188 - mae: 60.4525 - val_loss: 3620.4517 - val_mae: 33.1924\n",
      "Epoch 416 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.2148 - mae: 60.4525 - val_loss: 3620.4500 - val_mae: 33.1924\n",
      "Epoch 417 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.2148 - mae: 60.4525 - val_loss: 3620.4490 - val_mae: 33.1924\n",
      "Epoch 418 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.2148 - mae: 60.4525 - val_loss: 3620.4480 - val_mae: 33.1924\n",
      "Epoch 419 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.2188 - mae: 60.4525 - val_loss: 3620.4470 - val_mae: 33.1924\n",
      "Epoch 420 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.2148 - mae: 60.4525 - val_loss: 3620.4460 - val_mae: 33.1924\n",
      "Epoch 421 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.2227 - mae: 60.4525 - val_loss: 3620.4443 - val_mae: 33.1923\n",
      "Epoch 422 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.2227 - mae: 60.4525 - val_loss: 3620.4431 - val_mae: 33.1923\n",
      "Epoch 423 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.2227 - mae: 60.4525 - val_loss: 3620.4419 - val_mae: 33.1923\n",
      "Epoch 424 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.2227 - mae: 60.4525 - val_loss: 3620.4414 - val_mae: 33.1923\n",
      "Epoch 425 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.2227 - mae: 60.4525 - val_loss: 3620.4407 - val_mae: 33.1923\n",
      "Epoch 426 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.2188 - mae: 60.4525 - val_loss: 3620.4390 - val_mae: 33.1923\n",
      "Epoch 427 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.2148 - mae: 60.4525 - val_loss: 3620.4382 - val_mae: 33.1923\n",
      "Epoch 428 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.2148 - mae: 60.4525 - val_loss: 3620.4368 - val_mae: 33.1923\n",
      "Epoch 429 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.2148 - mae: 60.4525 - val_loss: 3620.4358 - val_mae: 33.1923\n",
      "Epoch 430 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.2148 - mae: 60.4525 - val_loss: 3620.4346 - val_mae: 33.1923\n",
      "Epoch 431 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.2148 - mae: 60.4525 - val_loss: 3620.4333 - val_mae: 33.1923\n",
      "Epoch 432 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.2148 - mae: 60.4525 - val_loss: 3620.4324 - val_mae: 33.1923\n",
      "Epoch 433 / 1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 44427.2031 - mae: 60.4524 - val_loss: 3620.4309 - val_mae: 33.1923\n",
      "Epoch 434 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.2031 - mae: 60.4524 - val_loss: 3620.4294 - val_mae: 33.1923\n",
      "Epoch 435 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.1992 - mae: 60.4524 - val_loss: 3620.4292 - val_mae: 33.1923\n",
      "Epoch 436 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.1992 - mae: 60.4524 - val_loss: 3620.4277 - val_mae: 33.1923\n",
      "Epoch 437 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.1992 - mae: 60.4524 - val_loss: 3620.4263 - val_mae: 33.1923\n",
      "Epoch 438 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.1953 - mae: 60.4524 - val_loss: 3620.4248 - val_mae: 33.1923\n",
      "Epoch 439 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.1953 - mae: 60.4524 - val_loss: 3620.4236 - val_mae: 33.1922\n",
      "Epoch 440 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.1875 - mae: 60.4524 - val_loss: 3620.4229 - val_mae: 33.1922\n",
      "Epoch 441 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.1836 - mae: 60.4524 - val_loss: 3620.4214 - val_mae: 33.1922\n",
      "Epoch 442 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.1836 - mae: 60.4525 - val_loss: 3620.4202 - val_mae: 33.1922\n",
      "Epoch 443 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.1836 - mae: 60.4524 - val_loss: 3620.4187 - val_mae: 33.1922\n",
      "Epoch 444 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.1836 - mae: 60.4524 - val_loss: 3620.4175 - val_mae: 33.1922\n",
      "Epoch 445 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.1719 - mae: 60.4524 - val_loss: 3620.4163 - val_mae: 33.1922\n",
      "Epoch 446 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.1719 - mae: 60.4524 - val_loss: 3620.4141 - val_mae: 33.1922\n",
      "Epoch 447 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.1719 - mae: 60.4524 - val_loss: 3620.4121 - val_mae: 33.1922\n",
      "Epoch 448 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.1680 - mae: 60.4524 - val_loss: 3620.4111 - val_mae: 33.1922\n",
      "Epoch 449 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.1641 - mae: 60.4524 - val_loss: 3620.4097 - val_mae: 33.1922\n",
      "Epoch 450 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.1562 - mae: 60.4524 - val_loss: 3620.4077 - val_mae: 33.1922\n",
      "Epoch 451 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.1562 - mae: 60.4524 - val_loss: 3620.4055 - val_mae: 33.1922\n",
      "Epoch 452 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.1523 - mae: 60.4524 - val_loss: 3620.4045 - val_mae: 33.1921\n",
      "Epoch 453 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.1484 - mae: 60.4524 - val_loss: 3620.4023 - val_mae: 33.1921\n",
      "Epoch 454 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.1484 - mae: 60.4524 - val_loss: 3620.4009 - val_mae: 33.1921\n",
      "Epoch 455 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.1484 - mae: 60.4524 - val_loss: 3620.3989 - val_mae: 33.1921\n",
      "Epoch 456 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.1445 - mae: 60.4524 - val_loss: 3620.3970 - val_mae: 33.1921\n",
      "Epoch 457 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.1328 - mae: 60.4524 - val_loss: 3620.3958 - val_mae: 33.1921\n",
      "Epoch 458 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.1328 - mae: 60.4524 - val_loss: 3620.3931 - val_mae: 33.1921\n",
      "Epoch 459 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.1289 - mae: 60.4524 - val_loss: 3620.3918 - val_mae: 33.1921\n",
      "Epoch 460 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.1211 - mae: 60.4524 - val_loss: 3620.3892 - val_mae: 33.1921\n",
      "Epoch 461 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.1172 - mae: 60.4524 - val_loss: 3620.3879 - val_mae: 33.1921\n",
      "Epoch 462 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.1172 - mae: 60.4524 - val_loss: 3620.3865 - val_mae: 33.1921\n",
      "Epoch 463 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.1133 - mae: 60.4524 - val_loss: 3620.3845 - val_mae: 33.1920\n",
      "Epoch 464 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.1133 - mae: 60.4524 - val_loss: 3620.3826 - val_mae: 33.1920\n",
      "Epoch 465 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.1055 - mae: 60.4524 - val_loss: 3620.3799 - val_mae: 33.1920\n",
      "Epoch 466 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.1016 - mae: 60.4524 - val_loss: 3620.3789 - val_mae: 33.1920\n",
      "Epoch 467 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.1016 - mae: 60.4524 - val_loss: 3620.3765 - val_mae: 33.1920\n",
      "Epoch 468 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.0977 - mae: 60.4524 - val_loss: 3620.3748 - val_mae: 33.1920\n",
      "Epoch 469 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.1016 - mae: 60.4524 - val_loss: 3620.3730 - val_mae: 33.1920\n",
      "Epoch 470 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.0977 - mae: 60.4524 - val_loss: 3620.3711 - val_mae: 33.1920\n",
      "Epoch 471 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.0977 - mae: 60.4524 - val_loss: 3620.3691 - val_mae: 33.1920\n",
      "Epoch 472 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.0859 - mae: 60.4524 - val_loss: 3620.3674 - val_mae: 33.1920\n",
      "Epoch 473 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.0820 - mae: 60.4524 - val_loss: 3620.3655 - val_mae: 33.1919\n",
      "Epoch 474 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.0781 - mae: 60.4524 - val_loss: 3620.3633 - val_mae: 33.1919\n",
      "Epoch 475 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.0703 - mae: 60.4524 - val_loss: 3620.3611 - val_mae: 33.1919\n",
      "Epoch 476 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.0664 - mae: 60.4524 - val_loss: 3620.3594 - val_mae: 33.1919\n",
      "Epoch 477 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.0664 - mae: 60.4524 - val_loss: 3620.3569 - val_mae: 33.1919\n",
      "Epoch 478 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.0547 - mae: 60.4524 - val_loss: 3620.3552 - val_mae: 33.1919\n",
      "Epoch 479 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.0508 - mae: 60.4524 - val_loss: 3620.3540 - val_mae: 33.1919\n",
      "Epoch 480 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.0469 - mae: 60.4524 - val_loss: 3620.3513 - val_mae: 33.1919\n",
      "Epoch 481 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.0352 - mae: 60.4524 - val_loss: 3620.3496 - val_mae: 33.1919\n",
      "Epoch 482 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.0312 - mae: 60.4524 - val_loss: 3620.3472 - val_mae: 33.1919\n",
      "Epoch 483 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.0273 - mae: 60.4523 - val_loss: 3620.3450 - val_mae: 33.1918\n",
      "Epoch 484 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.0195 - mae: 60.4523 - val_loss: 3620.3425 - val_mae: 33.1918\n",
      "Epoch 485 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44427.0195 - mae: 60.4523 - val_loss: 3620.3406 - val_mae: 33.1918\n",
      "Epoch 486 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.0156 - mae: 60.4523 - val_loss: 3620.3381 - val_mae: 33.1918\n",
      "Epoch 487 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.0117 - mae: 60.4523 - val_loss: 3620.3357 - val_mae: 33.1918\n",
      "Epoch 488 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.0117 - mae: 60.4523 - val_loss: 3620.3342 - val_mae: 33.1918\n",
      "Epoch 489 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.0039 - mae: 60.4523 - val_loss: 3620.3318 - val_mae: 33.1918\n",
      "Epoch 490 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44427.0000 - mae: 60.4523 - val_loss: 3620.3293 - val_mae: 33.1918\n",
      "Epoch 491 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44426.9961 - mae: 60.4523 - val_loss: 3620.3279 - val_mae: 33.1918\n",
      "Epoch 492 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44426.9883 - mae: 60.4523 - val_loss: 3620.3252 - val_mae: 33.1917\n",
      "Epoch 493 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44426.9805 - mae: 60.4523 - val_loss: 3620.3225 - val_mae: 33.1917\n",
      "Epoch 494 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44426.9727 - mae: 60.4523 - val_loss: 3620.3203 - val_mae: 33.1917\n",
      "Epoch 495 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44426.9688 - mae: 60.4523 - val_loss: 3620.3174 - val_mae: 33.1917\n",
      "Epoch 496 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44426.9648 - mae: 60.4523 - val_loss: 3620.3152 - val_mae: 33.1917\n",
      "Epoch 497 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44426.9609 - mae: 60.4523 - val_loss: 3620.3130 - val_mae: 33.1917\n",
      "Epoch 498 / 1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 44426.9492 - mae: 60.4523 - val_loss: 3620.3103 - val_mae: 33.1917\n",
      "Epoch 499 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44426.9453 - mae: 60.4523 - val_loss: 3620.3071 - val_mae: 33.1917\n",
      "Epoch 500 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44426.9453 - mae: 60.4523 - val_loss: 3620.3052 - val_mae: 33.1917\n",
      "Epoch 501 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44426.9336 - mae: 60.4523 - val_loss: 3620.3027 - val_mae: 33.1916\n",
      "Epoch 502 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44426.9297 - mae: 60.4523 - val_loss: 3620.3008 - val_mae: 33.1916\n",
      "Epoch 503 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44426.9297 - mae: 60.4523 - val_loss: 3620.2983 - val_mae: 33.1916\n",
      "Epoch 504 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44426.9219 - mae: 60.4523 - val_loss: 3620.2954 - val_mae: 33.1916\n",
      "Epoch 505 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44426.9219 - mae: 60.4522 - val_loss: 3620.2932 - val_mae: 33.1916\n",
      "Epoch 506 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44426.9219 - mae: 60.4522 - val_loss: 3620.2900 - val_mae: 33.1916\n",
      "Epoch 507 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44426.9180 - mae: 60.4522 - val_loss: 3620.2874 - val_mae: 33.1916\n",
      "Epoch 508 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44426.9023 - mae: 60.4522 - val_loss: 3620.2847 - val_mae: 33.1915\n",
      "Epoch 509 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44426.8984 - mae: 60.4522 - val_loss: 3620.2822 - val_mae: 33.1915\n",
      "Epoch 510 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44426.8945 - mae: 60.4522 - val_loss: 3620.2791 - val_mae: 33.1915\n",
      "Epoch 511 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44426.8867 - mae: 60.4522 - val_loss: 3620.2759 - val_mae: 33.1915\n",
      "Epoch 512 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44426.8789 - mae: 60.4522 - val_loss: 3620.2734 - val_mae: 33.1915\n",
      "Epoch 513 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44426.8789 - mae: 60.4522 - val_loss: 3620.2695 - val_mae: 33.1915\n",
      "Epoch 514 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44426.8672 - mae: 60.4522 - val_loss: 3620.2664 - val_mae: 33.1915\n",
      "Epoch 515 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44426.8672 - mae: 60.4522 - val_loss: 3620.2634 - val_mae: 33.1914\n",
      "Epoch 516 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44426.8633 - mae: 60.4522 - val_loss: 3620.2603 - val_mae: 33.1914\n",
      "Epoch 517 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44426.8477 - mae: 60.4522 - val_loss: 3620.2566 - val_mae: 33.1914\n",
      "Epoch 518 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44426.8438 - mae: 60.4522 - val_loss: 3620.2527 - val_mae: 33.1914\n",
      "Epoch 519 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44426.8320 - mae: 60.4522 - val_loss: 3620.2495 - val_mae: 33.1914\n",
      "Epoch 520 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44426.8320 - mae: 60.4522 - val_loss: 3620.2461 - val_mae: 33.1914\n",
      "Epoch 521 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44426.8203 - mae: 60.4522 - val_loss: 3620.2424 - val_mae: 33.1913\n",
      "Epoch 522 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44426.8203 - mae: 60.4522 - val_loss: 3620.2393 - val_mae: 33.1913\n",
      "Epoch 523 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44426.8047 - mae: 60.4522 - val_loss: 3620.2368 - val_mae: 33.1913\n",
      "Epoch 524 / 1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 44426.7969 - mae: 60.4522 - val_loss: 3620.2327 - val_mae: 33.1913\n",
      "Epoch 525 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44426.7891 - mae: 60.4522 - val_loss: 3620.2297 - val_mae: 33.1913\n",
      "Epoch 526 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44426.7812 - mae: 60.4522 - val_loss: 3620.2258 - val_mae: 33.1913\n",
      "Epoch 527 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44426.7695 - mae: 60.4522 - val_loss: 3620.2219 - val_mae: 33.1912\n",
      "Epoch 528 / 1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 44426.7656 - mae: 60.4522 - val_loss: 3620.2190 - val_mae: 33.1912\n",
      "Epoch 529 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44426.7617 - mae: 60.4521 - val_loss: 3620.2153 - val_mae: 33.1912\n",
      "Epoch 530 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44426.7695 - mae: 60.4521 - val_loss: 3620.2114 - val_mae: 33.1912\n",
      "Epoch 531 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44426.7617 - mae: 60.4521 - val_loss: 3620.2070 - val_mae: 33.1912\n",
      "Epoch 532 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44426.7500 - mae: 60.4522 - val_loss: 3620.2034 - val_mae: 33.1911\n",
      "Epoch 533 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44426.7500 - mae: 60.4521 - val_loss: 3620.1997 - val_mae: 33.1911\n",
      "Epoch 534 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44426.7383 - mae: 60.4521 - val_loss: 3620.1960 - val_mae: 33.1911\n",
      "Epoch 535 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44426.7344 - mae: 60.4521 - val_loss: 3620.1926 - val_mae: 33.1911\n",
      "Epoch 536 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44426.7227 - mae: 60.4521 - val_loss: 3620.1887 - val_mae: 33.1911\n",
      "Epoch 537 / 1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 44426.7305 - mae: 60.4521 - val_loss: 3620.1853 - val_mae: 33.1910\n",
      "Epoch 538 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44426.7188 - mae: 60.4521 - val_loss: 3620.1821 - val_mae: 33.1910\n",
      "Epoch 539 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44426.7148 - mae: 60.4521 - val_loss: 3620.1782 - val_mae: 33.1910\n",
      "Epoch 540 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44426.6953 - mae: 60.4521 - val_loss: 3620.1746 - val_mae: 33.1910\n",
      "Epoch 541 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44426.6875 - mae: 60.4521 - val_loss: 3620.1702 - val_mae: 33.1910\n",
      "Epoch 542 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44426.6836 - mae: 60.4521 - val_loss: 3620.1672 - val_mae: 33.1910\n",
      "Epoch 543 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44426.6836 - mae: 60.4521 - val_loss: 3620.1641 - val_mae: 33.1909\n",
      "Epoch 544 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44426.6641 - mae: 60.4521 - val_loss: 3620.1604 - val_mae: 33.1909\n",
      "Epoch 545 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44426.6562 - mae: 60.4521 - val_loss: 3620.1565 - val_mae: 33.1909\n",
      "Epoch 546 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44426.6641 - mae: 60.4520 - val_loss: 3620.1528 - val_mae: 33.1909\n",
      "Epoch 547 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44426.6523 - mae: 60.4520 - val_loss: 3620.1489 - val_mae: 33.1909\n",
      "Epoch 548 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44426.6445 - mae: 60.4520 - val_loss: 3620.1448 - val_mae: 33.1909\n",
      "Epoch 549 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44426.6367 - mae: 60.4521 - val_loss: 3620.1411 - val_mae: 33.1908\n",
      "Epoch 550 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44426.6289 - mae: 60.4520 - val_loss: 3620.1365 - val_mae: 33.1908\n",
      "Epoch 551 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44426.6211 - mae: 60.4520 - val_loss: 3620.1323 - val_mae: 33.1908\n",
      "Epoch 552 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44426.6133 - mae: 60.4520 - val_loss: 3620.1277 - val_mae: 33.1908\n",
      "Epoch 553 / 1000\n",
      "98/98 [==============================] - 0s 5ms/step - loss: 44426.6055 - mae: 60.4520 - val_loss: 3620.1235 - val_mae: 33.1907\n",
      "Epoch 554 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44426.5977 - mae: 60.4520 - val_loss: 3620.1199 - val_mae: 33.1907\n",
      "Epoch 555 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44426.5820 - mae: 60.4520 - val_loss: 3620.1152 - val_mae: 33.1907\n",
      "Epoch 556 / 1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 44426.5703 - mae: 60.4520 - val_loss: 3620.1108 - val_mae: 33.1907\n",
      "Epoch 557 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44426.5664 - mae: 60.4520 - val_loss: 3620.1067 - val_mae: 33.1907\n",
      "Epoch 558 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44426.5664 - mae: 60.4520 - val_loss: 3620.1021 - val_mae: 33.1906\n",
      "Epoch 559 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44426.5547 - mae: 60.4520 - val_loss: 3620.0972 - val_mae: 33.1906\n",
      "Epoch 560 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44426.5508 - mae: 60.4520 - val_loss: 3620.0928 - val_mae: 33.1906\n",
      "Epoch 561 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44426.5391 - mae: 60.4520 - val_loss: 3620.0879 - val_mae: 33.1906\n",
      "Epoch 562 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44426.5273 - mae: 60.4519 - val_loss: 3620.0828 - val_mae: 33.1905\n",
      "Epoch 563 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44426.5156 - mae: 60.4520 - val_loss: 3620.0781 - val_mae: 33.1905\n",
      "Epoch 564 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44426.5000 - mae: 60.4520 - val_loss: 3620.0728 - val_mae: 33.1905\n",
      "Epoch 565 / 1000\n",
      "98/98 [==============================] - 0s 4ms/step - loss: 44426.4883 - mae: 60.4520 - val_loss: 3620.0676 - val_mae: 33.1905\n",
      "Epoch 566 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44426.4805 - mae: 60.4519 - val_loss: 3620.0625 - val_mae: 33.1904\n",
      "Epoch 567 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44426.4648 - mae: 60.4519 - val_loss: 3620.0569 - val_mae: 33.1904\n",
      "Epoch 568 / 1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 44426.4531 - mae: 60.4519 - val_loss: 3620.0520 - val_mae: 33.1904\n",
      "Epoch 569 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44426.4453 - mae: 60.4519 - val_loss: 3620.0469 - val_mae: 33.1904\n",
      "Epoch 570 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44426.4336 - mae: 60.4519 - val_loss: 3620.0415 - val_mae: 33.1903\n",
      "Epoch 571 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44426.4219 - mae: 60.4519 - val_loss: 3620.0369 - val_mae: 33.1903\n",
      "Epoch 572 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44426.4062 - mae: 60.4519 - val_loss: 3620.0312 - val_mae: 33.1903\n",
      "Epoch 573 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44426.4062 - mae: 60.4519 - val_loss: 3620.0266 - val_mae: 33.1903\n",
      "Epoch 574 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44426.3945 - mae: 60.4519 - val_loss: 3620.0212 - val_mae: 33.1902\n",
      "Epoch 575 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44426.3867 - mae: 60.4519 - val_loss: 3620.0164 - val_mae: 33.1902\n",
      "Epoch 576 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44426.3828 - mae: 60.4519 - val_loss: 3620.0117 - val_mae: 33.1902\n",
      "Epoch 577 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44426.3711 - mae: 60.4519 - val_loss: 3620.0073 - val_mae: 33.1902\n",
      "Epoch 578 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44426.3633 - mae: 60.4519 - val_loss: 3620.0024 - val_mae: 33.1901\n",
      "Epoch 579 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44426.3516 - mae: 60.4519 - val_loss: 3619.9976 - val_mae: 33.1901\n",
      "Epoch 580 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44426.3359 - mae: 60.4518 - val_loss: 3619.9919 - val_mae: 33.1901\n",
      "Epoch 581 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44426.3281 - mae: 60.4518 - val_loss: 3619.9868 - val_mae: 33.1901\n",
      "Epoch 582 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44426.3281 - mae: 60.4518 - val_loss: 3619.9817 - val_mae: 33.1900\n",
      "Epoch 583 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44426.3164 - mae: 60.4518 - val_loss: 3619.9766 - val_mae: 33.1900\n",
      "Epoch 584 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44426.3008 - mae: 60.4519 - val_loss: 3619.9707 - val_mae: 33.1900\n",
      "Epoch 585 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44426.3008 - mae: 60.4518 - val_loss: 3619.9651 - val_mae: 33.1900\n",
      "Epoch 586 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44426.2812 - mae: 60.4518 - val_loss: 3619.9592 - val_mae: 33.1899\n",
      "Epoch 587 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44426.2773 - mae: 60.4518 - val_loss: 3619.9536 - val_mae: 33.1899\n",
      "Epoch 588 / 1000\n",
      "98/98 [==============================] - 1s 6ms/step - loss: 44426.2617 - mae: 60.4518 - val_loss: 3619.9490 - val_mae: 33.1899\n",
      "Epoch 589 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44426.2461 - mae: 60.4518 - val_loss: 3619.9429 - val_mae: 33.1898\n",
      "Epoch 590 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44426.2461 - mae: 60.4518 - val_loss: 3619.9373 - val_mae: 33.1898\n",
      "Epoch 591 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44426.2305 - mae: 60.4518 - val_loss: 3619.9321 - val_mae: 33.1898\n",
      "Epoch 592 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44426.2148 - mae: 60.4518 - val_loss: 3619.9260 - val_mae: 33.1898\n",
      "Epoch 593 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44426.2148 - mae: 60.4518 - val_loss: 3619.9204 - val_mae: 33.1897\n",
      "Epoch 594 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44426.1992 - mae: 60.4518 - val_loss: 3619.9146 - val_mae: 33.1897\n",
      "Epoch 595 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44426.1953 - mae: 60.4518 - val_loss: 3619.9082 - val_mae: 33.1897\n",
      "Epoch 596 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44426.1797 - mae: 60.4518 - val_loss: 3619.9019 - val_mae: 33.1896\n",
      "Epoch 597 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44426.1680 - mae: 60.4518 - val_loss: 3619.8962 - val_mae: 33.1896\n",
      "Epoch 598 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44426.1562 - mae: 60.4517 - val_loss: 3619.8904 - val_mae: 33.1896\n",
      "Epoch 599 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44426.1445 - mae: 60.4518 - val_loss: 3619.8850 - val_mae: 33.1896\n",
      "Epoch 600 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44426.1445 - mae: 60.4517 - val_loss: 3619.8796 - val_mae: 33.1895\n",
      "Epoch 601 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44426.1289 - mae: 60.4517 - val_loss: 3619.8735 - val_mae: 33.1895\n",
      "Epoch 602 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44426.1172 - mae: 60.4517 - val_loss: 3619.8672 - val_mae: 33.1895\n",
      "Epoch 603 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44426.1016 - mae: 60.4517 - val_loss: 3619.8608 - val_mae: 33.1894\n",
      "Epoch 604 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44426.0938 - mae: 60.4517 - val_loss: 3619.8547 - val_mae: 33.1894\n",
      "Epoch 605 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44426.0664 - mae: 60.4517 - val_loss: 3619.8484 - val_mae: 33.1894\n",
      "Epoch 606 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44426.0508 - mae: 60.4517 - val_loss: 3619.8420 - val_mae: 33.1893\n",
      "Epoch 607 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44426.0312 - mae: 60.4517 - val_loss: 3619.8357 - val_mae: 33.1893\n",
      "Epoch 608 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44426.0195 - mae: 60.4517 - val_loss: 3619.8293 - val_mae: 33.1893\n",
      "Epoch 609 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44426.0156 - mae: 60.4517 - val_loss: 3619.8235 - val_mae: 33.1892\n",
      "Epoch 610 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44426.0039 - mae: 60.4517 - val_loss: 3619.8167 - val_mae: 33.1892\n",
      "Epoch 611 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44426.0000 - mae: 60.4517 - val_loss: 3619.8110 - val_mae: 33.1892\n",
      "Epoch 612 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44425.9805 - mae: 60.4517 - val_loss: 3619.8042 - val_mae: 33.1891\n",
      "Epoch 613 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44425.9609 - mae: 60.4516 - val_loss: 3619.7981 - val_mae: 33.1891\n",
      "Epoch 614 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44425.9531 - mae: 60.4516 - val_loss: 3619.7915 - val_mae: 33.1891\n",
      "Epoch 615 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44425.9531 - mae: 60.4516 - val_loss: 3619.7854 - val_mae: 33.1891\n",
      "Epoch 616 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44425.9453 - mae: 60.4516 - val_loss: 3619.7791 - val_mae: 33.1890\n",
      "Epoch 617 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44425.9336 - mae: 60.4516 - val_loss: 3619.7729 - val_mae: 33.1890\n",
      "Epoch 618 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44425.9297 - mae: 60.4516 - val_loss: 3619.7661 - val_mae: 33.1890\n",
      "Epoch 619 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44425.9141 - mae: 60.4516 - val_loss: 3619.7593 - val_mae: 33.1889\n",
      "Epoch 620 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44425.9141 - mae: 60.4516 - val_loss: 3619.7527 - val_mae: 33.1889\n",
      "Epoch 621 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44425.9023 - mae: 60.4516 - val_loss: 3619.7471 - val_mae: 33.1889\n",
      "Epoch 622 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44425.8945 - mae: 60.4516 - val_loss: 3619.7407 - val_mae: 33.1888\n",
      "Epoch 623 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44425.8672 - mae: 60.4516 - val_loss: 3619.7344 - val_mae: 33.1888\n",
      "Epoch 624 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44425.8438 - mae: 60.4516 - val_loss: 3619.7288 - val_mae: 33.1888\n",
      "Epoch 625 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44425.8320 - mae: 60.4516 - val_loss: 3619.7219 - val_mae: 33.1887\n",
      "Epoch 626 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44425.8164 - mae: 60.4515 - val_loss: 3619.7151 - val_mae: 33.1887\n",
      "Epoch 627 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44425.8125 - mae: 60.4515 - val_loss: 3619.7095 - val_mae: 33.1887\n",
      "Epoch 628 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44425.8047 - mae: 60.4515 - val_loss: 3619.7024 - val_mae: 33.1886\n",
      "Epoch 629 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44425.7852 - mae: 60.4515 - val_loss: 3619.6965 - val_mae: 33.1886\n",
      "Epoch 630 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44425.7773 - mae: 60.4515 - val_loss: 3619.6895 - val_mae: 33.1886\n",
      "Epoch 631 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44425.7656 - mae: 60.4515 - val_loss: 3619.6829 - val_mae: 33.1885\n",
      "Epoch 632 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44425.7539 - mae: 60.4515 - val_loss: 3619.6760 - val_mae: 33.1885\n",
      "Epoch 633 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44425.7461 - mae: 60.4515 - val_loss: 3619.6694 - val_mae: 33.1885\n",
      "Epoch 634 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44425.7305 - mae: 60.4515 - val_loss: 3619.6628 - val_mae: 33.1884\n",
      "Epoch 635 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44425.7227 - mae: 60.4515 - val_loss: 3619.6562 - val_mae: 33.1884\n",
      "Epoch 636 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44425.7109 - mae: 60.4515 - val_loss: 3619.6497 - val_mae: 33.1884\n",
      "Epoch 637 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44425.6992 - mae: 60.4515 - val_loss: 3619.6428 - val_mae: 33.1883\n",
      "Epoch 638 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44425.6797 - mae: 60.4515 - val_loss: 3619.6362 - val_mae: 33.1883\n",
      "Epoch 639 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44425.6719 - mae: 60.4515 - val_loss: 3619.6296 - val_mae: 33.1883\n",
      "Epoch 640 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44425.6523 - mae: 60.4515 - val_loss: 3619.6230 - val_mae: 33.1882\n",
      "Epoch 641 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44425.6328 - mae: 60.4514 - val_loss: 3619.6162 - val_mae: 33.1882\n",
      "Epoch 642 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44425.6133 - mae: 60.4515 - val_loss: 3619.6084 - val_mae: 33.1882\n",
      "Epoch 643 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44425.6016 - mae: 60.4514 - val_loss: 3619.6025 - val_mae: 33.1881\n",
      "Epoch 644 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44425.5859 - mae: 60.4514 - val_loss: 3619.5955 - val_mae: 33.1881\n",
      "Epoch 645 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44425.5703 - mae: 60.4514 - val_loss: 3619.5884 - val_mae: 33.1881\n",
      "Epoch 646 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44425.5625 - mae: 60.4514 - val_loss: 3619.5815 - val_mae: 33.1880\n",
      "Epoch 647 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44425.5547 - mae: 60.4514 - val_loss: 3619.5750 - val_mae: 33.1880\n",
      "Epoch 648 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44425.5469 - mae: 60.4514 - val_loss: 3619.5684 - val_mae: 33.1880\n",
      "Epoch 649 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44425.5352 - mae: 60.4514 - val_loss: 3619.5610 - val_mae: 33.1879\n",
      "Epoch 650 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44425.5195 - mae: 60.4514 - val_loss: 3619.5544 - val_mae: 33.1879\n",
      "Epoch 651 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44425.5000 - mae: 60.4514 - val_loss: 3619.5464 - val_mae: 33.1879\n",
      "Epoch 652 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44425.4844 - mae: 60.4514 - val_loss: 3619.5393 - val_mae: 33.1878\n",
      "Epoch 653 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44425.4727 - mae: 60.4514 - val_loss: 3619.5320 - val_mae: 33.1878\n",
      "Epoch 654 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44425.4648 - mae: 60.4514 - val_loss: 3619.5249 - val_mae: 33.1878\n",
      "Epoch 655 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44425.4648 - mae: 60.4514 - val_loss: 3619.5173 - val_mae: 33.1877\n",
      "Epoch 656 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44425.4492 - mae: 60.4514 - val_loss: 3619.5100 - val_mae: 33.1877\n",
      "Epoch 657 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44425.4336 - mae: 60.4513 - val_loss: 3619.5022 - val_mae: 33.1876\n",
      "Epoch 658 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44425.4141 - mae: 60.4513 - val_loss: 3619.4954 - val_mae: 33.1876\n",
      "Epoch 659 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44425.3945 - mae: 60.4513 - val_loss: 3619.4885 - val_mae: 33.1876\n",
      "Epoch 660 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44425.3789 - mae: 60.4513 - val_loss: 3619.4814 - val_mae: 33.1875\n",
      "Epoch 661 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44425.3672 - mae: 60.4513 - val_loss: 3619.4736 - val_mae: 33.1875\n",
      "Epoch 662 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44425.3477 - mae: 60.4513 - val_loss: 3619.4673 - val_mae: 33.1875\n",
      "Epoch 663 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44425.3438 - mae: 60.4513 - val_loss: 3619.4607 - val_mae: 33.1874\n",
      "Epoch 664 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44425.3281 - mae: 60.4513 - val_loss: 3619.4534 - val_mae: 33.1874\n",
      "Epoch 665 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44425.3125 - mae: 60.4513 - val_loss: 3619.4465 - val_mae: 33.1874\n",
      "Epoch 666 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44425.2969 - mae: 60.4513 - val_loss: 3619.4402 - val_mae: 33.1873\n",
      "Epoch 667 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44425.2891 - mae: 60.4513 - val_loss: 3619.4333 - val_mae: 33.1873\n",
      "Epoch 668 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44425.2812 - mae: 60.4512 - val_loss: 3619.4270 - val_mae: 33.1873\n",
      "Epoch 669 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44425.2656 - mae: 60.4513 - val_loss: 3619.4194 - val_mae: 33.1872\n",
      "Epoch 670 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44425.2500 - mae: 60.4513 - val_loss: 3619.4131 - val_mae: 33.1872\n",
      "Epoch 671 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44425.2344 - mae: 60.4512 - val_loss: 3619.4058 - val_mae: 33.1872\n",
      "Epoch 672 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44425.2188 - mae: 60.4513 - val_loss: 3619.3987 - val_mae: 33.1871\n",
      "Epoch 673 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44425.2031 - mae: 60.4513 - val_loss: 3619.3918 - val_mae: 33.1871\n",
      "Epoch 674 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44425.1992 - mae: 60.4512 - val_loss: 3619.3845 - val_mae: 33.1871\n",
      "Epoch 675 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44425.1680 - mae: 60.4512 - val_loss: 3619.3770 - val_mae: 33.1870\n",
      "Epoch 676 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44425.1523 - mae: 60.4512 - val_loss: 3619.3694 - val_mae: 33.1870\n",
      "Epoch 677 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44425.1445 - mae: 60.4512 - val_loss: 3619.3623 - val_mae: 33.1870\n",
      "Epoch 678 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44425.1211 - mae: 60.4512 - val_loss: 3619.3550 - val_mae: 33.1869\n",
      "Epoch 679 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44425.1172 - mae: 60.4512 - val_loss: 3619.3479 - val_mae: 33.1869\n",
      "Epoch 680 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44425.0977 - mae: 60.4512 - val_loss: 3619.3403 - val_mae: 33.1868\n",
      "Epoch 681 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44425.0820 - mae: 60.4512 - val_loss: 3619.3335 - val_mae: 33.1868\n",
      "Epoch 682 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44425.0781 - mae: 60.4512 - val_loss: 3619.3269 - val_mae: 33.1868\n",
      "Epoch 683 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44425.0547 - mae: 60.4512 - val_loss: 3619.3193 - val_mae: 33.1867\n",
      "Epoch 684 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44425.0469 - mae: 60.4511 - val_loss: 3619.3125 - val_mae: 33.1867\n",
      "Epoch 685 / 1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 44425.0312 - mae: 60.4512 - val_loss: 3619.3057 - val_mae: 33.1867\n",
      "Epoch 686 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44425.0156 - mae: 60.4512 - val_loss: 3619.2991 - val_mae: 33.1866\n",
      "Epoch 687 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44425.0117 - mae: 60.4511 - val_loss: 3619.2922 - val_mae: 33.1866\n",
      "Epoch 688 / 1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 44424.9961 - mae: 60.4511 - val_loss: 3619.2849 - val_mae: 33.1866\n",
      "Epoch 689 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44424.9805 - mae: 60.4511 - val_loss: 3619.2781 - val_mae: 33.1865\n",
      "Epoch 690 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44424.9688 - mae: 60.4511 - val_loss: 3619.2715 - val_mae: 33.1865\n",
      "Epoch 691 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44424.9648 - mae: 60.4511 - val_loss: 3619.2642 - val_mae: 33.1865\n",
      "Epoch 692 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44424.9453 - mae: 60.4511 - val_loss: 3619.2573 - val_mae: 33.1864\n",
      "Epoch 693 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44424.9297 - mae: 60.4511 - val_loss: 3619.2498 - val_mae: 33.1864\n",
      "Epoch 694 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44424.9023 - mae: 60.4511 - val_loss: 3619.2424 - val_mae: 33.1864\n",
      "Epoch 695 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44424.8945 - mae: 60.4511 - val_loss: 3619.2354 - val_mae: 33.1863\n",
      "Epoch 696 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44424.8789 - mae: 60.4511 - val_loss: 3619.2285 - val_mae: 33.1863\n",
      "Epoch 697 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44424.8672 - mae: 60.4511 - val_loss: 3619.2214 - val_mae: 33.1863\n",
      "Epoch 698 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44424.8516 - mae: 60.4511 - val_loss: 3619.2144 - val_mae: 33.1862\n",
      "Epoch 699 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44424.8320 - mae: 60.4511 - val_loss: 3619.2073 - val_mae: 33.1862\n",
      "Epoch 700 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44424.8203 - mae: 60.4511 - val_loss: 3619.2000 - val_mae: 33.1861\n",
      "Epoch 701 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44424.8164 - mae: 60.4510 - val_loss: 3619.1929 - val_mae: 33.1861\n",
      "Epoch 702 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44424.8008 - mae: 60.4511 - val_loss: 3619.1860 - val_mae: 33.1861\n",
      "Epoch 703 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44424.7852 - mae: 60.4511 - val_loss: 3619.1790 - val_mae: 33.1860\n",
      "Epoch 704 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44424.7656 - mae: 60.4510 - val_loss: 3619.1721 - val_mae: 33.1860\n",
      "Epoch 705 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44424.7539 - mae: 60.4511 - val_loss: 3619.1653 - val_mae: 33.1860\n",
      "Epoch 706 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44424.7383 - mae: 60.4510 - val_loss: 3619.1582 - val_mae: 33.1859\n",
      "Epoch 707 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44424.7305 - mae: 60.4510 - val_loss: 3619.1511 - val_mae: 33.1859\n",
      "Epoch 708 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44424.7109 - mae: 60.4510 - val_loss: 3619.1448 - val_mae: 33.1859\n",
      "Epoch 709 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44424.7031 - mae: 60.4510 - val_loss: 3619.1379 - val_mae: 33.1858\n",
      "Epoch 710 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44424.6797 - mae: 60.4510 - val_loss: 3619.1311 - val_mae: 33.1858\n",
      "Epoch 711 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44424.6680 - mae: 60.4510 - val_loss: 3619.1255 - val_mae: 33.1858\n",
      "Epoch 712 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44424.6523 - mae: 60.4510 - val_loss: 3619.1189 - val_mae: 33.1857\n",
      "Epoch 713 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44424.6445 - mae: 60.4510 - val_loss: 3619.1123 - val_mae: 33.1857\n",
      "Epoch 714 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44424.6289 - mae: 60.4510 - val_loss: 3619.1057 - val_mae: 33.1857\n",
      "Epoch 715 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44424.6289 - mae: 60.4510 - val_loss: 3619.0986 - val_mae: 33.1856\n",
      "Epoch 716 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44424.6055 - mae: 60.4510 - val_loss: 3619.0925 - val_mae: 33.1856\n",
      "Epoch 717 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44424.6016 - mae: 60.4510 - val_loss: 3619.0857 - val_mae: 33.1856\n",
      "Epoch 718 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44424.5977 - mae: 60.4509 - val_loss: 3619.0784 - val_mae: 33.1855\n",
      "Epoch 719 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44424.5859 - mae: 60.4510 - val_loss: 3619.0718 - val_mae: 33.1855\n",
      "Epoch 720 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44424.5820 - mae: 60.4510 - val_loss: 3619.0649 - val_mae: 33.1855\n",
      "Epoch 721 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44424.5781 - mae: 60.4509 - val_loss: 3619.0576 - val_mae: 33.1854\n",
      "Epoch 722 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44424.5664 - mae: 60.4509 - val_loss: 3619.0508 - val_mae: 33.1854\n",
      "Epoch 723 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44424.5391 - mae: 60.4509 - val_loss: 3619.0437 - val_mae: 33.1854\n",
      "Epoch 724 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44424.5312 - mae: 60.4509 - val_loss: 3619.0371 - val_mae: 33.1853\n",
      "Epoch 725 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44424.5195 - mae: 60.4509 - val_loss: 3619.0300 - val_mae: 33.1853\n",
      "Epoch 726 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44424.5039 - mae: 60.4509 - val_loss: 3619.0237 - val_mae: 33.1853\n",
      "Epoch 727 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44424.4805 - mae: 60.4509 - val_loss: 3619.0173 - val_mae: 33.1852\n",
      "Epoch 728 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44424.4727 - mae: 60.4509 - val_loss: 3619.0098 - val_mae: 33.1852\n",
      "Epoch 729 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44424.4648 - mae: 60.4509 - val_loss: 3619.0034 - val_mae: 33.1852\n",
      "Epoch 730 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44424.4609 - mae: 60.4509 - val_loss: 3618.9968 - val_mae: 33.1851\n",
      "Epoch 731 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44424.4375 - mae: 60.4509 - val_loss: 3618.9905 - val_mae: 33.1851\n",
      "Epoch 732 / 1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 44424.4297 - mae: 60.4509 - val_loss: 3618.9839 - val_mae: 33.1851\n",
      "Epoch 733 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44424.4180 - mae: 60.4509 - val_loss: 3618.9773 - val_mae: 33.1850\n",
      "Epoch 734 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44424.4023 - mae: 60.4509 - val_loss: 3618.9714 - val_mae: 33.1850\n",
      "Epoch 735 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44424.3984 - mae: 60.4509 - val_loss: 3618.9651 - val_mae: 33.1850\n",
      "Epoch 736 / 1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 44424.3828 - mae: 60.4509 - val_loss: 3618.9587 - val_mae: 33.1849\n",
      "Epoch 737 / 1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 44424.3789 - mae: 60.4509 - val_loss: 3618.9524 - val_mae: 33.1849\n",
      "Epoch 738 / 1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 44424.3633 - mae: 60.4509 - val_loss: 3618.9465 - val_mae: 33.1849\n",
      "Epoch 739 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44424.3516 - mae: 60.4508 - val_loss: 3618.9399 - val_mae: 33.1849\n",
      "Epoch 740 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44424.3320 - mae: 60.4509 - val_loss: 3618.9341 - val_mae: 33.1848\n",
      "Epoch 741 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44424.3281 - mae: 60.4508 - val_loss: 3618.9275 - val_mae: 33.1848\n",
      "Epoch 742 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44424.3203 - mae: 60.4508 - val_loss: 3618.9214 - val_mae: 33.1848\n",
      "Epoch 743 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44424.3164 - mae: 60.4508 - val_loss: 3618.9153 - val_mae: 33.1847\n",
      "Epoch 744 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44424.3047 - mae: 60.4509 - val_loss: 3618.9089 - val_mae: 33.1847\n",
      "Epoch 745 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44424.2852 - mae: 60.4508 - val_loss: 3618.9033 - val_mae: 33.1847\n",
      "Epoch 746 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44424.2812 - mae: 60.4508 - val_loss: 3618.8975 - val_mae: 33.1846\n",
      "Epoch 747 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44424.2695 - mae: 60.4508 - val_loss: 3618.8914 - val_mae: 33.1846\n",
      "Epoch 748 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44424.2539 - mae: 60.4508 - val_loss: 3618.8848 - val_mae: 33.1846\n",
      "Epoch 749 / 1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 44424.2461 - mae: 60.4508 - val_loss: 3618.8787 - val_mae: 33.1846\n",
      "Epoch 750 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44424.2227 - mae: 60.4508 - val_loss: 3618.8733 - val_mae: 33.1845\n",
      "Epoch 751 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44424.2188 - mae: 60.4508 - val_loss: 3618.8669 - val_mae: 33.1845\n",
      "Epoch 752 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44424.2109 - mae: 60.4508 - val_loss: 3618.8613 - val_mae: 33.1845\n",
      "Epoch 753 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44424.1953 - mae: 60.4508 - val_loss: 3618.8555 - val_mae: 33.1844\n",
      "Epoch 754 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44424.1719 - mae: 60.4508 - val_loss: 3618.8503 - val_mae: 33.1844\n",
      "Epoch 755 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44424.1641 - mae: 60.4508 - val_loss: 3618.8447 - val_mae: 33.1844\n",
      "Epoch 756 / 1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 44424.1523 - mae: 60.4508 - val_loss: 3618.8391 - val_mae: 33.1844\n",
      "Epoch 757 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44424.1484 - mae: 60.4508 - val_loss: 3618.8333 - val_mae: 33.1843\n",
      "Epoch 758 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44424.1328 - mae: 60.4508 - val_loss: 3618.8279 - val_mae: 33.1843\n",
      "Epoch 759 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44424.1211 - mae: 60.4507 - val_loss: 3618.8225 - val_mae: 33.1843\n",
      "Epoch 760 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44424.1055 - mae: 60.4508 - val_loss: 3618.8167 - val_mae: 33.1842\n",
      "Epoch 761 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44424.0938 - mae: 60.4508 - val_loss: 3618.8105 - val_mae: 33.1842\n",
      "Epoch 762 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44424.0859 - mae: 60.4508 - val_loss: 3618.8057 - val_mae: 33.1842\n",
      "Epoch 763 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44424.0781 - mae: 60.4507 - val_loss: 3618.7996 - val_mae: 33.1842\n",
      "Epoch 764 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44424.0703 - mae: 60.4507 - val_loss: 3618.7937 - val_mae: 33.1841\n",
      "Epoch 765 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44424.0625 - mae: 60.4508 - val_loss: 3618.7886 - val_mae: 33.1841\n",
      "Epoch 766 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44424.0508 - mae: 60.4508 - val_loss: 3618.7822 - val_mae: 33.1841\n",
      "Epoch 767 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44424.0391 - mae: 60.4507 - val_loss: 3618.7766 - val_mae: 33.1840\n",
      "Epoch 768 / 1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 44424.0273 - mae: 60.4507 - val_loss: 3618.7715 - val_mae: 33.1840\n",
      "Epoch 769 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44424.0039 - mae: 60.4507 - val_loss: 3618.7664 - val_mae: 33.1840\n",
      "Epoch 770 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44424.0000 - mae: 60.4507 - val_loss: 3618.7617 - val_mae: 33.1840\n",
      "Epoch 771 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44423.9883 - mae: 60.4507 - val_loss: 3618.7561 - val_mae: 33.1839\n",
      "Epoch 772 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.9805 - mae: 60.4507 - val_loss: 3618.7505 - val_mae: 33.1839\n",
      "Epoch 773 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44423.9531 - mae: 60.4507 - val_loss: 3618.7451 - val_mae: 33.1839\n",
      "Epoch 774 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.9375 - mae: 60.4507 - val_loss: 3618.7393 - val_mae: 33.1839\n",
      "Epoch 775 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.9336 - mae: 60.4507 - val_loss: 3618.7344 - val_mae: 33.1838\n",
      "Epoch 776 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.9375 - mae: 60.4507 - val_loss: 3618.7288 - val_mae: 33.1838\n",
      "Epoch 777 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.9297 - mae: 60.4507 - val_loss: 3618.7234 - val_mae: 33.1838\n",
      "Epoch 778 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.9141 - mae: 60.4507 - val_loss: 3618.7180 - val_mae: 33.1838\n",
      "Epoch 779 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.9062 - mae: 60.4507 - val_loss: 3618.7131 - val_mae: 33.1837\n",
      "Epoch 780 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.8945 - mae: 60.4507 - val_loss: 3618.7078 - val_mae: 33.1837\n",
      "Epoch 781 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.8867 - mae: 60.4507 - val_loss: 3618.7026 - val_mae: 33.1837\n",
      "Epoch 782 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.8789 - mae: 60.4507 - val_loss: 3618.6978 - val_mae: 33.1837\n",
      "Epoch 783 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.8711 - mae: 60.4507 - val_loss: 3618.6926 - val_mae: 33.1836\n",
      "Epoch 784 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44423.8555 - mae: 60.4507 - val_loss: 3618.6875 - val_mae: 33.1836\n",
      "Epoch 785 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44423.8555 - mae: 60.4507 - val_loss: 3618.6824 - val_mae: 33.1836\n",
      "Epoch 786 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.8477 - mae: 60.4507 - val_loss: 3618.6780 - val_mae: 33.1836\n",
      "Epoch 787 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.8359 - mae: 60.4507 - val_loss: 3618.6724 - val_mae: 33.1835\n",
      "Epoch 788 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.8281 - mae: 60.4507 - val_loss: 3618.6677 - val_mae: 33.1835\n",
      "Epoch 789 / 1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 44423.8125 - mae: 60.4507 - val_loss: 3618.6619 - val_mae: 33.1835\n",
      "Epoch 790 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44423.8047 - mae: 60.4507 - val_loss: 3618.6575 - val_mae: 33.1835\n",
      "Epoch 791 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44423.8008 - mae: 60.4506 - val_loss: 3618.6528 - val_mae: 33.1834\n",
      "Epoch 792 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44423.7852 - mae: 60.4507 - val_loss: 3618.6487 - val_mae: 33.1834\n",
      "Epoch 793 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44423.7773 - mae: 60.4507 - val_loss: 3618.6436 - val_mae: 33.1834\n",
      "Epoch 794 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.7695 - mae: 60.4507 - val_loss: 3618.6389 - val_mae: 33.1834\n",
      "Epoch 795 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44423.7539 - mae: 60.4507 - val_loss: 3618.6350 - val_mae: 33.1833\n",
      "Epoch 796 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44423.7461 - mae: 60.4506 - val_loss: 3618.6306 - val_mae: 33.1833\n",
      "Epoch 797 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44423.7344 - mae: 60.4506 - val_loss: 3618.6260 - val_mae: 33.1833\n",
      "Epoch 798 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.7227 - mae: 60.4506 - val_loss: 3618.6218 - val_mae: 33.1833\n",
      "Epoch 799 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44423.7148 - mae: 60.4506 - val_loss: 3618.6174 - val_mae: 33.1833\n",
      "Epoch 800 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44423.6992 - mae: 60.4506 - val_loss: 3618.6128 - val_mae: 33.1832\n",
      "Epoch 801 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44423.6992 - mae: 60.4506 - val_loss: 3618.6082 - val_mae: 33.1832\n",
      "Epoch 802 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.6992 - mae: 60.4506 - val_loss: 3618.6040 - val_mae: 33.1832\n",
      "Epoch 803 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.6953 - mae: 60.4506 - val_loss: 3618.5994 - val_mae: 33.1832\n",
      "Epoch 804 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44423.6836 - mae: 60.4506 - val_loss: 3618.5947 - val_mae: 33.1831\n",
      "Epoch 805 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.6797 - mae: 60.4506 - val_loss: 3618.5903 - val_mae: 33.1831\n",
      "Epoch 806 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.6680 - mae: 60.4506 - val_loss: 3618.5862 - val_mae: 33.1831\n",
      "Epoch 807 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.6484 - mae: 60.4506 - val_loss: 3618.5815 - val_mae: 33.1831\n",
      "Epoch 808 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.6484 - mae: 60.4506 - val_loss: 3618.5774 - val_mae: 33.1831\n",
      "Epoch 809 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44423.6445 - mae: 60.4506 - val_loss: 3618.5732 - val_mae: 33.1830\n",
      "Epoch 810 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.6289 - mae: 60.4506 - val_loss: 3618.5693 - val_mae: 33.1830\n",
      "Epoch 811 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.6289 - mae: 60.4506 - val_loss: 3618.5657 - val_mae: 33.1830\n",
      "Epoch 812 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.6172 - mae: 60.4506 - val_loss: 3618.5613 - val_mae: 33.1830\n",
      "Epoch 813 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44423.6055 - mae: 60.4506 - val_loss: 3618.5574 - val_mae: 33.1830\n",
      "Epoch 814 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.5859 - mae: 60.4506 - val_loss: 3618.5537 - val_mae: 33.1829\n",
      "Epoch 815 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.5820 - mae: 60.4506 - val_loss: 3618.5493 - val_mae: 33.1829\n",
      "Epoch 816 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.5781 - mae: 60.4506 - val_loss: 3618.5461 - val_mae: 33.1829\n",
      "Epoch 817 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.5664 - mae: 60.4506 - val_loss: 3618.5422 - val_mae: 33.1829\n",
      "Epoch 818 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.5625 - mae: 60.4506 - val_loss: 3618.5388 - val_mae: 33.1829\n",
      "Epoch 819 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.5508 - mae: 60.4506 - val_loss: 3618.5349 - val_mae: 33.1828\n",
      "Epoch 820 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.5469 - mae: 60.4505 - val_loss: 3618.5315 - val_mae: 33.1828\n",
      "Epoch 821 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.5469 - mae: 60.4506 - val_loss: 3618.5276 - val_mae: 33.1828\n",
      "Epoch 822 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.5352 - mae: 60.4506 - val_loss: 3618.5247 - val_mae: 33.1828\n",
      "Epoch 823 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.5273 - mae: 60.4506 - val_loss: 3618.5208 - val_mae: 33.1828\n",
      "Epoch 824 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.5312 - mae: 60.4506 - val_loss: 3618.5168 - val_mae: 33.1828\n",
      "Epoch 825 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.5273 - mae: 60.4505 - val_loss: 3618.5139 - val_mae: 33.1827\n",
      "Epoch 826 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44423.5156 - mae: 60.4505 - val_loss: 3618.5098 - val_mae: 33.1827\n",
      "Epoch 827 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44423.5156 - mae: 60.4505 - val_loss: 3618.5066 - val_mae: 33.1827\n",
      "Epoch 828 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44423.5039 - mae: 60.4505 - val_loss: 3618.5032 - val_mae: 33.1827\n",
      "Epoch 829 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.5000 - mae: 60.4505 - val_loss: 3618.4998 - val_mae: 33.1827\n",
      "Epoch 830 / 1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 44423.4883 - mae: 60.4505 - val_loss: 3618.4963 - val_mae: 33.1827\n",
      "Epoch 831 / 1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 44423.4844 - mae: 60.4505 - val_loss: 3618.4927 - val_mae: 33.1826\n",
      "Epoch 832 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44423.4844 - mae: 60.4505 - val_loss: 3618.4900 - val_mae: 33.1826\n",
      "Epoch 833 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.4727 - mae: 60.4505 - val_loss: 3618.4861 - val_mae: 33.1826\n",
      "Epoch 834 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.4648 - mae: 60.4505 - val_loss: 3618.4832 - val_mae: 33.1826\n",
      "Epoch 835 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.4609 - mae: 60.4505 - val_loss: 3618.4790 - val_mae: 33.1826\n",
      "Epoch 836 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.4609 - mae: 60.4505 - val_loss: 3618.4758 - val_mae: 33.1826\n",
      "Epoch 837 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.4453 - mae: 60.4505 - val_loss: 3618.4719 - val_mae: 33.1825\n",
      "Epoch 838 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.4336 - mae: 60.4505 - val_loss: 3618.4680 - val_mae: 33.1825\n",
      "Epoch 839 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.4219 - mae: 60.4505 - val_loss: 3618.4641 - val_mae: 33.1825\n",
      "Epoch 840 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.4141 - mae: 60.4505 - val_loss: 3618.4602 - val_mae: 33.1825\n",
      "Epoch 841 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.4062 - mae: 60.4505 - val_loss: 3618.4573 - val_mae: 33.1825\n",
      "Epoch 842 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.4062 - mae: 60.4505 - val_loss: 3618.4539 - val_mae: 33.1824\n",
      "Epoch 843 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.4023 - mae: 60.4505 - val_loss: 3618.4502 - val_mae: 33.1824\n",
      "Epoch 844 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44423.3945 - mae: 60.4505 - val_loss: 3618.4473 - val_mae: 33.1824\n",
      "Epoch 845 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44423.3828 - mae: 60.4505 - val_loss: 3618.4438 - val_mae: 33.1824\n",
      "Epoch 846 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44423.3789 - mae: 60.4505 - val_loss: 3618.4407 - val_mae: 33.1824\n",
      "Epoch 847 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44423.3672 - mae: 60.4505 - val_loss: 3618.4375 - val_mae: 33.1824\n",
      "Epoch 848 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44423.3555 - mae: 60.4505 - val_loss: 3618.4341 - val_mae: 33.1824\n",
      "Epoch 849 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44423.3477 - mae: 60.4505 - val_loss: 3618.4309 - val_mae: 33.1823\n",
      "Epoch 850 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44423.3438 - mae: 60.4505 - val_loss: 3618.4275 - val_mae: 33.1823\n",
      "Epoch 851 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44423.3320 - mae: 60.4505 - val_loss: 3618.4246 - val_mae: 33.1823\n",
      "Epoch 852 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44423.3320 - mae: 60.4505 - val_loss: 3618.4216 - val_mae: 33.1823\n",
      "Epoch 853 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.3281 - mae: 60.4505 - val_loss: 3618.4185 - val_mae: 33.1823\n",
      "Epoch 854 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.3203 - mae: 60.4505 - val_loss: 3618.4160 - val_mae: 33.1823\n",
      "Epoch 855 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.3164 - mae: 60.4505 - val_loss: 3618.4128 - val_mae: 33.1822\n",
      "Epoch 856 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.3125 - mae: 60.4505 - val_loss: 3618.4104 - val_mae: 33.1822\n",
      "Epoch 857 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.3047 - mae: 60.4505 - val_loss: 3618.4072 - val_mae: 33.1822\n",
      "Epoch 858 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44423.3047 - mae: 60.4505 - val_loss: 3618.4045 - val_mae: 33.1822\n",
      "Epoch 859 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44423.3008 - mae: 60.4505 - val_loss: 3618.4014 - val_mae: 33.1822\n",
      "Epoch 860 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.2891 - mae: 60.4505 - val_loss: 3618.3982 - val_mae: 33.1822\n",
      "Epoch 861 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.2852 - mae: 60.4505 - val_loss: 3618.3953 - val_mae: 33.1822\n",
      "Epoch 862 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.2773 - mae: 60.4505 - val_loss: 3618.3926 - val_mae: 33.1821\n",
      "Epoch 863 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44423.2695 - mae: 60.4505 - val_loss: 3618.3896 - val_mae: 33.1821\n",
      "Epoch 864 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44423.2656 - mae: 60.4505 - val_loss: 3618.3872 - val_mae: 33.1821\n",
      "Epoch 865 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44423.2656 - mae: 60.4505 - val_loss: 3618.3843 - val_mae: 33.1821\n",
      "Epoch 866 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44423.2656 - mae: 60.4505 - val_loss: 3618.3813 - val_mae: 33.1821\n",
      "Epoch 867 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44423.2617 - mae: 60.4505 - val_loss: 3618.3784 - val_mae: 33.1821\n",
      "Epoch 868 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44423.2539 - mae: 60.4505 - val_loss: 3618.3760 - val_mae: 33.1821\n",
      "Epoch 869 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44423.2461 - mae: 60.4505 - val_loss: 3618.3738 - val_mae: 33.1820\n",
      "Epoch 870 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44423.2461 - mae: 60.4504 - val_loss: 3618.3706 - val_mae: 33.1820\n",
      "Epoch 871 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44423.2461 - mae: 60.4505 - val_loss: 3618.3687 - val_mae: 33.1820\n",
      "Epoch 872 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44423.2305 - mae: 60.4504 - val_loss: 3618.3660 - val_mae: 33.1820\n",
      "Epoch 873 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44423.2227 - mae: 60.4505 - val_loss: 3618.3640 - val_mae: 33.1820\n",
      "Epoch 874 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44423.2227 - mae: 60.4505 - val_loss: 3618.3623 - val_mae: 33.1820\n",
      "Epoch 875 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44423.2148 - mae: 60.4505 - val_loss: 3618.3594 - val_mae: 33.1820\n",
      "Epoch 876 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44423.2109 - mae: 60.4504 - val_loss: 3618.3569 - val_mae: 33.1820\n",
      "Epoch 877 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44423.2031 - mae: 60.4504 - val_loss: 3618.3550 - val_mae: 33.1820\n",
      "Epoch 878 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44423.2031 - mae: 60.4505 - val_loss: 3618.3521 - val_mae: 33.1819\n",
      "Epoch 879 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44423.1992 - mae: 60.4504 - val_loss: 3618.3499 - val_mae: 33.1819\n",
      "Epoch 880 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.1875 - mae: 60.4504 - val_loss: 3618.3474 - val_mae: 33.1819\n",
      "Epoch 881 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44423.1953 - mae: 60.4505 - val_loss: 3618.3447 - val_mae: 33.1819\n",
      "Epoch 882 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44423.1797 - mae: 60.4504 - val_loss: 3618.3430 - val_mae: 33.1819\n",
      "Epoch 883 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.1836 - mae: 60.4504 - val_loss: 3618.3401 - val_mae: 33.1819\n",
      "Epoch 884 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.1719 - mae: 60.4504 - val_loss: 3618.3379 - val_mae: 33.1819\n",
      "Epoch 885 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.1680 - mae: 60.4504 - val_loss: 3618.3354 - val_mae: 33.1819\n",
      "Epoch 886 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.1641 - mae: 60.4504 - val_loss: 3618.3328 - val_mae: 33.1818\n",
      "Epoch 887 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.1562 - mae: 60.4504 - val_loss: 3618.3306 - val_mae: 33.1818\n",
      "Epoch 888 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.1562 - mae: 60.4504 - val_loss: 3618.3276 - val_mae: 33.1818\n",
      "Epoch 889 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.1523 - mae: 60.4504 - val_loss: 3618.3259 - val_mae: 33.1818\n",
      "Epoch 890 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.1484 - mae: 60.4504 - val_loss: 3618.3230 - val_mae: 33.1818\n",
      "Epoch 891 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.1484 - mae: 60.4504 - val_loss: 3618.3203 - val_mae: 33.1818\n",
      "Epoch 892 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44423.1445 - mae: 60.4504 - val_loss: 3618.3191 - val_mae: 33.1818\n",
      "Epoch 893 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44423.1445 - mae: 60.4504 - val_loss: 3618.3167 - val_mae: 33.1818\n",
      "Epoch 894 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.1328 - mae: 60.4504 - val_loss: 3618.3152 - val_mae: 33.1818\n",
      "Epoch 895 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.1289 - mae: 60.4504 - val_loss: 3618.3132 - val_mae: 33.1818\n",
      "Epoch 896 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.1289 - mae: 60.4504 - val_loss: 3618.3115 - val_mae: 33.1817\n",
      "Epoch 897 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.1328 - mae: 60.4504 - val_loss: 3618.3091 - val_mae: 33.1817\n",
      "Epoch 898 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.1211 - mae: 60.4504 - val_loss: 3618.3071 - val_mae: 33.1817\n",
      "Epoch 899 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.1211 - mae: 60.4504 - val_loss: 3618.3054 - val_mae: 33.1817\n",
      "Epoch 900 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.1211 - mae: 60.4504 - val_loss: 3618.3035 - val_mae: 33.1817\n",
      "Epoch 901 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44423.1172 - mae: 60.4504 - val_loss: 3618.3015 - val_mae: 33.1817\n",
      "Epoch 902 / 1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 44423.1133 - mae: 60.4504 - val_loss: 3618.2998 - val_mae: 33.1817\n",
      "Epoch 903 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44423.1055 - mae: 60.4504 - val_loss: 3618.2981 - val_mae: 33.1817\n",
      "Epoch 904 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44423.1055 - mae: 60.4504 - val_loss: 3618.2954 - val_mae: 33.1817\n",
      "Epoch 905 / 1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 44423.1055 - mae: 60.4504 - val_loss: 3618.2937 - val_mae: 33.1817\n",
      "Epoch 906 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44423.1055 - mae: 60.4504 - val_loss: 3618.2913 - val_mae: 33.1816\n",
      "Epoch 907 / 1000\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 44423.1016 - mae: 60.4504 - val_loss: 3618.2900 - val_mae: 33.1816\n",
      "Epoch 908 / 1000\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 44423.1055 - mae: 60.4504 - val_loss: 3618.2874 - val_mae: 33.1816\n",
      "Epoch 909 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.1016 - mae: 60.4504 - val_loss: 3618.2854 - val_mae: 33.1816\n",
      "Epoch 910 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.0977 - mae: 60.4504 - val_loss: 3618.2837 - val_mae: 33.1816\n",
      "Epoch 911 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.1016 - mae: 60.4504 - val_loss: 3618.2815 - val_mae: 33.1816\n",
      "Epoch 912 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.0977 - mae: 60.4504 - val_loss: 3618.2803 - val_mae: 33.1816\n",
      "Epoch 913 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.0859 - mae: 60.4504 - val_loss: 3618.2783 - val_mae: 33.1816\n",
      "Epoch 914 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.0859 - mae: 60.4504 - val_loss: 3618.2771 - val_mae: 33.1816\n",
      "Epoch 915 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.0859 - mae: 60.4504 - val_loss: 3618.2749 - val_mae: 33.1816\n",
      "Epoch 916 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.0781 - mae: 60.4504 - val_loss: 3618.2734 - val_mae: 33.1815\n",
      "Epoch 917 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.0703 - mae: 60.4504 - val_loss: 3618.2715 - val_mae: 33.1815\n",
      "Epoch 918 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.0625 - mae: 60.4504 - val_loss: 3618.2703 - val_mae: 33.1815\n",
      "Epoch 919 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.0625 - mae: 60.4504 - val_loss: 3618.2678 - val_mae: 33.1815\n",
      "Epoch 920 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.0547 - mae: 60.4504 - val_loss: 3618.2661 - val_mae: 33.1815\n",
      "Epoch 921 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.0625 - mae: 60.4504 - val_loss: 3618.2649 - val_mae: 33.1815\n",
      "Epoch 922 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.0625 - mae: 60.4504 - val_loss: 3618.2634 - val_mae: 33.1815\n",
      "Epoch 923 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.0508 - mae: 60.4504 - val_loss: 3618.2615 - val_mae: 33.1815\n",
      "Epoch 924 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.0508 - mae: 60.4504 - val_loss: 3618.2605 - val_mae: 33.1815\n",
      "Epoch 925 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.0508 - mae: 60.4504 - val_loss: 3618.2593 - val_mae: 33.1815\n",
      "Epoch 926 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.0469 - mae: 60.4504 - val_loss: 3618.2571 - val_mae: 33.1815\n",
      "Epoch 927 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.0352 - mae: 60.4504 - val_loss: 3618.2556 - val_mae: 33.1815\n",
      "Epoch 928 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.0312 - mae: 60.4504 - val_loss: 3618.2542 - val_mae: 33.1815\n",
      "Epoch 929 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.0352 - mae: 60.4504 - val_loss: 3618.2522 - val_mae: 33.1814\n",
      "Epoch 930 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.0312 - mae: 60.4504 - val_loss: 3618.2507 - val_mae: 33.1814\n",
      "Epoch 931 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.0312 - mae: 60.4504 - val_loss: 3618.2488 - val_mae: 33.1814\n",
      "Epoch 932 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.0273 - mae: 60.4504 - val_loss: 3618.2473 - val_mae: 33.1814\n",
      "Epoch 933 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.0195 - mae: 60.4504 - val_loss: 3618.2451 - val_mae: 33.1814\n",
      "Epoch 934 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.0117 - mae: 60.4504 - val_loss: 3618.2432 - val_mae: 33.1814\n",
      "Epoch 935 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.0117 - mae: 60.4504 - val_loss: 3618.2422 - val_mae: 33.1814\n",
      "Epoch 936 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.0039 - mae: 60.4504 - val_loss: 3618.2410 - val_mae: 33.1814\n",
      "Epoch 937 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.0000 - mae: 60.4504 - val_loss: 3618.2390 - val_mae: 33.1814\n",
      "Epoch 938 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44423.0000 - mae: 60.4504 - val_loss: 3618.2380 - val_mae: 33.1814\n",
      "Epoch 939 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44422.9961 - mae: 60.4504 - val_loss: 3618.2358 - val_mae: 33.1814\n",
      "Epoch 940 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44422.9961 - mae: 60.4504 - val_loss: 3618.2351 - val_mae: 33.1814\n",
      "Epoch 941 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44422.9961 - mae: 60.4504 - val_loss: 3618.2341 - val_mae: 33.1814\n",
      "Epoch 942 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44422.9883 - mae: 60.4504 - val_loss: 3618.2329 - val_mae: 33.1814\n",
      "Epoch 943 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44422.9844 - mae: 60.4504 - val_loss: 3618.2312 - val_mae: 33.1813\n",
      "Epoch 944 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44422.9844 - mae: 60.4504 - val_loss: 3618.2297 - val_mae: 33.1813\n",
      "Epoch 945 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44422.9844 - mae: 60.4504 - val_loss: 3618.2288 - val_mae: 33.1813\n",
      "Epoch 946 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44422.9805 - mae: 60.4504 - val_loss: 3618.2275 - val_mae: 33.1813\n",
      "Epoch 947 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44422.9805 - mae: 60.4504 - val_loss: 3618.2263 - val_mae: 33.1813\n",
      "Epoch 948 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44422.9727 - mae: 60.4504 - val_loss: 3618.2244 - val_mae: 33.1813\n",
      "Epoch 949 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44422.9688 - mae: 60.4504 - val_loss: 3618.2239 - val_mae: 33.1813\n",
      "Epoch 950 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44422.9648 - mae: 60.4504 - val_loss: 3618.2229 - val_mae: 33.1813\n",
      "Epoch 951 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44422.9648 - mae: 60.4504 - val_loss: 3618.2209 - val_mae: 33.1813\n",
      "Epoch 952 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44422.9648 - mae: 60.4504 - val_loss: 3618.2200 - val_mae: 33.1813\n",
      "Epoch 953 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44422.9648 - mae: 60.4504 - val_loss: 3618.2183 - val_mae: 33.1813\n",
      "Epoch 954 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44422.9531 - mae: 60.4504 - val_loss: 3618.2168 - val_mae: 33.1813\n",
      "Epoch 955 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44422.9531 - mae: 60.4503 - val_loss: 3618.2163 - val_mae: 33.1813\n",
      "Epoch 956 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44422.9531 - mae: 60.4504 - val_loss: 3618.2146 - val_mae: 33.1813\n",
      "Epoch 957 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44422.9492 - mae: 60.4504 - val_loss: 3618.2131 - val_mae: 33.1812\n",
      "Epoch 958 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44422.9453 - mae: 60.4504 - val_loss: 3618.2114 - val_mae: 33.1812\n",
      "Epoch 959 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44422.9453 - mae: 60.4504 - val_loss: 3618.2100 - val_mae: 33.1812\n",
      "Epoch 960 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44422.9453 - mae: 60.4504 - val_loss: 3618.2087 - val_mae: 33.1812\n",
      "Epoch 961 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44422.9453 - mae: 60.4504 - val_loss: 3618.2070 - val_mae: 33.1812\n",
      "Epoch 962 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44422.9336 - mae: 60.4504 - val_loss: 3618.2058 - val_mae: 33.1812\n",
      "Epoch 963 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44422.9297 - mae: 60.4504 - val_loss: 3618.2051 - val_mae: 33.1812\n",
      "Epoch 964 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44422.9297 - mae: 60.4504 - val_loss: 3618.2041 - val_mae: 33.1812\n",
      "Epoch 965 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44422.9297 - mae: 60.4504 - val_loss: 3618.2024 - val_mae: 33.1812\n",
      "Epoch 966 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44422.9297 - mae: 60.4504 - val_loss: 3618.2014 - val_mae: 33.1812\n",
      "Epoch 967 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44422.9297 - mae: 60.4504 - val_loss: 3618.1997 - val_mae: 33.1812\n",
      "Epoch 968 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44422.9219 - mae: 60.4504 - val_loss: 3618.1990 - val_mae: 33.1812\n",
      "Epoch 969 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44422.9180 - mae: 60.4504 - val_loss: 3618.1978 - val_mae: 33.1812\n",
      "Epoch 970 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44422.9180 - mae: 60.4504 - val_loss: 3618.1978 - val_mae: 33.1812\n",
      "Epoch 971 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44422.9180 - mae: 60.4504 - val_loss: 3618.1968 - val_mae: 33.1812\n",
      "Epoch 972 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44422.9180 - mae: 60.4504 - val_loss: 3618.1953 - val_mae: 33.1812\n",
      "Epoch 973 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44422.9141 - mae: 60.4504 - val_loss: 3618.1948 - val_mae: 33.1812\n",
      "Epoch 974 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44422.9141 - mae: 60.4503 - val_loss: 3618.1926 - val_mae: 33.1811\n",
      "Epoch 975 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44422.9141 - mae: 60.4503 - val_loss: 3618.1921 - val_mae: 33.1811\n",
      "Epoch 976 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44422.9062 - mae: 60.4504 - val_loss: 3618.1912 - val_mae: 33.1811\n",
      "Epoch 977 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44422.9062 - mae: 60.4504 - val_loss: 3618.1899 - val_mae: 33.1811\n",
      "Epoch 978 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44422.9023 - mae: 60.4504 - val_loss: 3618.1890 - val_mae: 33.1811\n",
      "Epoch 979 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44422.8984 - mae: 60.4504 - val_loss: 3618.1880 - val_mae: 33.1811\n",
      "Epoch 980 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44422.8984 - mae: 60.4504 - val_loss: 3618.1875 - val_mae: 33.1811\n",
      "Epoch 981 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44422.8945 - mae: 60.4504 - val_loss: 3618.1863 - val_mae: 33.1811\n",
      "Epoch 982 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44422.8945 - mae: 60.4504 - val_loss: 3618.1853 - val_mae: 33.1811\n",
      "Epoch 983 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44422.8945 - mae: 60.4504 - val_loss: 3618.1843 - val_mae: 33.1811\n",
      "Epoch 984 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44422.8945 - mae: 60.4504 - val_loss: 3618.1836 - val_mae: 33.1811\n",
      "Epoch 985 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44422.8867 - mae: 60.4504 - val_loss: 3618.1829 - val_mae: 33.1811\n",
      "Epoch 986 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44422.8867 - mae: 60.4504 - val_loss: 3618.1812 - val_mae: 33.1811\n",
      "Epoch 987 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44422.8789 - mae: 60.4504 - val_loss: 3618.1807 - val_mae: 33.1811\n",
      "Epoch 988 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44422.8789 - mae: 60.4503 - val_loss: 3618.1802 - val_mae: 33.1811\n",
      "Epoch 989 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44422.8789 - mae: 60.4503 - val_loss: 3618.1792 - val_mae: 33.1811\n",
      "Epoch 990 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44422.8828 - mae: 60.4504 - val_loss: 3618.1785 - val_mae: 33.1811\n",
      "Epoch 991 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44422.8711 - mae: 60.4503 - val_loss: 3618.1770 - val_mae: 33.1811\n",
      "Epoch 992 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44422.8711 - mae: 60.4503 - val_loss: 3618.1758 - val_mae: 33.1811\n",
      "Epoch 993 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44422.8711 - mae: 60.4504 - val_loss: 3618.1746 - val_mae: 33.1811\n",
      "Epoch 994 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44422.8711 - mae: 60.4503 - val_loss: 3618.1743 - val_mae: 33.1811\n",
      "Epoch 995 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44422.8711 - mae: 60.4503 - val_loss: 3618.1726 - val_mae: 33.1811\n",
      "Epoch 996 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44422.8711 - mae: 60.4503 - val_loss: 3618.1721 - val_mae: 33.1810\n",
      "Epoch 997 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44422.8633 - mae: 60.4504 - val_loss: 3618.1716 - val_mae: 33.1810\n",
      "Epoch 998 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44422.8633 - mae: 60.4504 - val_loss: 3618.1709 - val_mae: 33.1810\n",
      "Epoch 999 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44422.8633 - mae: 60.4504 - val_loss: 3618.1697 - val_mae: 33.1810\n",
      "Epoch 1000 / 1000\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 44422.8633 - mae: 60.4504 - val_loss: 3618.1687 - val_mae: 33.1810\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.utils.data_utils import iter_sequence_infinite as iter_inf \n",
    "state_model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
    "\n",
    "epochs = 1000\n",
    "loss = []\n",
    "val_loss = []\n",
    "for i in range(epochs):\n",
    "    print('Epoch', i+1, '/', epochs)\n",
    "    state_history = state_model.fit_generator(iter_inf(state_train_gen),\n",
    "                                  steps_per_epoch=len(state_train_gen),\n",
    "                                  validation_data=iter_inf(state_val_gen),\n",
    "                                  validation_steps=len(state_val_gen),\n",
    "                                  epochs=1,\n",
    "                                  verbose=1,\n",
    "                                  shuffle=False) # Because the time series\n",
    "    loss.append(state_history.history['loss'])\n",
    "    val_loss.append(state_history.history['val_loss'])\n",
    "    state_model.reset_states()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a3bb21a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss, label='statefull rnn training_loss')\n",
    "plt.plot(val_loss, label='statefull rnn validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "181c8895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss, label='statefull rnn training_loss')\n",
    "plt.plot(rnn_history .history['loss'], label='rnn training_loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
